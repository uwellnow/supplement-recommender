{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4fa7c39-1ed2-455b-8a2d-b3faff5cfe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14dcb0da-7699-4b17-ade8-941279455ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n프로틴/게이너 - 주로 운동 후\\n프리워크아웃 - 주로 운동 전\\n인트라워크아웃 - 주로 운동 중이긴 해\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "'''\n",
    "프로틴/게이너 - 주로 운동 후\n",
    "프리워크아웃 - 주로 운동 전\n",
    "인트라워크아웃 - 주로 운동 중이긴 해\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9258762-692b-48f4-b300-1350f601fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_MAIN = '[스트롱라이프]최종_데이터_20250924.xlsx'\n",
    "\n",
    "def load_and_concatenate_user_data(file_path):\n",
    "    \"\"\"\n",
    "    1차와 2차 시트를 로드, no/no. 칼럼을 통일한 후 수직으로 합침.\n",
    "    \"\"\"\n",
    "    \n",
    "    HEADER_ROW_INDEX = 0\n",
    "    \n",
    "    # 1차, 2차 시트 로드 및 헤더 설정\n",
    "    df_1st = pd.read_excel(file_path, sheet_name='1차', header=0)\n",
    "    df_2nd = pd.read_excel(file_path, sheet_name='2차', header=0)\n",
    "\n",
    "    df_1st.columns = df_1st.columns.astype(str).str.strip()\n",
    "    df_2nd.columns = df_2nd.columns.astype(str).str.strip()\n",
    "    \n",
    "    # User ID 칼럼 이름 통일 ('no.' -> 'no')\n",
    "    col_to_rename = {col: 'no' for col in df_2nd.columns if isinstance(col, str) and col.strip() == 'no.'}\n",
    "    if col_to_rename:\n",
    "        df_2nd.rename(columns=col_to_rename, inplace=True)\n",
    "    \n",
    "    # 수직으로 concatenate\n",
    "    df_user_raw = pd.concat([df_1st, df_2nd], ignore_index=True)\n",
    "    df_user_raw.rename(columns={'no': 'user_id'}, inplace=True)\n",
    "    \n",
    "    return df_user_raw.set_index('user_id', drop=False)\n",
    "\n",
    "\n",
    "def clean_user_ids(df_user_raw):\n",
    "    \"\"\"\n",
    "    user_id (인덱스)에서 결측치 및 유효하지 않은 잔여 행을 제거하여 user_id를 정리.\n",
    "    \"\"\"\n",
    "    # 문자열 'nan'을 실제 결측치(NaN)로 변환\n",
    "    df_user_raw.index = df_user_raw.index.to_series().replace('nan', np.nan) \n",
    "    \n",
    "    # 인덱스 값을 숫자형으로 변환 가능한지 확인 (오류 시 NaN 처리)\n",
    "    valid_user_ids_numeric = pd.to_numeric(df_user_raw.index, errors='coerce')\n",
    "\n",
    "    # 1. user_id가 결측치가 아니고 (NaN이 아니고)\n",
    "    # 2. user_id가 0보다 큰 값인 (유효한 ID인) 행만 선택\n",
    "    valid_indices = df_user_raw.index[valid_user_ids_numeric.notna() & (valid_user_ids_numeric > 0)].unique()\n",
    "\n",
    "    return df_user_raw.loc[valid_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "835e1cba-8fbf-4235-b4aa-3fe035ac1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 특징 데이터 concatenate\n",
      "-----------------------------------\n",
      "총 사용자 수 (정리 전): 1037명\n",
      "데이터프레임 크기 (정리 전): (1038, 147)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 데이터 로드 및 합치기\n",
    "    df_user_raw = load_and_concatenate_user_data(FILE_PATH_MAIN)\n",
    "    \n",
    "    # user_id 정리 전 상태 출력\n",
    "    print(\"사용자 특징 데이터 concatenate\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"총 사용자 수 (정리 전): {df_user_raw.index.nunique()}명\")\n",
    "    print(f\"데이터프레임 크기 (정리 전): {df_user_raw.shape}\")\n",
    "    \n",
    "    # 3. user_id 정리\n",
    "    df_user_clean = clean_user_ids(df_user_raw)\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터 로드 또는 처리 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed6cb9d0-214b-4ea3-b13f-392c2d68ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 특징 데이터 로드 완료 (df_item_raw)\n",
      "------------------------------\n",
      "\n",
      "--- df_item_raw (제품 특징 데이터) 검증 ---\n",
      "로드된 Item 칼럼 목록: ['product_id', 'brand_name_kor', 'brand_name', 'ingredient_type', 'category', 'sub_category', 'form_factor', 'serving_size', 'serving_unit', 'servings_total', 'calories', 'protein', 'carbs', 'sugars', 'fats', 'Trans Fat', 'Saturated Fat', 'Dietary Fiber', 'ingredients', 'intake_timing', 'product_name', 'sensory_tags', 'functional_tags', 'feature_tags', 'allergens', 'Unnamed: 25']\n",
      "                            product_id  protein\n",
      "0                ANIMAL_MEAL_CHOCOLATE     46.0\n",
      "1            CBUM_MASSGAINER_CHOCOLATE     53.0\n",
      "2         CBUM_MASSGAINER_COOKIESCREAM     53.0\n",
      "3              CBUM_MASSGAINER_VANILLA     53.0\n",
      "4  GASPARI_REALMASS_CHOCOLATEMILKSHAKE     50.0\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 정의\n",
    "FILE_PATH_META = \"제품 메타데이터 최종.xlsx\" # 제품 메타데이터 파일\n",
    "\n",
    "# Item ID 칼럼 이름 확정 (첫 번째 칼럼이 product_id라고 가정)\n",
    "ITEM_ID_COL = 'product_id' \n",
    "PROTEIN_COL = 'protein' # 단백질 정량 칼럼\n",
    "\n",
    "try:\n",
    "    # 1. Item Feature 데이터 로드 (Header=0 가정)\n",
    "    df_item_raw = pd.read_excel(FILE_PATH_META, sheet_name='제품 메타데이터 최종', header=0)\n",
    "    \n",
    "    # 2. Item ID 칼럼 이름 통일 및 확인\n",
    "    df_item_raw.rename(columns={df_item_raw.columns[0]: ITEM_ID_COL}, inplace=True)\n",
    "    \n",
    "    print(\"아이템 특징 데이터 로드 완료 (df_item_raw)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 3. Item Data 핵심 칼럼 확인\n",
    "    print(\"\\n--- df_item_raw (제품 특징 데이터) 검증 ---\")\n",
    "    \n",
    "    # Item ID와 단백질 정량 칼럼만 출력하여 확인\n",
    "    display_item_cols = [ITEM_ID_COL, PROTEIN_COL]\n",
    "    \n",
    "    # df_item_raw의 모든 칼럼을 출력하여 칼럼 이름이 제대로 로드되었는지 최종 확인\n",
    "    print(f\"로드된 Item 칼럼 목록: {df_item_raw.columns.tolist()}\")\n",
    "    \n",
    "    print(df_item_raw[df_item_raw.columns.intersection(display_item_cols)].head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Item Data 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66e8fba2-16ca-4f43-b3ea-803f3be65180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 엑셀 파일 로드 및 정확한 ID 매핑 딕셔너리 생성 완료.\n",
      "**원본 데이터프레임 (df_align)은 7개의 컬럼으로 메모리에 유지됩니다.**\n"
     ]
    }
   ],
   "source": [
    "# 2. 엑셀 파일을 읽어 데이터프레임 전체를 로드 (모든 컬럼 유지)\n",
    "FILE_PATH_ALIGN = \"uwellnow_product_align.xlsx\"\n",
    "try:\n",
    "    df_align = pd.read_excel(FILE_PATH_ALIGN)\n",
    "    \n",
    "    # 3. 매핑 키 생성 및 딕셔너리 구축\n",
    "    # 두 컬럼을 조합하여 새로운 키 (Key)를 만듭니다: \"PRODUCT_FLAVOR\"\n",
    "    df_align['MAPPING_KEY'] = (df_align['product'].astype(str).str.strip().str.upper() + \n",
    "                               '_' + \n",
    "                               df_align['flavor'].astype(str).str.strip().str.upper())\n",
    "\n",
    "    # 4. 매핑 딕셔너리 생성: {PRODUCT_FLAVOR: product_id}\n",
    "    # Series를 사용하여 딕셔너리를 만듭니다. (중복된 키가 있다면 첫 번째 값을 사용)\n",
    "    ITEM_FULL_ID_MAP = pd.Series(\n",
    "        df_align['product_id'].astype(str).str.strip().str.upper().values,\n",
    "        index=df_align['MAPPING_KEY']\n",
    "    ).to_dict()\n",
    "\n",
    "    # 딕셔너리에서 NaN (결측치) 관련 항목은 제거 (선택 사항)\n",
    "    if 'NAN_NAN' in ITEM_FULL_ID_MAP:\n",
    "        del ITEM_FULL_ID_MAP['NAN_NAN']\n",
    "        \n",
    "    print(\"✅ 엑셀 파일 로드 및 정확한 ID 매핑 딕셔너리 생성 완료.\")\n",
    "    print(f\"**원본 데이터프레임 (df_align)은 {df_align.shape[1]}개의 컬럼으로 메모리에 유지됩니다.**\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 오류: 파일 경로 '{FILE_PATH_ALIGN}'를 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "    ITEM_FULL_ID_MAP = {}\n",
    "    df_align = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4603628-d843-4e77-aa4a-dcdc0d9aea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 개선된 함수 사용 예시 (AC, AD 분리된 경우) ---\n",
      "('게토레이 파우더', '게토레이맛') -> GATORADE_POWDER_LEMONLIME\n",
      "('새로운 단백질', '바나나맛') -> 새로운단백질바나나맛\n"
     ]
    }
   ],
   "source": [
    "# 2) 사용자 응답 제품명을 정확한 product_id로 매핑하는 함수 (AC 컬럼 + AD 컬럼 사용)\n",
    "def normalize_interaction_id(product_name_ac, flavor_ad, mapping_dict=ITEM_FULL_ID_MAP):\n",
    "    \n",
    "    if not product_name_ac or not flavor_ad or not mapping_dict:\n",
    "        return None \n",
    "    \n",
    "    # 1. 두 입력값을 정제하여 딕셔너리 키 형태로 변환: \"PRODUCT_FLAVOR\"\n",
    "    product_clean = str(product_name_ac).strip().upper()\n",
    "    flavor_clean = str(flavor_ad).strip().upper()\n",
    "    \n",
    "    # 딕셔너리 검색에 사용할 최종 키 조합\n",
    "    search_key = f\"{product_clean}_{flavor_clean}\"\n",
    "    \n",
    "    # 2. 딕셔너리에서 정확히 일치하는 키가 있는지 확인\n",
    "    if search_key in mapping_dict:\n",
    "        return mapping_dict[search_key]\n",
    "\n",
    "    # 3. 매핑되지 않은 경우, 두 이름을 합쳐서 공백 및 특수문자를 제거한 문자열을 반환 (안전장치)\n",
    "    # 두 인자를 합치기 때문에, 베이스 ID 매핑 함수와는 다른 결과를 반환할 수 있습니다.\n",
    "    combined_name = f\"{product_clean}{flavor_clean}\"\n",
    "    return combined_name.replace(' ', '').replace('-', '').replace('.', '').replace('(', '').replace(')', '')\n",
    "\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "print(\"\\n--- 개선된 함수 사용 예시 (AC, AD 분리된 경우) ---\")\n",
    "\n",
    "# 예시 1: 엑셀 파일에 '게토레이 파우더_게토레이맛'으로 매핑된 경우\n",
    "# (가정: GATORADE_POWDER_LEMONLIME이 매핑되어 있다고 가정)\n",
    "product_in = '게토레이 파우더'\n",
    "flavor_in = '게토레이맛'\n",
    "result1 = normalize_interaction_id(product_in, flavor_in)\n",
    "print(f\"('{product_in}', '{flavor_in}') -> {result1}\") \n",
    "# 예상 결과: GATORADE_POWDER_LEMONLIME\n",
    "\n",
    "# 예시 2: 엑셀 파일에 없는 제품의 경우\n",
    "product_in = '새로운 단백질'\n",
    "flavor_in = '바나나맛'\n",
    "result2 = normalize_interaction_id(product_in, flavor_in)\n",
    "print(f\"('{product_in}', '{flavor_in}') -> {result2}\") \n",
    "# 예상 결과: 새로운단백질바나나맛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cd1f37d-f5b6-4288-a24f-486ab970da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightFM 모델링 변수 정의 ---\n",
    "\n",
    "# 사용자 특징 (User Feature, Multi-Hot Encoding 대상)\n",
    "OHE_USER_COLS = [\n",
    "    # Feature Group 1 (기본 정보 및 활동 패턴)\n",
    "    '3) 성별', \n",
    "    '8) 운동 활동 기간', \n",
    "    '7) 프로틴, 프리워크아웃, 전해질 음료, 게이너 등 헬스 보충제 2종 이상을 섭취해 보신 경험이 있으신가요?',\n",
    "    '9) 주에 몇 회 정도 운동을 진행하시나요?(택1)',\n",
    "    '10) 알러지 또는 민감성분(복수선택 가능)',\n",
    "    '11) 평소 챙기는 끼니는 어떻게 되나요?(복수선택 가능)',\n",
    "    '12) 식사 기준으로 운동 시간은 언제인가요?(택 1)',\n",
    "    '12-1) 일과(수업,업무,일 등) 기준으로 운동 시간은 언제인가요?(택 1)',\n",
    "    '12-2) 운동을 제외한 일과 중 활동은 어느 정도로 활발한가요?(택 1)',\n",
    "    '12-3) 시간 기준으로 운동 시작 시간이 언제인가요?(택 1)',\n",
    "    # Feature Group 2 (영향 요인 및 고려 항목) - 모든 보충제 관련 고려 항목 포함\n",
    "    '13-3) 프로틴의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '13-4) 프로틴의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '13-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '13-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '13-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)',\n",
    "    '14-3) 프리워크아웃의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '14-4) 프리워크아웃의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '14-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '14-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '14-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)',\n",
    "    '15-3) 전해질 음료의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '15-4) 전해질 음료의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '15-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '15-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '15-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)',\n",
    "    '16-3) 게이너의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '16-4) 게이너의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '16-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '16-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '16-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)',\n",
    "    '17-3) 해당 보충제의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '17-4) 해당 보충제의 효과에서 고려한 점은 무엇인가요?', '17-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '17-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)', '17-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)',\n",
    "]\n",
    "\n",
    "# B. 아이템 특징 (Item Feature, Multi-Hot Encoding 대상)\n",
    "OHE_ITEM_COLS = ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
    "\n",
    "# C. 상호작용 (Interaction, One-Hot Encoding 대상)\n",
    "# '가장 마음에 들었던 제품'을 Item ID로 사용하고, '재구매 의사'를 가중치로 사용합니다.\n",
    "INTERACTION_WEIGHT_COLS = [\n",
    "    ('13-9) [프로틴] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)', '13-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)', '13-17) 해당 프로틴에 대한 재구매 의사는 어느 정도인가요?'),\n",
    "    ('14-9) [프리워크아웃] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)', '14-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)', '14-17) 해당 프리워크아웃에 대한 재구매 의사는 어느 정도인가요?'),\n",
    "    ('15-9) [전해질 음료(BCAA, 이온음료)] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)', '15-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)', '15-17) 해당 전해질 음료에 대한 재구매 의사는 어느 정도인가요?'),\n",
    "    ('16-9) [게이너] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)', '16-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)', '16-17) 해당 게이너에 대한 재구매 의사는 어느 정도인가요?'),\n",
    "    ('17-9) 종합적으로 가장 마음에 들었던 제품 1개를 작성해 주세요', '17-10) 마음에 들었던 제품이 어떤 맛인가요?', '17-17) 해당 제품에 대한 재구매 의사는 어느 정도인가요?'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43e96d12-3a98-47b2-8043-16f16d45cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: OHE_ITEM_COLS 목록: ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
      "------------------------------\n",
      "DEBUG: Item Features 총 개수 (생성된 피처 종류): 90\n",
      "DEBUG: Item Features 행 개수 (상호작용): 489\n",
      "✅ Item Feature (정량 포함) 전처리 완료.\n",
      "✅ Interaction Matrix 소스 데이터 준비 완료. (랭킹 데이터 User Feature로 이동)\n",
      "✅ User Feature Matrix 소스 데이터 준비 완료. (랭킹 가중치 통합)\n",
      "\n",
      "--- 디버깅: 피처 데이터 상태 확인 ---\n",
      "User Features 총 개수 (Unique): 448\n",
      "User Features (상위 5개):\n",
      "   user_id   feature  weight\n",
      "0      2.0  3) 성별_남성     1.0\n",
      "1      4.0  3) 성별_여성     1.0\n",
      "2      5.0  3) 성별_여성     1.0\n",
      "3      6.0  3) 성별_여성     1.0\n",
      "4      7.0  3) 성별_여성     1.0\n",
      "\n",
      "Item Features 총 개수 (Unique): 90\n",
      "Item Features (상위 5개):\n",
      "                            product_id              feature\n",
      "0                ANIMAL_MEAL_CHOCOLATE  ingredient_type_주원료\n",
      "1            CBUM_MASSGAINER_CHOCOLATE  ingredient_type_주원료\n",
      "2         CBUM_MASSGAINER_COOKIESCREAM  ingredient_type_주원료\n",
      "3              CBUM_MASSGAINER_VANILLA  ingredient_type_주원료\n",
      "4  GASPARI_REALMASS_CHOCOLATEMILKSHAKE  ingredient_type_주원료\n",
      "\n",
      "--- LightFM 행렬 크기 ---\n",
      "Interaction Matrix (Total): (1037, 122)\n",
      "Interaction Matrix (Train): (1037, 122) / Non-zero: 280\n",
      "Interaction Matrix (Test): (1037, 122) / Non-zero: 70\n",
      "\n",
      "\n",
      "LightFM 하이브리드 추천 모델 학습 완료\n"
     ]
    }
   ],
   "source": [
    "# df_user_clean의 인덱스 이름 정리 (오류 해결)\n",
    "if df_user_clean.index.name == 'user_id':\n",
    "    df_user_clean.index.name = None\n",
    "\n",
    "try:\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 🚨 디버깅을 위해 OHE_ITEM_COLS에 어떤 컬럼이 있는지 확인합니다.\n",
    "    print(f\"DEBUG: OHE_ITEM_COLS 목록: {OHE_ITEM_COLS}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # 단백질 정량 처리 및 이산화 (Binning)\n",
    "    df_item_raw[PROTEIN_COL] = pd.to_numeric(df_item_raw[PROTEIN_COL], errors='coerce')\n",
    "    df_item_raw.dropna(subset=[PROTEIN_COL, ITEM_ID_COL], inplace=True)\n",
    "    bins = [0, 15, 25, df_item_raw[PROTEIN_COL].max() + 1]\n",
    "    labels = ['protein_low', 'protein_mid', 'protein_high']\n",
    "    df_item_raw['protein_bin'] = pd.cut(df_item_raw[PROTEIN_COL], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Item Feature Long 포맷 생성\n",
    "    selected_ohe_cols = [col for col in OHE_ITEM_COLS + ['protein_bin'] if col in df_item_raw.columns]\n",
    "    \n",
    "    df_item_features = df_item_raw.melt(\n",
    "        id_vars=[ITEM_ID_COL], \n",
    "        value_vars=selected_ohe_cols\n",
    "    )\n",
    "    \n",
    "    # 🚨 결측치(NaN)를 'NONE' 피처로 대체하여 데이터 손실을 방지합니다.\n",
    "    df_item_features['value'] = df_item_features['value'].fillna('NONE') \n",
    "    # 결측치 처리 후에는 모든 행이 유효하므로, .dropna()는 제거합니다.\n",
    "    \n",
    "    # 피처 이름 생성: '컬럼이름_값' (예: 'Category_프로틴', 'protein_bin_protein_mid')\n",
    "    df_item_features['feature'] = df_item_features['variable'].astype(str) + '_' + df_item_features['value'].astype(str).str.strip()\n",
    "    \n",
    "    # 최종 정리\n",
    "    df_item_features = df_item_features[[ITEM_ID_COL, 'feature']].drop_duplicates()\n",
    "    \n",
    "    print(f\"DEBUG: Item Features 총 개수 (생성된 피처 종류): {len(df_item_features['feature'].unique())}\")\n",
    "    print(f\"DEBUG: Item Features 행 개수 (상호작용): {len(df_item_features)}\")\n",
    "    \n",
    "    print(\"✅ Item Feature (정량 포함) 전처리 완료.\")\n",
    "# ---------------------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------------\n",
    "    ## 6단계: Interaction Matrix 소스 데이터 구축 (랭킹 데이터 추가 통합)\n",
    "    \n",
    "    # 기존의 INTERACTION_WEIGHT_COLS 및 새로운 RANKING_COLS_MAP을 모두 사용합니다.\n",
    "    # (INTERACTION_WEIGHT_COLS는 (제품명, 맛, 가중치) 구조를 유지한다고 가정)\n",
    "    # 우선 전해질 음료는 ELECTROLYTE 로 정의함\n",
    "    \n",
    "    RANKING_COLS_MAP = [\n",
    "        # (순위 컬럼, 가중치 컬럼, 제품군 태그, 첫 번째 항목 컬럼)\n",
    "        ('13-2) 프로틴 선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요', '13-17) 해당 프로틴에 대한 재구매 의사는 어느 정도인가요?  ', 'PROTEIN', '13-3) 프로틴의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)'),\n",
    "        ('14-2) 프리워크아웃 선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요', '14-17) 해당 프리워크아웃에 대한 재구매 의사는 어느 정도인가요?  ', 'PREWORKOUT', '14-3) 프리워크아웃의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)'),\n",
    "        ('15-2) 전해질 음료(BCAA, 이온음료)선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요', '15-17) 해당 전해질 음료에 대한 재구매 의사는 어느 정도인가요?  ', 'ELECTROLYTE', '15-3) 전해질 음료의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)'),\n",
    "        ('16-2) 게이너 선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요', '16-17) 해당 게이너에 대한 재구매 의사는 어느 정도인가요?  ', 'GAINER', '16-3) 게이너의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)')\n",
    "    ]\n",
    "    MAX_RANK_COUNT = 7 \n",
    "    # 순위의 역순으로 가중치를 부여하는 함수\n",
    "    def rank_to_weight(rank_value, max_rank=MAX_RANK_COUNT):\n",
    "        rank_value = pd.to_numeric(rank_value, errors='coerce')\n",
    "        if pd.isna(rank_value):\n",
    "            return np.nan\n",
    "        # 1순위 -> 7, 7순위 -> 1\n",
    "        return (max_rank + 1) - rank_value \n",
    "    \n",
    "    df_interactions_list = []\n",
    "    \n",
    "    # --- 1. 제품명 + 맛 기반 상호작용 (기존 로직: 랭킹 제거) ---\n",
    "    for item_col, flavor_col, weight_col in INTERACTION_WEIGHT_COLS:\n",
    "        temp_df = df_user_clean[['user_id', item_col, flavor_col, weight_col]].copy()\n",
    "        \n",
    "        temp_df.rename(columns={item_col: 'product', \n",
    "                                flavor_col: 'flavor', \n",
    "                                weight_col: 'weight'}, \n",
    "                       inplace=True)\n",
    "        \n",
    "        temp_df.dropna(subset=['product', 'flavor'], inplace=True)\n",
    "        \n",
    "        # 제품명/맛 정규화 및 item_id 생성\n",
    "        temp_df['item_id'] = temp_df.apply(lambda row: normalize_interaction_id(row['product'], row['flavor']), axis=1)\n",
    "        temp_df.drop(columns=['product', 'flavor'], inplace=True)\n",
    "        \n",
    "        # 🚨 상호작용 가중치 10배 증폭 적용\n",
    "        temp_df['weight'] = temp_df['weight'] * 10\n",
    "        \n",
    "        df_interactions_list.append(temp_df)\n",
    "    \n",
    "    \n",
    "    # --- 2. 랭킹 응답 기반 상호작용 (제거됨 - 7단계로 이동) ---\n",
    "    \n",
    "    df_interactions = pd.concat(df_interactions_list, ignore_index=True)\n",
    "    \n",
    "    df_interactions['weight'] = pd.to_numeric(df_interactions['weight'], errors='coerce')\n",
    "    \n",
    "    # Item Feature에 존재하는 유효한 Item ID만 남기고 필터링\n",
    "    valid_items = df_item_raw[ITEM_ID_COL].unique()\n",
    "    df_interactions = df_interactions[df_interactions['item_id'].isin(valid_items)]\n",
    "    \n",
    "    df_interactions.dropna(subset=['item_id', 'weight'], inplace=True)\n",
    "    \n",
    "    # Item ID와 User ID 쌍의 중복 제거 (가장 높은 가중치를 남김)\n",
    "    df_interactions.sort_values(by='weight', ascending=False, inplace=True)\n",
    "    df_interactions.drop_duplicates(subset=['user_id', 'item_id'], keep='first', inplace=True)\n",
    "    \n",
    "    print(\"✅ Interaction Matrix 소스 데이터 준비 완료. (랭킹 데이터 User Feature로 이동)\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 7단계: User Feature Matrix 구축 (★ 랭킹 데이터 통합)\n",
    "    df_user_features_list = []\n",
    "    \n",
    "    # --- 1. 일반 User Feature 처리 (기존 로직) ---\n",
    "    df_user_features_ohe = df_user_clean[['user_id'] + OHE_USER_COLS].melt(\n",
    "        id_vars='user_id', var_name='question', value_name='feature_value'\n",
    "    ).dropna(subset=['feature_value'])\n",
    "    \n",
    "    df_user_features_ohe['feature_value'] = df_user_features_ohe['feature_value'].astype(str).str.split(r'[,/]')\n",
    "    df_user_features_ohe = df_user_features_ohe.explode('feature_value')\n",
    "    df_user_features_ohe['feature'] = df_user_features_ohe['question'].astype(str) + '_' + df_user_features_ohe['feature_value'].astype(str).str.strip()\n",
    "    df_user_features_ohe['weight'] = 1.0 # OHE 피처는 가중치 1.0 유지\n",
    "    df_user_features_list.append(df_user_features_ohe[['user_id', 'feature', 'weight']].drop_duplicates())\n",
    "    \n",
    "    \n",
    "    # --- 2. 랭킹 데이터 User Feature로 통합 (새로운 로직) ---\n",
    "    for rank_col, weight_col, product_tag, feature_start_col in RANKING_COLS_MAP:\n",
    "        if rank_col in df_user_clean.columns:\n",
    "            \n",
    "            df_rank_user_feat = df_user_clean[['user_id', rank_col]].copy()\n",
    "            df_rank_user_feat.rename(columns={rank_col: 'rank_str'}, inplace=True)\n",
    "            \n",
    "            # 1. 랭킹 응답 문자열을 각 순위(1, 2, 3...)별로 분리하여 explode\n",
    "            df_rank_user_feat['rank_list'] = df_rank_user_feat['rank_str'].astype(str).str.strip().apply(list)\n",
    "            df_rank_user_feat = df_rank_user_feat.explode('rank_list')\n",
    "            \n",
    "            # 2. 응답의 순서(Index)를 계산 (1, 2, 3...)\n",
    "            df_rank_user_feat['feature_index'] = df_rank_user_feat.groupby('user_id').cumcount() \n",
    "            \n",
    "            # 3. Item Feature와 동일한 방법으로 컬럼 헤더 이름 목록 추출\n",
    "            all_cols = df_user_clean.columns.tolist()\n",
    "            try:\n",
    "                start_idx = all_cols.index(feature_start_col)\n",
    "                feature_cols_list = all_cols[start_idx : start_idx + MAX_RANK_COUNT] \n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "            index_to_col = {i: col for i, col in enumerate(feature_cols_list)}\n",
    "            \n",
    "            # 4. Feature 이름 생성 (제품군_RANK_항목헤더)\n",
    "            df_rank_user_feat['feature_header'] = df_rank_user_feat['feature_index'].map(index_to_col)\n",
    "            df_rank_user_feat['feature'] = product_tag.upper() + '_RANK_' + df_rank_user_feat['feature_header'].astype(str).str.upper()\n",
    "            \n",
    "            # 5. 가중치 계산 (순위 역변환을 가중치로 사용)\n",
    "            df_rank_user_feat['weight'] = df_rank_user_feat['rank_list'].apply(rank_to_weight) \n",
    "            \n",
    "            df_rank_user_feat.dropna(subset=['feature', 'weight'], inplace=True)\n",
    "            \n",
    "            # 최종 User Feature 데이터: user_id, feature, weight\n",
    "            df_user_features_list.append(df_rank_user_feat[['user_id', 'feature', 'weight']].drop_duplicates())\n",
    "    \n",
    "    # --- 3. 최종 User Feature 결합 ---\n",
    "    df_user_features = pd.concat(df_user_features_list, ignore_index=True)\n",
    "    df_user_features = df_user_features.drop_duplicates(subset=['user_id', 'feature'], keep='first')\n",
    "    \n",
    "    \n",
    "    print(\"✅ User Feature Matrix 소스 데이터 준비 완료. (랭킹 가중치 통합)\")\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(\"\\n--- 디버깅: 피처 데이터 상태 확인 ---\")\n",
    "    print(f\"User Features 총 개수 (Unique): {len(df_user_features['feature'].unique())}\")\n",
    "    # User Feature의 상위 10개 피처와 해당 가중치 확인\n",
    "    print(\"User Features (상위 5개):\")\n",
    "    print(df_user_features.head(5))\n",
    "    \n",
    "    print(f\"\\nItem Features 총 개수 (Unique): {len(df_item_features['feature'].unique())}\")\n",
    "    # Item Feature의 상위 10개 피처와 해당 Item ID 확인\n",
    "    print(\"Item Features (상위 5개):\")\n",
    "    print(df_item_features.head(5))\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 8단계: LightFM Dataset 구축 및 Train/Test 분리 (안정화된 수동 분리)\n",
    "    # 1. Dataset 객체 초기화 및 fit (이전과 동일)\n",
    "    dataset = Dataset()\n",
    "    dataset.fit(\n",
    "        users=df_user_clean.index.unique(),\n",
    "        items=df_item_raw[ITEM_ID_COL].unique(),\n",
    "        user_features=df_user_features['feature'].unique(),\n",
    "        item_features=df_item_features['feature'].unique()\n",
    "    )\n",
    "    \n",
    "    # 2. Total Interaction 행렬 구축 (총 상호작용 개수 확인용)\n",
    "    (interactions_all, sample_weights_all) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight'])\n",
    "        for index, row in df_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    # 3. 데이터프레임 인덱스 기반 수동 분리\n",
    "    total_indices = np.arange(len(df_interactions))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(total_indices)\n",
    "    \n",
    "    test_size = int(len(df_interactions) * 0.2)\n",
    "    train_indices = total_indices[test_size:]\n",
    "    test_indices = total_indices[:test_size]\n",
    "    \n",
    "    # 4. Train/Test 데이터프레임 분리 (인덱스 순서 유지)\n",
    "    df_train_interactions = df_interactions.iloc[train_indices].copy()\n",
    "    df_test_interactions = df_interactions.iloc[test_indices].copy()\n",
    "    \n",
    "    # 5. Train/Test 행렬 및 가중치 행렬 재구축 (오류 방지 핵심)\n",
    "    # 분리된 데이터프레임을 사용하여 build_interactions를 호출하면 순서 불일치가 발생하지 않음\n",
    "    (interactions_train, weights_train) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) \n",
    "        for index, row in df_train_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    (interactions_test, weights_test) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) \n",
    "        for index, row in df_test_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    # 6. Feature Matrix 구축 (동일)\n",
    "    user_features_matrix = dataset.build_user_features(\n",
    "        (row['user_id'], {row['feature']: row['weight']}) for index, row in df_user_features.iterrows()\n",
    "    )\n",
    "    item_features_matrix = dataset.build_item_features(\n",
    "        (row[ITEM_ID_COL], [row['feature']]) for index, row in df_item_features.iterrows()\n",
    "    )\n",
    "    \n",
    "\n",
    "    print(\"\\n--- LightFM 행렬 크기 ---\")\n",
    "    print(f\"Interaction Matrix (Total): {interactions_all.shape}\")\n",
    "    print(f\"Interaction Matrix (Train): {interactions_train.shape} / Non-zero: {interactions_train.getnnz()}\")\n",
    "    print(f\"Interaction Matrix (Test): {interactions_test.shape} / Non-zero: {interactions_test.getnnz()}\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 9단계: 모델 학습 (Train Set 사용)\n",
    "\n",
    "    model = LightFM(\n",
    "        loss='warp', \n",
    "        no_components=15,\n",
    "        learning_rate=0.03, \n",
    "        user_alpha=0,\n",
    "        item_alpha=0,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        interactions_train, \n",
    "        sample_weight=weights_train, # COO 형식으로 전달\n",
    "        user_features=user_features_matrix, \n",
    "        item_features=item_features_matrix,\n",
    "        epochs=60, \n",
    "        num_threads=4,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\nLightFM 하이브리드 추천 모델 학습 완료\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 최종 모델 구축 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdb76ef7-5729-4c65-a8d9-3c7d99488732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "             🌟 LightFM 모델 최종 평가 결과 🌟\n",
      "==================================================\n",
      "| Set   |   Precision@3 |   AUC Score |\n",
      "|:------|--------------:|------------:|\n",
      "| Train |        0.2497 |      0.9789 |\n",
      "| Test  |        0.2429 |      0.9691 |\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, interactions, user_features, item_features, name):\n",
    "    precision = precision_at_k(model, interactions, user_features=user_features, item_features=item_features, k=3).mean()\n",
    "    auc = auc_score(model, interactions, user_features=user_features, item_features=item_features).mean()\n",
    "    return {'Set': name, 'Precision@3': f\"{precision:.4f}\", 'AUC Score': f\"{auc:.4f}\"}\n",
    "\n",
    "results = [\n",
    "    evaluate_model(model, interactions_train, user_features_matrix, item_features_matrix, 'Train'),\n",
    "    evaluate_model(model, interactions_test, user_features_matrix, item_features_matrix, 'Test')\n",
    "]\n",
    "evaluation_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"             🌟 LightFM 모델 최종 평가 결과 🌟\")\n",
    "print(\"=\" * 50)\n",
    "# 'tabulate' 라이브러리 설치가 필요할 수 있습니다.\n",
    "try:\n",
    "    print(evaluation_results.to_markdown(index=False))\n",
    "except ImportError:\n",
    "    print(evaluation_results.to_string(index=False))\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12156c06-cb92-4a55-8146-afe73e5af87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 제품 메타데이터에 'timing_category' 컬럼을 카테고리 기반으로 생성 완료.\n",
      "\n",
      "\n",
      "============================================================\n",
      "       ✅ 사용자 ID 18.0에 대한 시나리오별 추천 결과 (카테고리 기반)\n",
      "============================================================\n",
      "\n",
      "--- 운동 전 (Pre-Workout) 추천 (상위 3개) ---\n",
      "| product_id        | category     | product_name                   |   Predicted_Score |\n",
      "|:------------------|:-------------|:-------------------------------|------------------:|\n",
      "| SAMDAE_PRE_ORANGE | 프리워크아웃 | 삼대오백 프리워크아웃 오렌지맛 |          -1.61604 |\n",
      "| SAMDAE_PRE_GRAPE  | 프리워크아웃 | 삼대오백 프리워크아웃 포도맛   |          -1.94001 |\n",
      "| SAMDAE_PRE_LEMON  | 프리워크아웃 | 삼대오백 프리워크아웃 레몬맛   |          -2.74836 |\n",
      "\n",
      "--- 운동 중 (Intra-Workout) 추천 (상위 3개) ---\n",
      "| product_id   | category   | product_name   | Predicted_Score   |\n",
      "|--------------|------------|----------------|-------------------|\n",
      "\n",
      "--- 운동 후 (Post-Workout) 추천 (상위 3개) ---\n",
      "| product_id                  | category   | product_name                                 |   Predicted_Score |\n",
      "|:----------------------------|:-----------|:---------------------------------------------|------------------:|\n",
      "| OPTIMUM_HYDROWHEY_CHOCOLATE | 프로틴     | 옵티멈 뉴트리션 플래티넘 하이드로웨이 초콜릿 |          0.443286 |\n",
      "| OPTIMUM_GSWHEY_CHOCOLATE    | 프로틴     | 옵티멈 뉴트리션 골드스탠다드 웨이 초콜릿맛   |          0.395144 |\n",
      "| SAMDAE_WPC_CHOCOLATE        | 프로틴     | 삼대오백 WPC 초콜렛                          |         -0.582854 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 8-1. recommend_for_user 함수 (timing_category를 결과에 포함하도록 수정)\n",
    "def recommend_for_user(user_id, model, dataset, user_features_matrix, item_features_matrix, df_item_raw, k=50):\n",
    "    \"\"\"특정 user_id에 대해 LightFM 모델 기반으로 상위 K개의 아이템을 추천합니다.\"\"\"\n",
    "    \n",
    "    user_id_map = dataset.mapping()[0]\n",
    "    item_id_map = dataset.mapping()[2]\n",
    "    item_id_rev_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "    if user_id not in user_id_map:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    user_inner_id = user_id_map[user_id]\n",
    "    n_items = interactions_train.shape[1]\n",
    "    all_item_ids = np.arange(n_items)\n",
    "    \n",
    "    scores = model.predict(\n",
    "        user_ids=[user_inner_id] * n_items,\n",
    "        item_ids=all_item_ids,\n",
    "        user_features=user_features_matrix,\n",
    "        item_features=item_features_matrix\n",
    "    )\n",
    "    \n",
    "    top_k_indices = np.argsort(-scores)[:k]\n",
    "    recommended_item_ids = [item_id_rev_map[i] for i in all_item_ids[top_k_indices]]\n",
    "    \n",
    "    recommendation_df = pd.DataFrame({\n",
    "        ITEM_ID_COL: recommended_item_ids,\n",
    "        'Predicted_Score': scores[top_k_indices]\n",
    "    })\n",
    "    \n",
    "    # ⭐ 핵심 수정: timing_category를 포함한 메타데이터와 병합\n",
    "    item_display_cols = ['category', 'product_name', 'flavor', 'timing_category'] \n",
    "    available_cols = [col for col in item_display_cols if col in df_item_raw.columns]\n",
    "    \n",
    "    final_recommendations = recommendation_df.merge(\n",
    "        df_item_raw.rename(columns={ITEM_ID_COL: ITEM_ID_COL})[available_cols + [ITEM_ID_COL]],\n",
    "        on=ITEM_ID_COL,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return final_recommendations\n",
    "\n",
    "# 8-2. 카테고리 기반 타이밍 매핑 (df_item_raw에 적용)\n",
    "def map_category_to_timing(category):\n",
    "    \"\"\"제품 카테고리를 운동 타이밍으로 매핑 (Post/Pre/Intra)\"\"\"\n",
    "    if pd.isna(category): return 'Other'\n",
    "    category_str = str(category).upper()\n",
    "    if '프로틴' in category_str or '게이너' in category_str: return 'Post'\n",
    "    elif '프리워크아웃' in category_str: return 'Pre'\n",
    "    elif '전해질' in category_str or 'BCAA' in category_str or '이온음료' in category_str: return 'Intra'\n",
    "    else: return 'Other'\n",
    "\n",
    "# df_item_raw에 'timing_category' 컬럼 생성\n",
    "if 'category' in df_item_raw.columns:\n",
    "    df_item_raw['timing_category'] = df_item_raw['category'].apply(map_category_to_timing)\n",
    "    print(\"✅ 제품 메타데이터에 'timing_category' 컬럼을 카테고리 기반으로 생성 완료.\")\n",
    "\n",
    "\n",
    "# 8-3. 필터링된 추천 결과 가져오기\n",
    "def get_filtered_recommendations(user_id, model, dataset, user_features_matrix, item_features_matrix, df_item_raw, k_total=250, timing=None, k_final=3):\n",
    "    \"\"\"\n",
    "    전체 추천 결과를 받은 후, timing_category로 필터링하여 최종 K_final 개를 반환하는 함수.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_recs = recommend_for_user(user_id, model, dataset, user_features_matrix, item_features_matrix, df_item_raw, k=k_total)\n",
    "    \n",
    "    if all_recs.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 타이밍 카테고리로 필터링\n",
    "    if timing and 'timing_category' in all_recs.columns:\n",
    "        filtered_recs = all_recs[all_recs['timing_category'] == timing].head(k_final)\n",
    "    else:\n",
    "        # 필터링 조건이 없거나 컬럼이 없는 경우, 상위 K_final만 반환\n",
    "        filtered_recs = all_recs.head(k_final)\n",
    "        \n",
    "    # 최종 출력 컬럼 정리\n",
    "    output_cols = [ITEM_ID_COL, 'category', 'product_name', 'Predicted_Score']\n",
    "    final_cols = [col for col in output_cols if col in filtered_recs.columns]\n",
    "    \n",
    "    return filtered_recs[final_cols]\n",
    "\n",
    "\n",
    "# 8-4. 타이밍별 추천 실행 및 출력\n",
    "try:\n",
    "    example_user_id = df_user_clean['user_id'].iloc[10] # 첫 번째 유효한 사용자 ID 사용\n",
    "except IndexError:\n",
    "    example_user_id = None\n",
    "\n",
    "if example_user_id is not None:\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(f\"       ✅ 사용자 ID {example_user_id}에 대한 시나리오별 추천 결과 (카테고리 기반)\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. 운동 전 추천 (Pre-Workout)\n",
    "    print(\"\\n--- 운동 전 (Pre-Workout) 추천 (상위 3개) ---\")\n",
    "    recs_pre = get_filtered_recommendations(user_id=example_user_id, model=model, dataset=dataset, user_features_matrix=user_features_matrix, item_features_matrix=item_features_matrix, df_item_raw=df_item_raw, timing='Pre', k_final=3)\n",
    "    try:\n",
    "        print(recs_pre.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_pre.to_string(index=False))\n",
    "    \n",
    "    # 2. 운동 중 추천 (Intra-Workout)\n",
    "    print(\"\\n--- 운동 중 (Intra-Workout) 추천 (상위 3개) ---\")\n",
    "    recs_intra = get_filtered_recommendations(user_id=example_user_id, model=model, dataset=dataset, user_features_matrix=user_features_matrix, item_features_matrix=item_features_matrix, df_item_raw=df_item_raw, timing='Intra', k_final=3)\n",
    "    try:\n",
    "        print(recs_intra.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_intra.to_string(index=False))\n",
    "\n",
    "    # 3. 운동 후 추천 (Post-Workout)\n",
    "    print(\"\\n--- 운동 후 (Post-Workout) 추천 (상위 3개) ---\")\n",
    "    recs_post = get_filtered_recommendations(user_id=example_user_id, model=model, dataset=dataset, user_features_matrix=user_features_matrix, item_features_matrix=item_features_matrix, df_item_raw=df_item_raw, timing='Post', k_final=3)\n",
    "    try:\n",
    "        print(recs_post.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_post.to_string(index=False))\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "else:\n",
    "    print(\"\\n유효한 사용자 ID가 없어 타이밍별 추천을 생성할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4442f1-488a-42a2-8fad-51761bb8564d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198fb48-4cdb-4de2-849e-2d7b8156f48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (LightFM Ready)",
   "language": "python",
   "name": "lightfm_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
