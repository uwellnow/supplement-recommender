{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fa7c39-1ed2-455b-8a2d-b3faff5cfe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/homebrew/Caskroom/miniforge/base/envs/lightfm_python311/lib/python3.11/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14dcb0da-7699-4b17-ade8-941279455ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lightfm_python311/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9258762-692b-48f4-b300-1350f601fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_MAIN = '[ìŠ¤íŠ¸ë¡±ë¼ì´í”„]ìµœì¢…_ë°ì´í„°_20250924.xlsx'\n",
    "\n",
    "def load_and_concatenate_user_data(file_path):\n",
    "    \"\"\"\n",
    "    1ì°¨ì™€ 2ì°¨ ì‹œíŠ¸ë¥¼ ë¡œë“œ, no/no. ì¹¼ëŸ¼ì„ í†µì¼í•œ í›„ ìˆ˜ì§ìœ¼ë¡œ í•©ì¹¨.\n",
    "    \"\"\"\n",
    "    \n",
    "    HEADER_ROW_INDEX = 0\n",
    "    \n",
    "    # 1ì°¨, 2ì°¨ ì‹œíŠ¸ ë¡œë“œ ë° í—¤ë” ì„¤ì •\n",
    "    df_1st = pd.read_excel(file_path, sheet_name='1ì°¨', header=0)\n",
    "    df_2nd = pd.read_excel(file_path, sheet_name='2ì°¨', header=0)\n",
    "\n",
    "    df_1st.columns = df_1st.columns.astype(str).str.strip()\n",
    "    df_2nd.columns = df_2nd.columns.astype(str).str.strip()\n",
    "    \n",
    "    # User ID ì¹¼ëŸ¼ ì´ë¦„ í†µì¼ ('no.' -> 'no')\n",
    "    col_to_rename = {col: 'no' for col in df_2nd.columns if isinstance(col, str) and col.strip() == 'no.'}\n",
    "    if col_to_rename:\n",
    "        df_2nd.rename(columns=col_to_rename, inplace=True)\n",
    "    \n",
    "    # ìˆ˜ì§ìœ¼ë¡œ concatenate\n",
    "    df_user_raw = pd.concat([df_1st, df_2nd], ignore_index=True)\n",
    "    df_user_raw.rename(columns={'no': 'user_id'}, inplace=True)\n",
    "    \n",
    "    return df_user_raw.set_index('user_id', drop=False)\n",
    "\n",
    "\n",
    "def clean_user_ids(df_user_raw):\n",
    "    \"\"\"\n",
    "    user_id (ì¸ë±ìŠ¤)ì—ì„œ ê²°ì¸¡ì¹˜ ë° ìœ íš¨í•˜ì§€ ì•Šì€ ì”ì—¬ í–‰ì„ ì œê±°í•˜ì—¬ user_idë¥¼ ì •ë¦¬.\n",
    "    \"\"\"\n",
    "    # ë¬¸ìì—´ 'nan'ì„ ì‹¤ì œ ê²°ì¸¡ì¹˜(NaN)ë¡œ ë³€í™˜\n",
    "    df_user_raw.index = df_user_raw.index.to_series().replace('nan', np.nan) \n",
    "    \n",
    "    # ì¸ë±ìŠ¤ ê°’ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸ (ì˜¤ë¥˜ ì‹œ NaN ì²˜ë¦¬)\n",
    "    valid_user_ids_numeric = pd.to_numeric(df_user_raw.index, errors='coerce')\n",
    "\n",
    "    # 1. user_idê°€ ê²°ì¸¡ì¹˜ê°€ ì•„ë‹ˆê³  (NaNì´ ì•„ë‹ˆê³ )\n",
    "    # 2. user_idê°€ 0ë³´ë‹¤ í° ê°’ì¸ (ìœ íš¨í•œ IDì¸) í–‰ë§Œ ì„ íƒ\n",
    "    valid_indices = df_user_raw.index[valid_user_ids_numeric.notna() & (valid_user_ids_numeric > 0)].unique()\n",
    "\n",
    "    return df_user_raw.loc[valid_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835e1cba-8fbf-4235-b4aa-3fe035ac1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì íŠ¹ì§• ë°ì´í„° concatenate\n",
      "-----------------------------------\n",
      "ì´ ì‚¬ìš©ì ìˆ˜ (ì •ë¦¬ ì „): 1037ëª…\n",
      "ë°ì´í„°í”„ë ˆì„ í¬ê¸° (ì •ë¦¬ ì „): (1038, 147)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ë°ì´í„° ë¡œë“œ ë° í•©ì¹˜ê¸°\n",
    "    df_user_raw = load_and_concatenate_user_data(FILE_PATH_MAIN)\n",
    "    \n",
    "    # user_id ì •ë¦¬ ì „ ìƒíƒœ ì¶œë ¥\n",
    "    print(\"ì‚¬ìš©ì íŠ¹ì§• ë°ì´í„° concatenate\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"ì´ ì‚¬ìš©ì ìˆ˜ (ì •ë¦¬ ì „): {df_user_raw.index.nunique()}ëª…\")\n",
    "    print(f\"ë°ì´í„°í”„ë ˆì„ í¬ê¸° (ì •ë¦¬ ì „): {df_user_raw.shape}\")\n",
    "    \n",
    "    # 3. user_id ì •ë¦¬\n",
    "    df_user_clean = clean_user_ids(df_user_raw)\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6cb9d0-214b-4ea3-b13f-392c2d68ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´í…œ íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì™„ë£Œ (df_item_raw)\n",
      "------------------------------\n",
      "\n",
      "--- df_item_raw (ì œí’ˆ íŠ¹ì§• ë°ì´í„°) ê²€ì¦ ---\n",
      "ë¡œë“œëœ Item ì¹¼ëŸ¼ ëª©ë¡: ['product_id', 'brand_name_kor', 'brand_name', 'ingredient_type', 'category', 'sub_category', 'form_factor', 'serving_size', 'serving_unit', 'servings_total', 'calories', 'protein', 'carbs', 'sugars', 'fats', 'Trans Fat', 'Saturated Fat', 'Dietary Fiber', 'ingredients', 'intake_timing', 'product_name', 'sensory_tags', 'functional_tags', 'feature_tags', 'allergens', 'Unnamed: 25']\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ ê²½ë¡œ ì •ì˜\n",
    "FILE_PATH_META = \"ì œí’ˆ ë©”íƒ€ë°ì´í„° ìµœì¢….xlsx\" # ì œí’ˆ ë©”íƒ€ë°ì´í„° íŒŒì¼\n",
    "\n",
    "# Item ID ì¹¼ëŸ¼ ì´ë¦„ í™•ì • (ì²« ë²ˆì§¸ ì¹¼ëŸ¼ì´ product_idë¼ê³  ê°€ì •)\n",
    "ITEM_ID_COL = 'product_id'\n",
    "\n",
    "try:\n",
    "    # 1. Item Feature ë°ì´í„° ë¡œë“œ (Header=0 ê°€ì •)\n",
    "    df_item_raw = pd.read_excel(FILE_PATH_META, sheet_name='ì œí’ˆ ë©”íƒ€ë°ì´í„° ìµœì¢…', header=0)\n",
    "    \n",
    "    # 2. Item ID ì¹¼ëŸ¼ ì´ë¦„ í†µì¼ ë° í™•ì¸\n",
    "    df_item_raw.rename(columns={df_item_raw.columns[0]: ITEM_ID_COL}, inplace=True)\n",
    "    \n",
    "    print(\"ì•„ì´í…œ íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì™„ë£Œ (df_item_raw)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 3. Item Data í•µì‹¬ ì¹¼ëŸ¼ í™•ì¸\n",
    "    print(\"\\n--- df_item_raw (ì œí’ˆ íŠ¹ì§• ë°ì´í„°) ê²€ì¦ ---\")\n",
    "    \n",
    "    # df_item_rawì˜ ëª¨ë“  ì¹¼ëŸ¼ì„ ì¶œë ¥í•˜ì—¬ ì¹¼ëŸ¼ ì´ë¦„ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ ìµœì¢… í™•ì¸\n",
    "    print(f\"ë¡œë“œëœ Item ì¹¼ëŸ¼ ëª©ë¡: {df_item_raw.columns.tolist()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Item Data ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e8fba2-16ca-4f43-b3ea-803f3be65180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì—‘ì…€ íŒŒì¼ ë¡œë“œ ë° ì •í™•í•œ ID ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ.\n",
      "**ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (df_align)ì€ 7ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ìœ ì§€ë©ë‹ˆë‹¤.**\n"
     ]
    }
   ],
   "source": [
    "# 2. ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ ë°ì´í„°í”„ë ˆì„ ì „ì²´ë¥¼ ë¡œë“œ (ëª¨ë“  ì»¬ëŸ¼ ìœ ì§€)\n",
    "FILE_PATH_ALIGN = \"uwellnow_product_align.xlsx\"\n",
    "try:\n",
    "    df_align = pd.read_excel(FILE_PATH_ALIGN)\n",
    "    \n",
    "    # 3. ë§¤í•‘ í‚¤ ìƒì„± ë° ë”•ì…”ë„ˆë¦¬ êµ¬ì¶•\n",
    "    # ë‘ ì»¬ëŸ¼ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ í‚¤ (Key)ë¥¼ ë§Œë“­ë‹ˆë‹¤: \"PRODUCT_FLAVOR\"\n",
    "    df_align['MAPPING_KEY'] = (df_align['product'].astype(str).str.strip().str.upper() + \n",
    "                               '_' + \n",
    "                               df_align['flavor'].astype(str).str.strip().str.upper())\n",
    "\n",
    "    # 4. ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±: {PRODUCT_FLAVOR: product_id}\n",
    "    ITEM_FULL_ID_MAP = pd.Series(\n",
    "        df_align['product_id'].astype(str).str.strip().str.upper().values,\n",
    "        index=df_align['MAPPING_KEY']\n",
    "    ).to_dict()\n",
    "\n",
    "    # ë”•ì…”ë„ˆë¦¬ì—ì„œ NaN (ê²°ì¸¡ì¹˜) ê´€ë ¨ í•­ëª©ì€ ì œê±° (ì„ íƒ ì‚¬í•­)\n",
    "    if 'NAN_NAN' in ITEM_FULL_ID_MAP:\n",
    "        del ITEM_FULL_ID_MAP['NAN_NAN']\n",
    "        \n",
    "    print(\"âœ… ì—‘ì…€ íŒŒì¼ ë¡œë“œ ë° ì •í™•í•œ ID ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ.\")\n",
    "    print(f\"**ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (df_align)ì€ {df_align.shape[1]}ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ìœ ì§€ë©ë‹ˆë‹¤.**\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ ê²½ë¡œ '{FILE_PATH_ALIGN}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    ITEM_FULL_ID_MAP = {}\n",
    "    df_align = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4603628-d843-4e77-aa4a-dcdc0d9aea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ (AC, AD ë¶„ë¦¬ëœ ê²½ìš°) ---\n",
      "('ê²Œí† ë ˆì´ íŒŒìš°ë”', 'ê²Œí† ë ˆì´ë§›') -> ['GATORADE_POWDER_LEMONLIME']\n",
      "('ì˜µí‹°ë©ˆ ì›¨ì´', 'ì´ˆì½œë¦¿, ë°”ë‹ë¼') -> ['OPTIMUM_GSWHEY_VANILLA', 'OPTIMUM_GSWHEY_CHOCOLATE']\n",
      "('ìƒˆë¡œìš´ ë‹¨ë°±ì§ˆ', 'ë°”ë‚˜ë‚˜ë§›,í‚¤ìœ„ë§›') -> ['ìƒˆë¡œìš´ë‹¨ë°±ì§ˆë°”ë‚˜ë‚˜ë§›,í‚¤ìœ„ë§›']\n"
     ]
    }
   ],
   "source": [
    "# 2) ì‚¬ìš©ì ì‘ë‹µ ì œí’ˆëª…ì„ ì •í™•í•œ product_idë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ (AC ì»¬ëŸ¼ + AD ì»¬ëŸ¼ ì‚¬ìš©)\n",
    "def normalize_interaction_id(product_name_ac, flavor_ad, mapping_dict=ITEM_FULL_ID_MAP):\n",
    "    \n",
    "    if not product_name_ac or not flavor_ad or not mapping_dict:\n",
    "        # ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê²½ìš° None ë°˜í™˜\n",
    "        return [None] \n",
    "    \n",
    "    product_clean = str(product_name_ac).strip().upper()\n",
    "    flavor_input = str(flavor_ad).strip().upper()\n",
    "    \n",
    "    # 1. ì½¤ë§ˆ(,)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§›ì„ ë¶„ë¦¬í•˜ê³ , ê³µë°±ì„ ì œê±°\n",
    "    # 'ë°”ë‹ë¼, ì´ˆì½œë¦¿' -> ['ë°”ë‹ë¼', 'ì´ˆì½œë¦¿']\n",
    "    flavor_list = [f.strip() for f in flavor_input.split(',') if f.strip()]\n",
    "    \n",
    "    found_product_ids = []\n",
    "    \n",
    "    # 2. ë¶„ë¦¬ëœ ê° ë§›ì— ëŒ€í•´ ë”•ì…”ë„ˆë¦¬ ê²€ìƒ‰ ì‹œë„\n",
    "    for flavor_clean in flavor_list:\n",
    "        # ë”•ì…”ë„ˆë¦¬ ê²€ìƒ‰ì— ì‚¬ìš©í•  ìµœì¢… í‚¤ ì¡°í•©: \"PRODUCT_FLAVOR\"\n",
    "        search_key = f\"{product_clean}_{flavor_clean}\"\n",
    "        \n",
    "        # ë”•ì…”ë„ˆë¦¬ì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if search_key in mapping_dict:\n",
    "            found_product_ids.append(mapping_dict[search_key])\n",
    "\n",
    "    # 3. ìœ íš¨í•œ IDê°€ ë°œê²¬ëœ ê²½ìš°\n",
    "    if found_product_ids:\n",
    "        # ì¤‘ë³µ ì œê±° í›„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "        return list(set(found_product_ids))\n",
    "    \n",
    "    # 4. ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš°: ì•ˆì „ ì¥ì¹˜ (ì œí’ˆëª…+ì›ë˜ ë§› ë¬¸ìì—´)ë¥¼ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "    # ì´ ë¶€ë¶„ì€ LightFM item IDë¡œ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•œ ë¬¸ìì—´ë¡œ ê°€ê³µë©ë‹ˆë‹¤.\n",
    "    combined_name = f\"{product_clean}{flavor_input}\"\n",
    "    fallback_id = combined_name.replace(' ', '').replace('-', '').replace('.', '').replace('(', '').replace(')', '')\n",
    "    return [fallback_id]\n",
    "\n",
    "\n",
    "# --- ì‚¬ìš© ì˜ˆì‹œ ---\n",
    "print(\"\\n--- ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ (AC, AD ë¶„ë¦¬ëœ ê²½ìš°) ---\")\n",
    "\n",
    "# ì˜ˆì‹œ 1: ë‹¨ì¼ ë§› (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "product_in1 = 'ê²Œí† ë ˆì´ íŒŒìš°ë”'\n",
    "flavor_in1 = 'ê²Œí† ë ˆì´ë§›'\n",
    "result1 = normalize_interaction_id(product_in1, flavor_in1, mapping_dict={'ê²Œí† ë ˆì´ íŒŒìš°ë”_ê²Œí† ë ˆì´ë§›': 'GATORADE_POWDER_LEMONLIME'})\n",
    "print(f\"('{product_in1}', '{flavor_in1}') -> {result1}\") \n",
    "# ì˜ˆìƒ ê²°ê³¼: ['GATORADE_POWDER_LEMONLIME']\n",
    "\n",
    "# ì˜ˆì‹œ 2: ë‹¤ì¤‘ ë§› í¬í•¨ (ì½¤ë§ˆë¡œ êµ¬ë¶„)\n",
    "product_in2 = 'ì˜µí‹°ë©ˆ ì›¨ì´'\n",
    "flavor_in2 = 'ì´ˆì½œë¦¿, ë°”ë‹ë¼'\n",
    "test_map = {\n",
    "    'ì˜µí‹°ë©ˆ ì›¨ì´_ì´ˆì½œë¦¿': 'OPTIMUM_GSWHEY_CHOCOLATE',\n",
    "    'ì˜µí‹°ë©ˆ ì›¨ì´_ë°”ë‹ë¼': 'OPTIMUM_GSWHEY_VANILLA',\n",
    "    'ì˜µí‹°ë©ˆ ì›¨ì´_ë”¸ê¸°': 'OPTIMUM_GSWHEY_STRAWBERRY'\n",
    "}\n",
    "result2 = normalize_interaction_id(product_in2, flavor_in2, mapping_dict=test_map)\n",
    "print(f\"('{product_in2}', '{flavor_in2}') -> {result2}\") \n",
    "# ì˜ˆìƒ ê²°ê³¼: ['OPTIMUM_GSWHEY_CHOCOLATE', 'OPTIMUM_GSWHEY_VANILLA']\n",
    "\n",
    "# ì˜ˆì‹œ 3: ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš° (ì•ˆì „ì¥ì¹˜ ë°œë™)\n",
    "product_in3 = 'ìƒˆë¡œìš´ ë‹¨ë°±ì§ˆ'\n",
    "flavor_in3 = 'ë°”ë‚˜ë‚˜ë§›,í‚¤ìœ„ë§›'\n",
    "result3 = normalize_interaction_id(product_in3, flavor_in3, mapping_dict=test_map)\n",
    "print(f\"('{product_in3}', '{flavor_in3}') -> {result3}\") \n",
    "# ì˜ˆìƒ ê²°ê³¼: ['ìƒˆë¡œìš´ë‹¨ë°±ì§ˆë°”ë‚˜ë‚˜ë§›,í‚¤ìœ„ë§›']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd1f37d-f5b6-4288-a24f-486ab970da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightFM ëª¨ë¸ë§ ë³€ìˆ˜ ì •ì˜ ---\n",
    "\n",
    "# ì‚¬ìš©ì íŠ¹ì§• (User Feature, Multi-Hot Encoding ëŒ€ìƒ)\n",
    "OHE_USER_COLS = [\n",
    "    # Feature Group 1 (ê¸°ë³¸ ì •ë³´ ë° í™œë™ íŒ¨í„´)\n",
    "    '3) ì„±ë³„', \n",
    "    '8) ìš´ë™ í™œë™ ê¸°ê°„', \n",
    "    '7) í”„ë¡œí‹´, í”„ë¦¬ì›Œí¬ì•„ì›ƒ, ì „í•´ì§ˆ ìŒë£Œ, ê²Œì´ë„ˆ ë“± í—¬ìŠ¤ ë³´ì¶©ì œ 2ì¢… ì´ìƒì„ ì„­ì·¨í•´ ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?',\n",
    "    '9) ì£¼ì— ëª‡ íšŒ ì •ë„ ìš´ë™ì„ ì§„í–‰í•˜ì‹œë‚˜ìš”?(íƒ1)',\n",
    "    '10) ì•ŒëŸ¬ì§€ ë˜ëŠ” ë¯¼ê°ì„±ë¶„(ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '11) í‰ì†Œ ì±™ê¸°ëŠ” ë¼ë‹ˆëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?(ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '12) ì‹ì‚¬ ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?(íƒ 1)',\n",
    "    '12-1) ì¼ê³¼(ìˆ˜ì—…,ì—…ë¬´,ì¼ ë“±) ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?(íƒ 1)',\n",
    "    '12-2) ìš´ë™ì„ ì œì™¸í•œ ì¼ê³¼ ì¤‘ í™œë™ì€ ì–´ëŠ ì •ë„ë¡œ í™œë°œí•œê°€ìš”?(íƒ 1)',\n",
    "    '12-3) ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œì‘ ì‹œê°„ì´ ì–¸ì œì¸ê°€ìš”?(íƒ 1)',\n",
    "    # Feature Group 2 (ì˜í–¥ ìš”ì¸ ë° ê³ ë ¤ í•­ëª©) - ëª¨ë“  ë³´ì¶©ì œ ê´€ë ¨ ê³ ë ¤ í•­ëª© í¬í•¨\n",
    "    '13-3) í”„ë¡œí‹´ì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-4) í”„ë¡œí‹´ì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '14-3) í”„ë¦¬ì›Œí¬ì•„ì›ƒì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-4) í”„ë¦¬ì›Œí¬ì•„ì›ƒì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '15-3) ì „í•´ì§ˆ ìŒë£Œì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-4) ì „í•´ì§ˆ ìŒë£Œì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '16-3) ê²Œì´ë„ˆì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-4) ê²Œì´ë„ˆì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '17-3) í•´ë‹¹ ë³´ì¶©ì œì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '17-4) í•´ë‹¹ ë³´ì¶©ì œì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?', '17-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '17-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '17-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "]\n",
    "\n",
    "# B. ì•„ì´í…œ íŠ¹ì§• (Item Feature, Multi-Hot Encoding ëŒ€ìƒ)\n",
    "OHE_ITEM_COLS = ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
    "\n",
    "# C. ìƒí˜¸ì‘ìš© (Interaction, One-Hot Encoding ëŒ€ìƒ)\n",
    "# 'ê°€ì¥ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ'ì„ Item IDë¡œ ì‚¬ìš©í•˜ê³ , 'ì¬êµ¬ë§¤ ì˜ì‚¬'ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "INTERACTION_WEIGHT_COLS = [\n",
    "    ('13-9) [í”„ë¡œí‹´] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '13-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-17) í•´ë‹¹ í”„ë¡œí‹´ì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('14-9) [í”„ë¦¬ì›Œí¬ì•„ì›ƒ] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '14-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-17) í•´ë‹¹ í”„ë¦¬ì›Œí¬ì•„ì›ƒì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('15-9) [ì „í•´ì§ˆ ìŒë£Œ(BCAA, ì´ì˜¨ìŒë£Œ)] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '15-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-17) í•´ë‹¹ ì „í•´ì§ˆ ìŒë£Œì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('16-9) [ê²Œì´ë„ˆ] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '16-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-17) í•´ë‹¹ ê²Œì´ë„ˆì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('17-9) ì¢…í•©ì ìœ¼ë¡œ ê°€ì¥ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”', '17-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”?', '17-17) í•´ë‹¹ ì œí’ˆì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e96d12-3a98-47b2-8043-16f16d45cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: OHE_ITEM_COLS ëª©ë¡: ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
      "------------------------------\n",
      "DEBUG: Item Features ì´ ê°œìˆ˜ (ìƒì„±ëœ í”¼ì²˜ ì¢…ë¥˜): 136\n",
      "DEBUG: Item Features í–‰ ê°œìˆ˜ (ìƒí˜¸ì‘ìš©): 685\n",
      "âœ… Item Feature (ê°€ì¤‘ì¹˜ í¬í•¨) ì „ì²˜ë¦¬ ì™„ë£Œ.\n",
      "âœ… Interaction Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.\n",
      "âœ… User Feature Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. (ë­í‚¹ ê°€ì¤‘ì¹˜ í†µí•©)\n",
      "\n",
      "--- 8.5ë‹¨ê³„: User Feature ê¸°ë°˜ k-NN ë°ì´í„° ë³´ê°• ì‹œì‘ ---\n",
      "âœ… ë³´ê°•ëœ ìƒí˜¸ì‘ìš© 5079ê°œ ì¶”ê°€. ìµœì¢… Interaction í–‰ ê°œìˆ˜: 4457\n",
      "\n",
      "--- LightFM í–‰ë ¬ í¬ê¸° ---\n",
      "Interaction Matrix (Total): (1037, 228)\n",
      "Interaction Matrix (Train): (1037, 228) / Non-zero: 3566\n",
      "Interaction Matrix (Test): (1037, 228) / Non-zero: 891\n",
      "\n",
      "\n",
      "LightFM í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# df_user_cleanì˜ ì¸ë±ìŠ¤ ì´ë¦„ ì •ë¦¬ (ì˜¤ë¥˜ í•´ê²°)\n",
    "if df_user_clean.index.name == 'user_id':\n",
    "    df_user_clean.index.name = None\n",
    "\n",
    "# k-NN ë¡œì§ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ ì´ˆê¸°í™” (try ë¸”ë¡ ë°–ì—ì„œ ì •ì˜)\n",
    "user_features_matrix = None\n",
    "dataset = None \n",
    "\n",
    "try:\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 5ë‹¨ê³„: Item Feature Matrix ì†ŒìŠ¤ ë°ì´í„° êµ¬ì¶• (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(f\"DEBUG: OHE_ITEM_COLS ëª©ë¡: {OHE_ITEM_COLS}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # ... (df_item_raw ì •ë¦¬ ë° selected_ohe_cols ì •ì˜ ë¡œì§ì€ ë™ì¼)\n",
    "    df_item_raw.dropna(subset=[ITEM_ID_COL], inplace=True) \n",
    "    selected_ohe_cols = [col for col in OHE_ITEM_COLS if col in df_item_raw.columns] \n",
    "    \n",
    "    df_item_features = df_item_raw.melt(\n",
    "        id_vars=[ITEM_ID_COL], \n",
    "        value_vars=selected_ohe_cols\n",
    "    )\n",
    "    \n",
    "    df_item_features['value'] = df_item_features['value'].fillna('NONE') \n",
    "    df_item_features['feature'] = df_item_features['variable'].astype(str) + '_' + df_item_features['value'].astype(str).str.strip()\n",
    "    \n",
    "    # ğŸŒŸ Item Feature ê°€ì¤‘ì¹˜ ë¶€ì—¬ ë¡œì§ ğŸŒŸ\n",
    "    df_item_features['weight'] = 1.0 # ê¸°ë³¸ ê°€ì¤‘ì¹˜ 1.0\n",
    "    df_item_features.loc[df_item_features['variable'] == 'category', 'weight'] = 4.0\n",
    "    df_item_features.loc[df_item_features['variable'] == 'ingredient_type', 'weight'] = 3.0\n",
    "    \n",
    "    # ğŸŒŸ ìµœì¢… ì •ë¦¬: 'weight' ì»¬ëŸ¼ì„ í¬í•¨í•˜ë„ë¡ ìˆ˜ì • ğŸŒŸ\n",
    "    df_item_features = df_item_features[[ITEM_ID_COL, 'feature', 'weight']].drop_duplicates(subset=[ITEM_ID_COL, 'feature'], keep='first')\n",
    "    \n",
    "    print(f\"DEBUG: Item Features ì´ ê°œìˆ˜ (ìƒì„±ëœ í”¼ì²˜ ì¢…ë¥˜): {len(df_item_features['feature'].unique())}\")\n",
    "    print(f\"DEBUG: Item Features í–‰ ê°œìˆ˜ (ìƒí˜¸ì‘ìš©): {len(df_item_features)}\")\n",
    "    print(\"âœ… Item Feature (ê°€ì¤‘ì¹˜ í¬í•¨) ì „ì²˜ë¦¬ ì™„ë£Œ.\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 6ë‹¨ê³„: Interaction Matrix ì†ŒìŠ¤ ë°ì´í„° êµ¬ì¶• \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    df_interactions_list = []\n",
    "    \n",
    "    # --- 1. ì œí’ˆëª… + ë§› ê¸°ë°˜ ìƒí˜¸ì‘ìš© (explode ì ìš©) ---\n",
    "    for item_col, flavor_col, weight_col in INTERACTION_WEIGHT_COLS:\n",
    "        temp_df = df_user_clean[['user_id', item_col, flavor_col, weight_col]].copy()\n",
    "        \n",
    "        temp_df.rename(columns={item_col: 'product', flavor_col: 'flavor', weight_col: 'weight'}, inplace=True)\n",
    "        temp_df.dropna(subset=['product', 'flavor'], inplace=True)\n",
    "        temp_df['item_id_list'] = temp_df.apply(lambda row: normalize_interaction_id(row['product'], row['flavor']), axis=1)\n",
    "        temp_df = temp_df.explode('item_id_list')\n",
    "        temp_df.rename(columns={'item_id_list': 'item_id'}, inplace=True)\n",
    "        temp_df.drop(columns=['product', 'flavor'], inplace=True)\n",
    "        \n",
    "        # ìƒí˜¸ì‘ìš© ê°€ì¤‘ì¹˜ 10ë°° ì¦í­ ì ìš©\n",
    "        temp_df['weight'] = pd.to_numeric(temp_df['weight'], errors='coerce') * 10\n",
    "        \n",
    "        df_interactions_list.append(temp_df)\n",
    "    \n",
    "    # --- 2. ìµœì¢… Interaction ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì •ë¦¬ ---\n",
    "    df_interactions = pd.concat(df_interactions_list, ignore_index=True)\n",
    "    df_interactions['weight'] = pd.to_numeric(df_interactions['weight'], errors='coerce')\n",
    "    \n",
    "    valid_items = df_item_raw[ITEM_ID_COL].unique()\n",
    "    df_interactions = df_interactions[df_interactions['item_id'].isin(valid_items)]\n",
    "    \n",
    "    df_interactions.dropna(subset=['item_id', 'weight'], inplace=True)\n",
    "    df_interactions.sort_values(by='weight', ascending=False, inplace=True)\n",
    "    df_interactions.drop_duplicates(subset=['user_id', 'item_id'], keep='first', inplace=True)\n",
    "    \n",
    "    print(\"âœ… Interaction Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 7ë‹¨ê³„: User Feature Matrix êµ¬ì¶• (ê°€ì¤‘ì¹˜ ê°•í™” ì ìš©)\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ëˆ„ë½ëœ ìµœì¢… df_user_features ì •ì˜ ë¡œì§ì„ í¬í•¨í–ˆìŠµë‹ˆë‹¤. ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    df_user_features_list = []\n",
    "    \n",
    "    # --- 1. ì¼ë°˜ User Feature ì²˜ë¦¬ (ê°€ì¤‘ì¹˜ ê°•í™” ë¡œì§) ---\n",
    "    HIGH_WEIGHT_USER_COLS = [\n",
    "        '7) í”„ë¡œí‹´, í”„ë¦¬ì›Œí¬ì•„ì›ƒ, ì „í•´ì§ˆ ìŒë£Œ, ê²Œì´ë„ˆ ë“± í—¬ìŠ¤ ë³´ì¶©ì œ 2ì¢… ì´ìƒì„ ì„­ì·¨í•´ ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?', \n",
    "        '8) ìš´ë™ í™œë™ ê¸°ê°„',  \n",
    "        '10) ì•ŒëŸ¬ì§€ ë˜ëŠ” ë¯¼ê°ì„±ë¶„(ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', \n",
    "        '12-1) ì¼ê³¼(ìˆ˜ì—…,ì—…ë¬´,ì¼ ë“±) ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?(íƒ 1)', \n",
    "    ]\n",
    "    \n",
    "    df_user_features_ohe = df_user_clean[['user_id'] + OHE_USER_COLS].melt(\n",
    "        id_vars='user_id', var_name='question', value_name='feature_value'\n",
    "    ).dropna(subset=['feature_value'])\n",
    "    \n",
    "    df_user_features_ohe['feature_value'] = df_user_features_ohe['feature_value'].astype(str).str.split(r'[,/]')\n",
    "    df_user_features_ohe = df_user_features_ohe.explode('feature_value')\n",
    "    df_user_features_ohe['feature'] = df_user_features_ohe['question'].astype(str) + '_' + df_user_features_ohe['feature_value'].astype(str).str.strip()\n",
    "    \n",
    "    # ğŸŒŸ ê°€ì¤‘ì¹˜ í• ë‹¹ ë¡œì§: ê¸°ë³¸ 1.0, í•µì‹¬ í”¼ì²˜ 5.0 ğŸŒŸ\n",
    "    df_user_features_ohe['weight'] = 1.0 \n",
    "    df_user_features_ohe.loc[df_user_features_ohe['question'].isin(HIGH_WEIGHT_USER_COLS), 'weight'] = 5.0\n",
    "    df_user_features_list.append(df_user_features_ohe[['user_id', 'feature', 'weight']].drop_duplicates())\n",
    "    \n",
    "    # --- 2. ë­í‚¹ ë°ì´í„° User Featureë¡œ í†µí•© (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---\n",
    "    for rank_col, weight_col, product_tag, feature_start_col in RANKING_COLS_MAP:\n",
    "        if rank_col in df_user_clean.columns:\n",
    "            df_rank_user_feat = df_user_clean[['user_id', rank_col]].copy()\n",
    "            # ... (ë­í‚¹ ì²˜ë¦¬ ë¡œì§ ìƒëµ) ...\n",
    "            df_rank_user_feat.rename(columns={rank_col: 'rank_str'}, inplace=True)\n",
    "            df_rank_user_feat['rank_list'] = df_rank_user_feat['rank_str'].astype(str).str.strip().apply(list)\n",
    "            df_rank_user_feat = df_rank_user_feat.explode('rank_list')\n",
    "            df_rank_user_feat['feature_index'] = df_rank_user_feat.groupby('user_id').cumcount()\n",
    "            all_cols = df_user_clean.columns.tolist()\n",
    "            try: start_idx = all_cols.index(feature_start_col)\n",
    "            except ValueError: continue\n",
    "            feature_cols_list = all_cols[start_idx : start_idx + MAX_RANK_COUNT]\n",
    "            index_to_col = {i: col for i, col in enumerate(feature_cols_list)}\n",
    "            df_rank_user_feat['feature_header'] = df_rank_user_feat['feature_index'].map(index_to_col)\n",
    "            df_rank_user_feat['feature'] = product_tag.upper() + '_RANK_' + df_rank_user_feat['feature_header'].astype(str).str.upper()\n",
    "            df_rank_user_feat['weight'] = df_rank_user_feat['rank_list'].apply(rank_to_weight)\n",
    "            df_rank_user_feat.dropna(subset=['feature', 'weight'], inplace=True)\n",
    "            df_user_features_list.append(df_rank_user_feat[['user_id', 'feature', 'weight']].drop_duplicates())\n",
    "\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ìµœì¢… df_user_features ì •ì˜ ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    df_user_features = pd.concat(df_user_features_list, ignore_index=True)\n",
    "    df_user_features = df_user_features.drop_duplicates(subset=['user_id', 'feature'], keep='first')\n",
    "    \n",
    "    print(\"âœ… User Feature Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. (ë­í‚¹ ê°€ì¤‘ì¹˜ í†µí•©)\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 8ë‹¨ê³„: LightFM Dataset ë° Feature í–‰ë ¬ êµ¬ì¶• \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    \n",
    "    # 1. Dataset ê°ì²´ ì´ˆê¸°í™” ë° fit\n",
    "    dataset = Dataset()\n",
    "    dataset.fit(\n",
    "        users=df_user_clean.index.unique(),\n",
    "        items=df_item_raw[ITEM_ID_COL].unique(),\n",
    "        user_features=df_user_features['feature'].unique(),\n",
    "        item_features=df_item_features['feature'].unique()\n",
    "    )\n",
    "    \n",
    "    # 2. Feature Matrix êµ¬ì¶• (k-NN ë³´ê°•ì„ ìœ„í•´ ë°˜ë“œì‹œ ë¨¼ì € êµ¬ì¶•ë˜ì–´ì•¼ í•¨)\n",
    "    user_features_matrix = dataset.build_user_features(\n",
    "        (row['user_id'], {row['feature']: row['weight']}) for index, row in df_user_features.iterrows()\n",
    "    )\n",
    "    # ğŸŒŸ Item Feature êµ¬ì¶• ì‹œì—ë„ ê°€ì¤‘ì¹˜ ì‚¬ìš© ğŸŒŸ\n",
    "    item_features_matrix = dataset.build_item_features(\n",
    "        (row[ITEM_ID_COL], {row['feature']: row['weight']}) for index, row in df_item_features.iterrows()\n",
    "    )\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ 8.5ë‹¨ê³„: k-NN ê¸°ë°˜ Interaction ë°ì´í„° ë³´ê°• (ìœ„ì¹˜ ìˆ˜ì • ì™„ë£Œ) ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(\"\\n--- 8.5ë‹¨ê³„: User Feature ê¸°ë°˜ k-NN ë°ì´í„° ë³´ê°• ì‹œì‘ ---\")\n",
    "    \n",
    "    K_NEIGHBORS = 5\n",
    "    user_feature_data = user_features_matrix.tocsr() \n",
    "    knn_model = NearestNeighbors(n_neighbors=K_NEIGHBORS + 1, metric='cosine', n_jobs=-1) \n",
    "    knn_model.fit(user_feature_data) \n",
    "    distances, indices = knn_model.kneighbors(user_feature_data)\n",
    "    user_id_rev_map = {v: k for k, v in dataset.mapping()[0].items()}\n",
    "    \n",
    "    new_interactions_list = []\n",
    "    for i in range(user_feature_data.shape[0]):\n",
    "        current_user_id = user_id_rev_map[i]\n",
    "        for k in range(1, K_NEIGHBORS + 1):\n",
    "            neighbor_inner_id = indices[i, k]\n",
    "            if neighbor_inner_id not in user_id_rev_map: continue \n",
    "            neighbor_id = user_id_rev_map[neighbor_inner_id]\n",
    "            \n",
    "            neighbor_recs = df_interactions[df_interactions['user_id'] == neighbor_id].copy()\n",
    "            if neighbor_recs.empty: continue\n",
    "                \n",
    "            neighbor_recs['user_id'] = current_user_id \n",
    "            similarity = 1 - distances[i, k]\n",
    "            decay_factor = 0.2 * similarity \n",
    "            neighbor_recs['weight'] = neighbor_recs['weight'] * decay_factor\n",
    "            new_interactions_list.append(neighbor_recs)\n",
    "\n",
    "    if new_interactions_list:\n",
    "        df_augmented_interactions = pd.concat(new_interactions_list, ignore_index=True)\n",
    "        # ğŸŒŸ df_interactionsë¥¼ ë³´ê°•ëœ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ğŸŒŸ\n",
    "        df_interactions = pd.concat([df_interactions, df_augmented_interactions], ignore_index=True)\n",
    "        df_interactions.sort_values(by='weight', ascending=False, inplace=True)\n",
    "        df_interactions.drop_duplicates(subset=['user_id', 'item_id'], keep='first', inplace=True)\n",
    "        print(f\"âœ… ë³´ê°•ëœ ìƒí˜¸ì‘ìš© {len(df_augmented_interactions)}ê°œ ì¶”ê°€. ìµœì¢… Interaction í–‰ ê°œìˆ˜: {len(df_interactions)}\")\n",
    "    else:\n",
    "        print(\"âŒ k-NN ë³´ê°• ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ [ì¬ì‹¤í–‰]: Train/Test ë¶„ë¦¬ ë° í–‰ë ¬ êµ¬ì¶• (ë³´ê°•ëœ ë°ì´í„° ì‚¬ìš©) ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    \n",
    "    # 1. Total Interaction í–‰ë ¬ êµ¬ì¶• (ë³´ê°•ëœ df_interactions ì‚¬ìš©)\n",
    "    (interactions_all, sample_weights_all) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) for index, row in df_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    # 2. ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ ê¸°ë°˜ ìˆ˜ë™ ë¶„ë¦¬ (ë³´ê°•ëœ df_interactions ì‚¬ìš©)\n",
    "    total_indices = np.arange(len(df_interactions))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(total_indices)\n",
    "    \n",
    "    test_size = int(len(df_interactions) * 0.2)\n",
    "    df_train_interactions = df_interactions.iloc[total_indices[test_size:]].copy()\n",
    "    df_test_interactions = df_interactions.iloc[total_indices[:test_size]].copy()\n",
    "    \n",
    "    # 3. Train/Test í–‰ë ¬ ë° ê°€ì¤‘ì¹˜ í–‰ë ¬ ì¬êµ¬ì¶•\n",
    "    (interactions_train, weights_train) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) for index, row in df_train_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    (interactions_test, weights_test) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) for index, row in df_test_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(\"\\n--- LightFM í–‰ë ¬ í¬ê¸° ---\")\n",
    "    print(f\"Interaction Matrix (Total): {interactions_all.shape}\")\n",
    "    print(f\"Interaction Matrix (Train): {interactions_train.shape} / Non-zero: {interactions_train.getnnz()}\")\n",
    "    print(f\"Interaction Matrix (Test): {interactions_test.shape} / Non-zero: {interactions_test.getnnz()}\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 9ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ (Train Set ì‚¬ìš©)\n",
    "    model = LightFM(\n",
    "        loss='warp', \n",
    "        no_components=40,\n",
    "        learning_rate=0.03, \n",
    "        user_alpha=0.001,\n",
    "        item_alpha=0.0001,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        interactions_train, \n",
    "        sample_weight=weights_train,\n",
    "        user_features=user_features_matrix, \n",
    "        item_features=item_features_matrix,\n",
    "        epochs=50, \n",
    "        num_threads=4,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\nLightFM í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "except Exception as e:\n",
    "    # ğŸŒŸ ë””ë²„ê¹…ì„ ìœ„í•´ Exception ëŒ€ì‹  print(e)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ğŸŒŸ\n",
    "    print(f\"âŒ ìµœì¢… ëª¨ë¸ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb76ef7-5729-4c65-a8d9-3c7d99488732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "             ğŸŒŸ LightFM ëª¨ë¸ ìµœì¢… í‰ê°€ ê²°ê³¼ ğŸŒŸ\n",
      "==================================================\n",
      "| Set   |   Precision@3 |   AUC Score |\n",
      "|:------|--------------:|------------:|\n",
      "| Train |        0.489  |      0.9786 |\n",
      "| Test  |        0.2005 |      0.9659 |\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "def evaluate_model(model, interactions, user_features, item_features, name):\n",
    "    precision = precision_at_k(model, interactions, user_features=user_features, item_features=item_features, k=3).mean()\n",
    "    auc = auc_score(model, interactions, user_features=user_features, item_features=item_features).mean()\n",
    "    return {'Set': name, 'Precision@3': f\"{precision:.4f}\", 'AUC Score': f\"{auc:.4f}\"}\n",
    "\n",
    "results = [\n",
    "    evaluate_model(model, interactions_train, user_features_matrix, item_features_matrix, 'Train'),\n",
    "    evaluate_model(model, interactions_test, user_features_matrix, item_features_matrix, 'Test')\n",
    "]\n",
    "evaluation_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"             ğŸŒŸ LightFM ëª¨ë¸ ìµœì¢… í‰ê°€ ê²°ê³¼ ğŸŒŸ\")\n",
    "print(\"=\" * 50)\n",
    "# 'tabulate' ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "try:\n",
    "    print(evaluation_results.to_markdown(index=False))\n",
    "except ImportError:\n",
    "    print(evaluation_results.to_string(index=False))\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# precision@3: (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì— ì‹¤ì œ ì„ í˜¸í•˜ëŠ” ì œí’ˆ)/(ëª¨ë¸ ì˜ˆì¸¡)\n",
    "# => ì‹¤ì œ ìƒí˜¸ì‘ìš©ì´ ë„ˆë¬´ ì ì–´ì„œ ì ê²Œ ë‚˜ì˜¤ëŠ” ê²ƒì´ ë‹¹ì—°í•¨.\n",
    "# ë°˜ë©´ AUC: ê¸ì •ì  ìƒí˜¸ì‘ìš©(ì‹¤ì œ ì„ í˜¸)ì„ ë¶€ì •ì  ìƒí˜¸ì‘ìš©(ë¬´ì‘ìœ„ ë¹„ì„ í˜¸)ë³´ë‹¤ ë†’ì€ ìˆœìœ„ë¡œ ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12156c06-cb92-4a55-8146-afe73e5af87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì œí’ˆ ë©”íƒ€ë°ì´í„°ì— 'timing_category' ì»¬ëŸ¼ì„ **intake_timing** ê¸°ë°˜ìœ¼ë¡œ ìƒì„± ì™„ë£Œ.\n",
      "\n",
      "\n",
      "============================================================\n",
      "       âœ… ì‚¬ìš©ì ID 184ì— ëŒ€í•œ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ ê²°ê³¼ (intake_timing ê¸°ë°˜)\n",
      "============================================================\n",
      "\n",
      "--- ğŸ‹ï¸ ìš´ë™ ì „ (Pre-Workout) ì¶”ì²œ (ìƒìœ„ 3ê°œ) ---\n",
      "| product_id                | category     | product_name                          |   Predicted_Score |\n",
      "|:--------------------------|:-------------|:--------------------------------------|------------------:|\n",
      "| BSN_NOX_FRUITPUNCH        | í”„ë¦¬ì›Œí¬ì•„ì›ƒ | ë…¸ìµìŠ¤í”Œë¡œë“œ í›„ë¥´ì¸ í€ì¹˜               |          -3.83188 |\n",
      "| ANIMAL_PRIMAL_FRUITSPUNCH | í”„ë¦¬ì›Œí¬ì•„ì›ƒ | ì• ë‹ˆë©€ í”„ë¼ì´ë©€ í”„ë¦¬ì›Œí¬ì•„ì›ƒ ê³¼ì¼í€ì¹˜ |          -4.07776 |\n",
      "| RAW_ESSENTIAL_ORANGE      | í”„ë¦¬ì›Œí¬ì•„ì›ƒ | CBUM ì—ì„¼ì…œ í”„ë¦¬ ì›Œí¬ì•„ì›ƒ ì˜¤ë Œì§€      |          -4.28615 |\n",
      "\n",
      "--- ğŸ’§ ìš´ë™ ì¤‘ (Intra-Workout) ì¶”ì²œ (ìƒìœ„ 3ê°œ) ---\n",
      "| product_id             | category       | product_name                   |   Predicted_Score |\n",
      "|:-----------------------|:---------------|:-------------------------------|------------------:|\n",
      "| GATORADE_POWDER_ORANGE | ì¸íŠ¸ë¼ì›Œí¬ì•„ì›ƒ | ê²Œí† ë ˆì´ íŒŒìš°ë” ì˜¤ë Œì§€         |         -0.953812 |\n",
      "| XTEND_EAA_BLOODORANGE  | ì¸íŠ¸ë¼ì›Œí¬ì•„ì›ƒ | ì—‘ìŠ¤í…ë“œ EAA ë¸”ëŸ¬ë“œ ì˜¤ë Œì§€     |         -1.92309  |\n",
      "| GATORADE_GLACIERFREEZE | ì¸íŠ¸ë¼ì›Œí¬ì•„ì›ƒ | ê²Œí† ë ˆì´ íŒŒìš°ë” ê¸€ë˜ì‹œì–´í”„ë¦¬ì¦ˆ |         -2.04404  |\n",
      "\n",
      "--- ğŸ’ª ìš´ë™ í›„ (Post-Workout) ì¶”ì²œ (ìƒìœ„ 3ê°œ) ---\n",
      "| product_id                  | category   | product_name                                 |   Predicted_Score |\n",
      "|:----------------------------|:-----------|:---------------------------------------------|------------------:|\n",
      "| OPTIMUM_GSWHEY_CHOCOLATE    | í”„ë¡œí‹´     | ì˜µí‹°ë©ˆ ë‰´íŠ¸ë¦¬ì…˜ ê³¨ë“œìŠ¤íƒ ë‹¤ë“œ ì›¨ì´ ì´ˆì½œë¦¿ë§›   |          -1.3528  |\n",
      "| OPTIMUM_HYDROWHEY_CHOCOLATE | í”„ë¡œí‹´     | ì˜µí‹°ë©ˆ ë‰´íŠ¸ë¦¬ì…˜ í”Œë˜í‹°ë„˜ í•˜ì´ë“œë¡œì›¨ì´ ì´ˆì½œë¦¿ |          -1.60607 |\n",
      "| SAMDAE_WPC_CHOCOLATE        | í”„ë¡œí‹´     | ì‚¼ëŒ€ì˜¤ë°± WPC ì´ˆì½œë ›                          |          -2.25369 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# 8-2. [ìˆ˜ì •] intake_timing ì»¬ëŸ¼ ê¸°ë°˜ìœ¼ë¡œ íƒ€ì´ë° ë§¤í•‘ (df_item_rawì— ì ìš©)\n",
    "# ---------------------------------------------------------------------------------\n",
    "def map_intake_timing(intake_timing_value):\n",
    "    \"\"\"'intake_timing' ì»¬ëŸ¼ ê°’ì„ ìš´ë™ íƒ€ì´ë° (Post/Pre/Intra) ë¦¬ìŠ¤íŠ¸ë¡œ ë§¤í•‘\"\"\"\n",
    "    if pd.isna(intake_timing_value):\n",
    "        return ['Other']\n",
    "    \n",
    "    timing_str = str(intake_timing_value).strip()\n",
    "    \n",
    "    # ğŸŒŸ ì´ ì œí’ˆì´ í¬í•¨ë  ìˆ˜ ìˆëŠ” ëª¨ë“  íƒ€ì´ë° ì¹´í…Œê³ ë¦¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ğŸŒŸ\n",
    "    timing_list = []\n",
    "    \n",
    "    # ìˆœì„œì— ìƒê´€ì—†ì´ ëª¨ë“  í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸\n",
    "    if 'ìš´ë™ í›„' in timing_str:\n",
    "        timing_list.append('Post')\n",
    "    if 'ìš´ë™ ì „' in timing_str:\n",
    "        timing_list.append('Pre')\n",
    "    if 'ìš´ë™ ì¤‘' in timing_str:\n",
    "        timing_list.append('Intra')\n",
    "        \n",
    "    # ì•„ë¬´ê²ƒë„ í•´ë‹¹ë˜ì§€ ì•Šìœ¼ë©´ 'Other'ë¡œ ë¶„ë¥˜\n",
    "    if not timing_list:\n",
    "        return ['Other']\n",
    "        \n",
    "    return timing_list\n",
    "\n",
    "# df_item_rawì— 'timing_category' ì»¬ëŸ¼ì„ 'intake_timing' ê¸°ì¤€ìœ¼ë¡œ ìƒì„±\n",
    "if 'intake_timing' in df_item_raw.columns:\n",
    "    df_item_raw['timing_category'] = df_item_raw['intake_timing'].apply(map_intake_timing)\n",
    "    print(\"âœ… ì œí’ˆ ë©”íƒ€ë°ì´í„°ì— 'timing_category' ì»¬ëŸ¼ì„ **intake_timing** ê¸°ë°˜ìœ¼ë¡œ ìƒì„± ì™„ë£Œ.\")\n",
    "    \n",
    "    # ğŸŒŸ ë””ë²„ê¹…ìš©: íƒ€ì´ë°ë³„ ì œí’ˆ ê°œìˆ˜ í™•ì¸ (ì„ íƒ ì‚¬í•­)\n",
    "    # print(\"íƒ€ì´ë°ë³„ ë¶„ë¥˜ëœ ì œí’ˆ ê°œìˆ˜:\")\n",
    "    # print(df_item_raw['timing_category'].value_counts())\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ì˜¤ë¥˜: df_item_rawì— 'intake_timing' ì»¬ëŸ¼ì´ ì—†ì–´ íƒ€ì´ë°ë³„ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    # ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´, ê¸°ì¡´ category ê¸°ë°˜ ë¡œì§ì„ ì‚¬ìš©í•˜ë„ë¡ ëŒ€ì²´ (ì„ íƒ ì‚¬í•­)\n",
    "    # df_item_raw['timing_category'] = df_item_raw['category'].apply(lambda x: ...)\n",
    "    exit() # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì¤‘ë‹¨\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 8-1. recommend_for_user í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# ì´ í•¨ìˆ˜ëŠ” ì´ë¯¸ 'timing_category'ë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •ë˜ì—ˆìœ¼ë¯€ë¡œ ë³€ê²½ ë¶ˆí•„ìš”.\n",
    "def recommend_for_user(user_id, model, dataset, user_features_matrix, item_features_matrix, df_item_raw, k=250):\n",
    "    \"\"\"íŠ¹ì • user_idì— ëŒ€í•´ LightFM ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ìƒìœ„ Kê°œì˜ ì•„ì´í…œì„ ì¶”ì²œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    user_id_map = dataset.mapping()[0]\n",
    "    item_id_map = dataset.mapping()[2]\n",
    "    item_id_rev_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "    if user_id not in user_id_map:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    user_inner_id = user_id_map[user_id]\n",
    "    n_items = interactions_train.shape[1]\n",
    "    all_item_ids = np.arange(n_items)\n",
    "    \n",
    "    scores = model.predict(\n",
    "        user_ids=[user_inner_id] * n_items,\n",
    "        item_ids=all_item_ids,\n",
    "        user_features=user_features_matrix,\n",
    "        item_features=item_features_matrix\n",
    "    )\n",
    "    \n",
    "    top_k_indices = np.argsort(-scores)[:k]\n",
    "    recommended_item_ids = [item_id_rev_map[i] for i in all_item_ids[top_k_indices]]\n",
    "    \n",
    "    recommendation_df = pd.DataFrame({\n",
    "        ITEM_ID_COL: recommended_item_ids,\n",
    "        'Predicted_Score': scores[top_k_indices]\n",
    "    })\n",
    "    \n",
    "    # timing_categoryë¥¼ í¬í•¨í•œ ë©”íƒ€ë°ì´í„°ì™€ ë³‘í•©\n",
    "    item_display_cols = ['category', 'product_name', 'flavor', 'timing_category']\n",
    "    available_cols = [col for col in item_display_cols if col in df_item_raw.columns]\n",
    "    \n",
    "    final_recommendations = recommendation_df.merge(\n",
    "        df_item_raw.rename(columns={ITEM_ID_COL: ITEM_ID_COL})[available_cols + [ITEM_ID_COL]],\n",
    "        on=ITEM_ID_COL,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return final_recommendations\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 8-3. í•„í„°ë§ëœ ì¶”ì²œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)\n",
    "# ---------------------------------------------------------------------------------\n",
    "def get_filtered_recommendations(user_id, model, dataset, user_features_matrix, item_features_matrix, df_item_raw, k_total=250, timing=None, k_final=3):\n",
    "    \"\"\"\n",
    "    ì „ì²´ ì¶”ì²œ ê²°ê³¼ë¥¼ ë°›ì€ í›„, timing_category (ë¦¬ìŠ¤íŠ¸)ë¡œ í•„í„°ë§í•˜ì—¬ ìµœì¢… K_final ê°œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_recs = recommend_for_user(user_id, model, dataset, user_features_matrix, item_features_matrix, df_item_raw, k=k_total)\n",
    "    \n",
    "    if all_recs.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # íƒ€ì´ë° ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ (ğŸŒŸ ë¦¬ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ í™•ì¸ ë¡œì§ìœ¼ë¡œ ìˆ˜ì • ğŸŒŸ)\n",
    "    if timing and 'timing_category' in all_recs.columns:\n",
    "        \n",
    "        # 'timing_category'ê°€ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ, í•´ë‹¹ ë¦¬ìŠ¤íŠ¸ ì•ˆì— 'timing' ê°’ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¡œì§\n",
    "        filtered_recs = all_recs[all_recs['timing_category'].apply(lambda x: timing in x if isinstance(x, list) else x == timing)].head(k_final)\n",
    "    else:\n",
    "        filtered_recs = all_recs.head(k_final)\n",
    "        \n",
    "    # ìµœì¢… ì¶œë ¥ ì»¬ëŸ¼ ì •ë¦¬ (ë³€ê²½ ì—†ìŒ)\n",
    "    output_cols = [ITEM_ID_COL, 'category', 'product_name', 'Predicted_Score']\n",
    "    final_cols = [col for col in output_cols if col in filtered_recs.columns]\n",
    "    \n",
    "    return filtered_recs[final_cols]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 8-4. íƒ€ì´ë°ë³„ ì¶”ì²œ ì‹¤í–‰ ë° ì¶œë ¥ (ì‚¬ìš©ì IDë¥¼ 2.0ìœ¼ë¡œ ê³ ì •í•˜ì—¬ ì¬ì‹¤í–‰)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# ì´ì „ ì´ë¯¸ì§€ì—ì„œ ì‚¬ìš©ëœ '2.0' (í˜¹ì€ í•´ë‹¹ ì¸ë±ìŠ¤) ì‚¬ìš©ìë¥¼ ì¬í˜„í•©ë‹ˆë‹¤.\n",
    "# df_user_clean.indexê°€ ë¬¸ìì—´ '2.0'ì„ í¬í•¨í•œë‹¤ê³  ê°€ì •í•˜ê³ , ì¸ë±ìŠ¤ë¥¼ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "example_user_id = 184\n",
    "\n",
    "if example_user_id in df_user_clean.index:\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(f\"       âœ… ì‚¬ìš©ì ID {example_user_id}ì— ëŒ€í•œ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ ê²°ê³¼ (intake_timing ê¸°ë°˜)\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. ìš´ë™ ì „ ì¶”ì²œ (Pre-Workout)\n",
    "    print(\"\\n--- ğŸ‹ï¸ ìš´ë™ ì „ (Pre-Workout) ì¶”ì²œ (ìƒìœ„ 3ê°œ) ---\")\n",
    "    recs_pre = get_filtered_recommendations(user_id=example_user_id, model=model, dataset=dataset, user_features_matrix=user_features_matrix, item_features_matrix=item_features_matrix, df_item_raw=df_item_raw, timing='Pre', k_final=3)\n",
    "    try:\n",
    "        print(recs_pre.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_pre.to_string(index=False))\n",
    "    \n",
    "    # 2. ìš´ë™ ì¤‘ ì¶”ì²œ (Intra-Workout)\n",
    "    print(\"\\n--- ğŸ’§ ìš´ë™ ì¤‘ (Intra-Workout) ì¶”ì²œ (ìƒìœ„ 3ê°œ) ---\")\n",
    "    recs_intra = get_filtered_recommendations(user_id=example_user_id, model=model, dataset=dataset, user_features_matrix=user_features_matrix, item_features_matrix=item_features_matrix, df_item_raw=df_item_raw, timing='Intra', k_final=3)\n",
    "    try:\n",
    "        print(recs_intra.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_intra.to_string(index=False))\n",
    "\n",
    "    # 3. ìš´ë™ í›„ ì¶”ì²œ (Post-Workout)\n",
    "    print(\"\\n--- ğŸ’ª ìš´ë™ í›„ (Post-Workout) ì¶”ì²œ (ìƒìœ„ 3ê°œ) ---\")\n",
    "    recs_post = get_filtered_recommendations(user_id=example_user_id, model=model, dataset=dataset, user_features_matrix=user_features_matrix, item_features_matrix=item_features_matrix, df_item_raw=df_item_raw, timing='Post', k_final=3)\n",
    "    try:\n",
    "        print(recs_post.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_post.to_string(index=False))\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "else:\n",
    "    print(f\"\\nìœ íš¨í•œ ì‚¬ìš©ì ID({example_user_id})ê°€ ì—†ì–´ íƒ€ì´ë°ë³„ ì¶”ì²œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645444d-288e-4e80-93e7-654826c2c8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (LightFM Ready)",
   "language": "python",
   "name": "lightfm_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
