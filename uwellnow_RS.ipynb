{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dcb0da-7699-4b17-ade8-941279455ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/lightfm_python311/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9258762-692b-48f4-b300-1350f601fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_MAIN = '[ìŠ¤íŠ¸ë¡±ë¼ì´í”„]ìµœì¢…_ë°ì´í„°_20250924.xlsx'\n",
    "\n",
    "def load_and_concatenate_user_data(file_path):\n",
    "    \"\"\"\n",
    "    1ì°¨ì™€ 2ì°¨ ì‹œíŠ¸ë¥¼ ë¡œë“œ, no/no. ì¹¼ëŸ¼ì„ í†µì¼í•œ í›„ ìˆ˜ì§ìœ¼ë¡œ í•©ì¹¨.\n",
    "    \"\"\"\n",
    "    \n",
    "    HEADER_ROW_INDEX = 0\n",
    "    \n",
    "    # 1ì°¨, 2ì°¨ ì‹œíŠ¸ ë¡œë“œ ë° í—¤ë” ì„¤ì •\n",
    "    df_1st = pd.read_excel(file_path, sheet_name='1ì°¨', header=0)\n",
    "    df_2nd = pd.read_excel(file_path, sheet_name='2ì°¨', header=0)\n",
    "\n",
    "    df_1st.columns = df_1st.columns.astype(str).str.strip()\n",
    "    df_2nd.columns = df_2nd.columns.astype(str).str.strip()\n",
    "    \n",
    "    # User ID ì¹¼ëŸ¼ ì´ë¦„ í†µì¼ ('no.' -> 'no')\n",
    "    col_to_rename = {col: 'no' for col in df_2nd.columns if isinstance(col, str) and col.strip() == 'no.'}\n",
    "    if col_to_rename:\n",
    "        df_2nd.rename(columns=col_to_rename, inplace=True)\n",
    "    \n",
    "    # ìˆ˜ì§ìœ¼ë¡œ concatenate\n",
    "    df_user_raw = pd.concat([df_1st, df_2nd], ignore_index=True)\n",
    "    df_user_raw.rename(columns={'no': 'user_id'}, inplace=True)\n",
    "    \n",
    "    return df_user_raw.set_index('user_id', drop=False)\n",
    "\n",
    "\n",
    "def clean_user_ids(df_user_raw):\n",
    "    \"\"\"\n",
    "    user_id (ì¸ë±ìŠ¤)ì—ì„œ ê²°ì¸¡ì¹˜ ë° ìœ íš¨í•˜ì§€ ì•Šì€ ì”ì—¬ í–‰ì„ ì œê±°í•˜ì—¬ user_idë¥¼ ì •ë¦¬.\n",
    "    \"\"\"\n",
    "    # ë¬¸ìì—´ 'nan'ì„ ì‹¤ì œ ê²°ì¸¡ì¹˜(NaN)ë¡œ ë³€í™˜\n",
    "    df_user_raw.index = df_user_raw.index.to_series().replace('nan', np.nan) \n",
    "    \n",
    "    # ì¸ë±ìŠ¤ ê°’ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸ (ì˜¤ë¥˜ ì‹œ NaN ì²˜ë¦¬)\n",
    "    valid_user_ids_numeric = pd.to_numeric(df_user_raw.index, errors='coerce')\n",
    "\n",
    "    # 1. user_idê°€ ê²°ì¸¡ì¹˜ê°€ ì•„ë‹ˆê³  (NaNì´ ì•„ë‹ˆê³ )\n",
    "    # 2. user_idê°€ 0ë³´ë‹¤ í° ê°’ì¸ (ìœ íš¨í•œ IDì¸) í–‰ë§Œ ì„ íƒ\n",
    "    valid_indices = df_user_raw.index[valid_user_ids_numeric.notna() & (valid_user_ids_numeric > 0)].unique()\n",
    "\n",
    "    return df_user_raw.loc[valid_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835e1cba-8fbf-4235-b4aa-3fe035ac1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì íŠ¹ì§• ë°ì´í„° concatenate\n",
      "-----------------------------------\n",
      "ì´ ì‚¬ìš©ì ìˆ˜ (ì •ë¦¬ ì „): 1037ëª…\n",
      "ë°ì´í„°í”„ë ˆì„ í¬ê¸° (ì •ë¦¬ ì „): (1038, 147)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ë°ì´í„° ë¡œë“œ ë° í•©ì¹˜ê¸°\n",
    "    df_user_raw = load_and_concatenate_user_data(FILE_PATH_MAIN)\n",
    "    \n",
    "    # user_id ì •ë¦¬ ì „ ìƒíƒœ ì¶œë ¥\n",
    "    print(\"ì‚¬ìš©ì íŠ¹ì§• ë°ì´í„° concatenate\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"ì´ ì‚¬ìš©ì ìˆ˜ (ì •ë¦¬ ì „): {df_user_raw.index.nunique()}ëª…\")\n",
    "    print(f\"ë°ì´í„°í”„ë ˆì„ í¬ê¸° (ì •ë¦¬ ì „): {df_user_raw.shape}\")\n",
    "    \n",
    "    # 3. user_id ì •ë¦¬\n",
    "    df_user_clean = clean_user_ids(df_user_raw)\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6cb9d0-214b-4ea3-b13f-392c2d68ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´í…œ íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì™„ë£Œ (df_item_raw)\n",
      "------------------------------\n",
      "\n",
      "--- df_item_raw (ì œí’ˆ íŠ¹ì§• ë°ì´í„°) ê²€ì¦ ---\n",
      "ë¡œë“œëœ Item ì¹¼ëŸ¼ ëª©ë¡: ['product_id', 'brand_name_kor', 'brand_name', 'ingredient_type', 'category', 'sub_category', 'form_factor', 'serving_size', 'serving_unit', 'servings_total', 'calories', 'protein', 'carbs', 'sugars', 'fats', 'Trans Fat', 'Saturated Fat', 'Dietary Fiber', 'ingredients', 'intake_timing', 'product_name', 'sensory_tags', 'functional_tags', 'feature_tags', 'allergens', 'Unnamed: 25']\n",
      "                            product_id  protein\n",
      "0                ANIMAL_MEAL_CHOCOLATE     46.0\n",
      "1            CBUM_MASSGAINER_CHOCOLATE     53.0\n",
      "2         CBUM_MASSGAINER_COOKIESCREAM     53.0\n",
      "3              CBUM_MASSGAINER_VANILLA     53.0\n",
      "4  GASPARI_REALMASS_CHOCOLATEMILKSHAKE     50.0\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ ê²½ë¡œ ì •ì˜\n",
    "FILE_PATH_META = \"ì œí’ˆ ë©”íƒ€ë°ì´í„° ìµœì¢….xlsx\" # ì œí’ˆ ë©”íƒ€ë°ì´í„° íŒŒì¼\n",
    "\n",
    "# Item ID ì¹¼ëŸ¼ ì´ë¦„ í™•ì • (ì²« ë²ˆì§¸ ì¹¼ëŸ¼ì´ product_idë¼ê³  ê°€ì •)\n",
    "ITEM_ID_COL = 'product_id' \n",
    "PROTEIN_COL = 'protein' # ë‹¨ë°±ì§ˆ ì •ëŸ‰ ì¹¼ëŸ¼\n",
    "\n",
    "try:\n",
    "    # 1. Item Feature ë°ì´í„° ë¡œë“œ (Header=0 ê°€ì •)\n",
    "    df_item_raw = pd.read_excel(FILE_PATH_META, sheet_name='ì œí’ˆ ë©”íƒ€ë°ì´í„° ìµœì¢…', header=0)\n",
    "    \n",
    "    # 2. Item ID ì¹¼ëŸ¼ ì´ë¦„ í†µì¼ ë° í™•ì¸\n",
    "    df_item_raw.rename(columns={df_item_raw.columns[0]: ITEM_ID_COL}, inplace=True)\n",
    "    \n",
    "    print(\"ì•„ì´í…œ íŠ¹ì§• ë°ì´í„° ë¡œë“œ ì™„ë£Œ (df_item_raw)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 3. Item Data í•µì‹¬ ì¹¼ëŸ¼ í™•ì¸\n",
    "    print(\"\\n--- df_item_raw (ì œí’ˆ íŠ¹ì§• ë°ì´í„°) ê²€ì¦ ---\")\n",
    "    \n",
    "    # Item IDì™€ ë‹¨ë°±ì§ˆ ì •ëŸ‰ ì¹¼ëŸ¼ë§Œ ì¶œë ¥í•˜ì—¬ í™•ì¸\n",
    "    display_item_cols = [ITEM_ID_COL, PROTEIN_COL]\n",
    "    \n",
    "    # df_item_rawì˜ ëª¨ë“  ì¹¼ëŸ¼ì„ ì¶œë ¥í•˜ì—¬ ì¹¼ëŸ¼ ì´ë¦„ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ ìµœì¢… í™•ì¸\n",
    "    print(f\"ë¡œë“œëœ Item ì¹¼ëŸ¼ ëª©ë¡: {df_item_raw.columns.tolist()}\")\n",
    "    \n",
    "    print(df_item_raw[df_item_raw.columns.intersection(display_item_cols)].head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Item Data ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4603628-d843-4e77-aa4a-dcdc0d9aea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ (AC, AD ë¶„ë¦¬ëœ ê²½ìš°) ---\n",
      "('ê²Œí† ë ˆì´ íŒŒìš°ë”', 'ê²Œí† ë ˆì´ë§›') -> GATORADE_POWDER_LEMONLIME\n",
      "('ìƒˆë¡œìš´ ë‹¨ë°±ì§ˆ', 'ë°”ë‚˜ë‚˜ë§›') -> ìƒˆë¡œìš´ë‹¨ë°±ì§ˆë°”ë‚˜ë‚˜ë§›\n"
     ]
    }
   ],
   "source": [
    "# 2) ì‚¬ìš©ì ì‘ë‹µ ì œí’ˆëª…ì„ ì •í™•í•œ product_idë¡œ ë§¤í•‘í•˜ëŠ” í•¨ìˆ˜ (AC ì»¬ëŸ¼ + AD ì»¬ëŸ¼ ì‚¬ìš©)\n",
    "def normalize_interaction_id(product_name_ac, flavor_ad, mapping_dict=ITEM_FULL_ID_MAP):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì‘ë‹µ (ì œí’ˆëª…ê³¼ ë§›)ì„ ë”•ì…”ë„ˆë¦¬ í‚¤ë¡œ ì¡°í•©í•˜ì—¬ ì •í™•í•œ product_idë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        product_name_ac (str): AC ì»¬ëŸ¼ì˜ ì œí’ˆëª… (ì˜ˆ: 'BSN ì‹ íƒ€-6 ì›¨ì´')\n",
    "        flavor_ad (str): AD ì»¬ëŸ¼ì˜ ë§› (ì˜ˆ: 'ì´ˆì½”ë§›')\n",
    "        mapping_dict (dict): {PRODUCT_FLAVOR: product_id} í˜•íƒœì˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "    Returns:\n",
    "        str: ë§¤í•‘ëœ product_id ë˜ëŠ” ì •ì œëœ ëŒ€ì²´ ë¬¸ìì—´\n",
    "    \"\"\"\n",
    "    if not product_name_ac or not flavor_ad or not mapping_dict:\n",
    "        return None \n",
    "    \n",
    "    # 1. ë‘ ì…ë ¥ê°’ì„ ì •ì œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ í‚¤ í˜•íƒœë¡œ ë³€í™˜: \"PRODUCT_FLAVOR\"\n",
    "    product_clean = str(product_name_ac).strip().upper()\n",
    "    flavor_clean = str(flavor_ad).strip().upper()\n",
    "    \n",
    "    # ë”•ì…”ë„ˆë¦¬ ê²€ìƒ‰ì— ì‚¬ìš©í•  ìµœì¢… í‚¤ ì¡°í•©\n",
    "    search_key = f\"{product_clean}_{flavor_clean}\"\n",
    "    \n",
    "    # 2. ë”•ì…”ë„ˆë¦¬ì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "    if search_key in mapping_dict:\n",
    "        return mapping_dict[search_key]\n",
    "\n",
    "    # 3. ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš°, ë‘ ì´ë¦„ì„ í•©ì³ì„œ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•œ ë¬¸ìì—´ì„ ë°˜í™˜ (ì•ˆì „ì¥ì¹˜)\n",
    "    # ë‘ ì¸ìë¥¼ í•©ì¹˜ê¸° ë•Œë¬¸ì—, ë² ì´ìŠ¤ ID ë§¤í•‘ í•¨ìˆ˜ì™€ëŠ” ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    combined_name = f\"{product_clean}{flavor_clean}\"\n",
    "    return combined_name.replace(' ', '').replace('-', '').replace('.', '').replace('(', '').replace(')', '')\n",
    "\n",
    "\n",
    "# --- ì‚¬ìš© ì˜ˆì‹œ ---\n",
    "print(\"\\n--- ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš© ì˜ˆì‹œ (AC, AD ë¶„ë¦¬ëœ ê²½ìš°) ---\")\n",
    "\n",
    "# ì˜ˆì‹œ 1: ì—‘ì…€ íŒŒì¼ì— 'ê²Œí† ë ˆì´ íŒŒìš°ë”_ê²Œí† ë ˆì´ë§›'ìœ¼ë¡œ ë§¤í•‘ëœ ê²½ìš°\n",
    "# (ê°€ì •: GATORADE_POWDER_LEMONLIMEì´ ë§¤í•‘ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)\n",
    "product_in = 'ê²Œí† ë ˆì´ íŒŒìš°ë”'\n",
    "flavor_in = 'ê²Œí† ë ˆì´ë§›'\n",
    "result1 = normalize_interaction_id(product_in, flavor_in)\n",
    "print(f\"('{product_in}', '{flavor_in}') -> {result1}\") \n",
    "# ì˜ˆìƒ ê²°ê³¼: GATORADE_POWDER_LEMONLIME\n",
    "\n",
    "# ì˜ˆì‹œ 2: ì—‘ì…€ íŒŒì¼ì— ì—†ëŠ” ì œí’ˆì˜ ê²½ìš°\n",
    "product_in = 'ìƒˆë¡œìš´ ë‹¨ë°±ì§ˆ'\n",
    "flavor_in = 'ë°”ë‚˜ë‚˜ë§›'\n",
    "result2 = normalize_interaction_id(product_in, flavor_in)\n",
    "print(f\"('{product_in}', '{flavor_in}') -> {result2}\") \n",
    "# ì˜ˆìƒ ê²°ê³¼: ìƒˆë¡œìš´ë‹¨ë°±ì§ˆë°”ë‚˜ë‚˜ë§›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e8fba2-16ca-4f43-b3ea-803f3be65180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì—‘ì…€ íŒŒì¼ ë¡œë“œ ë° ì •í™•í•œ ID ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ.\n",
      "**ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (df_align)ì€ 7ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ìœ ì§€ë©ë‹ˆë‹¤.**\n"
     ]
    }
   ],
   "source": [
    "# 2. ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ ë°ì´í„°í”„ë ˆì„ ì „ì²´ë¥¼ ë¡œë“œ (ëª¨ë“  ì»¬ëŸ¼ ìœ ì§€)\n",
    "FILE_PATH_ALIGN = \"uwellnow_product_align.xlsx\"\n",
    "try:\n",
    "    df_align = pd.read_excel(FILE_PATH_ALIGN)\n",
    "    \n",
    "    # 3. ë§¤í•‘ í‚¤ ìƒì„± ë° ë”•ì…”ë„ˆë¦¬ êµ¬ì¶•\n",
    "    # ë‘ ì»¬ëŸ¼ì„ ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ í‚¤ (Key)ë¥¼ ë§Œë“­ë‹ˆë‹¤: \"PRODUCT_FLAVOR\"\n",
    "    df_align['MAPPING_KEY'] = (df_align['product'].astype(str).str.strip().str.upper() + \n",
    "                               '_' + \n",
    "                               df_align['flavor'].astype(str).str.strip().str.upper())\n",
    "\n",
    "    # 4. ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±: {PRODUCT_FLAVOR: product_id}\n",
    "    # Seriesë¥¼ ì‚¬ìš©í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë§Œë“­ë‹ˆë‹¤. (ì¤‘ë³µëœ í‚¤ê°€ ìˆë‹¤ë©´ ì²« ë²ˆì§¸ ê°’ì„ ì‚¬ìš©)\n",
    "    ITEM_FULL_ID_MAP = pd.Series(\n",
    "        df_align['product_id'].astype(str).str.strip().str.upper().values,\n",
    "        index=df_align['MAPPING_KEY']\n",
    "    ).to_dict()\n",
    "\n",
    "    # ë”•ì…”ë„ˆë¦¬ì—ì„œ NaN (ê²°ì¸¡ì¹˜) ê´€ë ¨ í•­ëª©ì€ ì œê±° (ì„ íƒ ì‚¬í•­)\n",
    "    if 'NAN_NAN' in ITEM_FULL_ID_MAP:\n",
    "        del ITEM_FULL_ID_MAP['NAN_NAN']\n",
    "        \n",
    "    print(\"âœ… ì—‘ì…€ íŒŒì¼ ë¡œë“œ ë° ì •í™•í•œ ID ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ.\")\n",
    "    print(f\"**ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (df_align)ì€ {df_align.shape[1]}ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë©”ëª¨ë¦¬ì— ìœ ì§€ë©ë‹ˆë‹¤.**\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: íŒŒì¼ ê²½ë¡œ '{FILE_PATH_ALIGN}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    ITEM_FULL_ID_MAP = {}\n",
    "    df_align = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd1f37d-f5b6-4288-a24f-486ab970da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightFM ëª¨ë¸ë§ ë³€ìˆ˜ ì •ì˜ ---\n",
    "\n",
    "# ì‚¬ìš©ì íŠ¹ì§• (User Feature, Multi-Hot Encoding ëŒ€ìƒ)\n",
    "OHE_USER_COLS = [\n",
    "    # Feature Group 1 (ê¸°ë³¸ ì •ë³´ ë° í™œë™ íŒ¨í„´)\n",
    "    '3) ì„±ë³„', \n",
    "    '8) ìš´ë™ í™œë™ ê¸°ê°„', \n",
    "    '7) í”„ë¡œí‹´, í”„ë¦¬ì›Œí¬ì•„ì›ƒ, ì „í•´ì§ˆ ìŒë£Œ, ê²Œì´ë„ˆ ë“± í—¬ìŠ¤ ë³´ì¶©ì œ 2ì¢… ì´ìƒì„ ì„­ì·¨í•´ ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?',\n",
    "    '9) ì£¼ì— ëª‡ íšŒ ì •ë„ ìš´ë™ì„ ì§„í–‰í•˜ì‹œë‚˜ìš”?(íƒ1)',\n",
    "    '10) ì•ŒëŸ¬ì§€ ë˜ëŠ” ë¯¼ê°ì„±ë¶„(ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '11) í‰ì†Œ ì±™ê¸°ëŠ” ë¼ë‹ˆëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?(ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '12) ì‹ì‚¬ ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?(íƒ 1)',\n",
    "    '12-1) ì¼ê³¼(ìˆ˜ì—…,ì—…ë¬´,ì¼ ë“±) ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?(íƒ 1)',\n",
    "    '12-2) ìš´ë™ì„ ì œì™¸í•œ ì¼ê³¼ ì¤‘ í™œë™ì€ ì–´ëŠ ì •ë„ë¡œ í™œë°œí•œê°€ìš”?(íƒ 1)',\n",
    "    '12-3) ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìš´ë™ ì‹œì‘ ì‹œê°„ì´ ì–¸ì œì¸ê°€ìš”?(íƒ 1)',\n",
    "    # Feature Group 2 (ì˜í–¥ ìš”ì¸ ë° ê³ ë ¤ í•­ëª©) - ëª¨ë“  ë³´ì¶©ì œ ê´€ë ¨ ê³ ë ¤ í•­ëª© í¬í•¨\n",
    "    '13-3) í”„ë¡œí‹´ì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-4) í”„ë¡œí‹´ì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '14-3) í”„ë¦¬ì›Œí¬ì•„ì›ƒì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-4) í”„ë¦¬ì›Œí¬ì•„ì›ƒì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '15-3) ì „í•´ì§ˆ ìŒë£Œì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-4) ì „í•´ì§ˆ ìŒë£Œì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '16-3) ê²Œì´ë„ˆì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-4) ê²Œì´ë„ˆì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "    '17-3) í•´ë‹¹ ë³´ì¶©ì œì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '17-4) í•´ë‹¹ ë³´ì¶©ì œì˜ íš¨ê³¼ì—ì„œ ê³ ë ¤í•œ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?', '17-5) ë¸Œëœë“œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '17-6) ìœ ëª…ì¸(ì„ ìˆ˜ ë˜ëŠ” ì „ë¬¸ê°€)ì˜ ì‚¬ìš© ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '17-7) ì§€ì¸ì˜ ì‚¬ìš©ì—¬ë¶€ ë˜ëŠ” ì¶”ì²œì—ì„œ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)',\n",
    "]\n",
    "\n",
    "# B. ì•„ì´í…œ íŠ¹ì§• (Item Feature, Multi-Hot Encoding ëŒ€ìƒ)\n",
    "OHE_ITEM_COLS = ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
    "\n",
    "# C. ìƒí˜¸ì‘ìš© (Interaction, One-Hot Encoding ëŒ€ìƒ)\n",
    "# 'ê°€ì¥ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ'ì„ Item IDë¡œ ì‚¬ìš©í•˜ê³ , 'ì¬êµ¬ë§¤ ì˜ì‚¬'ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "INTERACTION_WEIGHT_COLS = [\n",
    "    ('13-9) [í”„ë¡œí‹´] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '13-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '13-17) í•´ë‹¹ í”„ë¡œí‹´ì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('14-9) [í”„ë¦¬ì›Œí¬ì•„ì›ƒ] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '14-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '14-17) í•´ë‹¹ í”„ë¦¬ì›Œí¬ì•„ì›ƒì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('15-9) [ì „í•´ì§ˆ ìŒë£Œ(BCAA, ì´ì˜¨ìŒë£Œ)] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '15-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '15-17) í•´ë‹¹ ì „í•´ì§ˆ ìŒë£Œì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('16-9) [ê²Œì´ë„ˆ] ì„ íƒí•˜ì‹  ì œí’ˆì¤‘ì— ê°€ì¥ ì¢…í•©ì ìœ¼ë¡œ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš” (íƒ 1)', '16-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”? (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)', '16-17) í•´ë‹¹ ê²Œì´ë„ˆì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "    ('17-9) ì¢…í•©ì ìœ¼ë¡œ ê°€ì¥ ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆ 1ê°œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”', '17-10) ë§ˆìŒì— ë“¤ì—ˆë˜ ì œí’ˆì´ ì–´ë–¤ ë§›ì¸ê°€ìš”?', '17-17) í•´ë‹¹ ì œí’ˆì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e96d12-3a98-47b2-8043-16f16d45cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: OHE_ITEM_COLS ëª©ë¡: ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
      "------------------------------\n",
      "DEBUG: Item Features ì´ ê°œìˆ˜ (ìƒì„±ëœ í”¼ì²˜ ì¢…ë¥˜): 90\n",
      "DEBUG: Item Features í–‰ ê°œìˆ˜ (ìƒí˜¸ì‘ìš©): 489\n",
      "âœ… Item Feature (ì •ëŸ‰ í¬í•¨) ì „ì²˜ë¦¬ ì™„ë£Œ.\n",
      "âœ… Interaction Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. (ë­í‚¹ ë°ì´í„° User Featureë¡œ ì´ë™)\n",
      "âœ… User Feature Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. (ë­í‚¹ ê°€ì¤‘ì¹˜ í†µí•©)\n",
      "\n",
      "--- ë””ë²„ê¹…: í”¼ì²˜ ë°ì´í„° ìƒíƒœ í™•ì¸ ---\n",
      "User Features ì´ ê°œìˆ˜ (Unique): 448\n",
      "User Features (ìƒìœ„ 5ê°œ):\n",
      "   user_id   feature  weight\n",
      "0      2.0  3) ì„±ë³„_ë‚¨ì„±     1.0\n",
      "1      4.0  3) ì„±ë³„_ì—¬ì„±     1.0\n",
      "2      5.0  3) ì„±ë³„_ì—¬ì„±     1.0\n",
      "3      6.0  3) ì„±ë³„_ì—¬ì„±     1.0\n",
      "4      7.0  3) ì„±ë³„_ì—¬ì„±     1.0\n",
      "\n",
      "Item Features ì´ ê°œìˆ˜ (Unique): 90\n",
      "Item Features (ìƒìœ„ 5ê°œ):\n",
      "                            product_id              feature\n",
      "0                ANIMAL_MEAL_CHOCOLATE  ingredient_type_ì£¼ì›ë£Œ\n",
      "1            CBUM_MASSGAINER_CHOCOLATE  ingredient_type_ì£¼ì›ë£Œ\n",
      "2         CBUM_MASSGAINER_COOKIESCREAM  ingredient_type_ì£¼ì›ë£Œ\n",
      "3              CBUM_MASSGAINER_VANILLA  ingredient_type_ì£¼ì›ë£Œ\n",
      "4  GASPARI_REALMASS_CHOCOLATEMILKSHAKE  ingredient_type_ì£¼ì›ë£Œ\n",
      "\n",
      "--- LightFM í–‰ë ¬ í¬ê¸° ---\n",
      "Interaction Matrix (Total): (1037, 122)\n",
      "Interaction Matrix (Train): (1037, 122) / Non-zero: 280\n",
      "Interaction Matrix (Test): (1037, 122) / Non-zero: 70\n",
      "\n",
      "\n",
      "LightFM í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# df_user_cleanì˜ ì¸ë±ìŠ¤ ì´ë¦„ ì •ë¦¬ (ì˜¤ë¥˜ í•´ê²°)\n",
    "if df_user_clean.index.name == 'user_id':\n",
    "    df_user_clean.index.name = None\n",
    "\n",
    "try:\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # ğŸš¨ ë””ë²„ê¹…ì„ ìœ„í•´ OHE_ITEM_COLSì— ì–´ë–¤ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    print(f\"DEBUG: OHE_ITEM_COLS ëª©ë¡: {OHE_ITEM_COLS}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # ë‹¨ë°±ì§ˆ ì •ëŸ‰ ì²˜ë¦¬ ë° ì´ì‚°í™” (Binning)\n",
    "    df_item_raw[PROTEIN_COL] = pd.to_numeric(df_item_raw[PROTEIN_COL], errors='coerce')\n",
    "    df_item_raw.dropna(subset=[PROTEIN_COL, ITEM_ID_COL], inplace=True)\n",
    "    bins = [0, 15, 25, df_item_raw[PROTEIN_COL].max() + 1]\n",
    "    labels = ['protein_low', 'protein_mid', 'protein_high']\n",
    "    df_item_raw['protein_bin'] = pd.cut(df_item_raw[PROTEIN_COL], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Item Feature Long í¬ë§· ìƒì„±\n",
    "    selected_ohe_cols = [col for col in OHE_ITEM_COLS + ['protein_bin'] if col in df_item_raw.columns]\n",
    "    \n",
    "    df_item_features = df_item_raw.melt(\n",
    "        id_vars=[ITEM_ID_COL], \n",
    "        value_vars=selected_ohe_cols\n",
    "    )\n",
    "    \n",
    "    # ğŸš¨ ê²°ì¸¡ì¹˜(NaN)ë¥¼ 'NONE' í”¼ì²˜ë¡œ ëŒ€ì²´í•˜ì—¬ ë°ì´í„° ì†ì‹¤ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "    df_item_features['value'] = df_item_features['value'].fillna('NONE') \n",
    "    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í›„ì—ëŠ” ëª¨ë“  í–‰ì´ ìœ íš¨í•˜ë¯€ë¡œ, .dropna()ëŠ” ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    # í”¼ì²˜ ì´ë¦„ ìƒì„±: 'ì»¬ëŸ¼ì´ë¦„_ê°’' (ì˜ˆ: 'Category_í”„ë¡œí‹´', 'protein_bin_protein_mid')\n",
    "    df_item_features['feature'] = df_item_features['variable'].astype(str) + '_' + df_item_features['value'].astype(str).str.strip()\n",
    "    \n",
    "    # ìµœì¢… ì •ë¦¬\n",
    "    df_item_features = df_item_features[[ITEM_ID_COL, 'feature']].drop_duplicates()\n",
    "    \n",
    "    print(f\"DEBUG: Item Features ì´ ê°œìˆ˜ (ìƒì„±ëœ í”¼ì²˜ ì¢…ë¥˜): {len(df_item_features['feature'].unique())}\")\n",
    "    print(f\"DEBUG: Item Features í–‰ ê°œìˆ˜ (ìƒí˜¸ì‘ìš©): {len(df_item_features)}\")\n",
    "    \n",
    "    print(\"âœ… Item Feature (ì •ëŸ‰ í¬í•¨) ì „ì²˜ë¦¬ ì™„ë£Œ.\")\n",
    "# ---------------------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------------\n",
    "    ## 6ë‹¨ê³„: Interaction Matrix ì†ŒìŠ¤ ë°ì´í„° êµ¬ì¶• (ë­í‚¹ ë°ì´í„° ì¶”ê°€ í†µí•©)\n",
    "    \n",
    "    # ê¸°ì¡´ì˜ INTERACTION_WEIGHT_COLS ë° ìƒˆë¡œìš´ RANKING_COLS_MAPì„ ëª¨ë‘ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    # (INTERACTION_WEIGHT_COLSëŠ” (ì œí’ˆëª…, ë§›, ê°€ì¤‘ì¹˜) êµ¬ì¡°ë¥¼ ìœ ì§€í•œë‹¤ê³  ê°€ì •)\n",
    "    # ìš°ì„  ì „í•´ì§ˆ ìŒë£ŒëŠ” ELECTROLYTE ë¡œ ì •ì˜í•¨\n",
    "    \n",
    "    RANKING_COLS_MAP = [\n",
    "        # (ìˆœìœ„ ì»¬ëŸ¼, ê°€ì¤‘ì¹˜ ì»¬ëŸ¼, ì œí’ˆêµ° íƒœê·¸, ì²« ë²ˆì§¸ í•­ëª© ì»¬ëŸ¼)\n",
    "        ('13-2) í”„ë¡œí‹´ ì„ íƒ ì‹œ ê°€ì¥ ì˜í–¥ì„ ë§ì´ ë°›ì€ ìš”ì†Œë“¤ì˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”', '13-17) í•´ë‹¹ í”„ë¡œí‹´ì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?  ', 'PROTEIN', '13-3) í”„ë¡œí‹´ì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)'),\n",
    "        ('14-2) í”„ë¦¬ì›Œí¬ì•„ì›ƒ ì„ íƒ ì‹œ ê°€ì¥ ì˜í–¥ì„ ë§ì´ ë°›ì€ ìš”ì†Œë“¤ì˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”', '14-17) í•´ë‹¹ í”„ë¦¬ì›Œí¬ì•„ì›ƒì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?  ', 'PREWORKOUT', '14-3) í”„ë¦¬ì›Œí¬ì•„ì›ƒì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)'),\n",
    "        ('15-2) ì „í•´ì§ˆ ìŒë£Œ(BCAA, ì´ì˜¨ìŒë£Œ)ì„ íƒ ì‹œ ê°€ì¥ ì˜í–¥ì„ ë§ì´ ë°›ì€ ìš”ì†Œë“¤ì˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”', '15-17) í•´ë‹¹ ì „í•´ì§ˆ ìŒë£Œì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?  ', 'ELECTROLYTE', '15-3) ì „í•´ì§ˆ ìŒë£Œì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)'),\n",
    "        ('16-2) ê²Œì´ë„ˆ ì„ íƒ ì‹œ ê°€ì¥ ì˜í–¥ì„ ë§ì´ ë°›ì€ ìš”ì†Œë“¤ì˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”', '16-17) í•´ë‹¹ ê²Œì´ë„ˆì— ëŒ€í•œ ì¬êµ¬ë§¤ ì˜ì‚¬ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?  ', 'GAINER', '16-3) ê²Œì´ë„ˆì˜ ì˜ì–‘ì„±ë¶„ì„ ê³ ë ¤í•œ ì„¸ë¶€ í•­ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš” (ë³µìˆ˜ì„ íƒ ê°€ëŠ¥)')\n",
    "    ]\n",
    "    MAX_RANK_COUNT = 7 \n",
    "    # ìˆœìœ„ì˜ ì—­ìˆœìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” í•¨ìˆ˜\n",
    "    def rank_to_weight(rank_value, max_rank=MAX_RANK_COUNT):\n",
    "        rank_value = pd.to_numeric(rank_value, errors='coerce')\n",
    "        if pd.isna(rank_value):\n",
    "            return np.nan\n",
    "        # 1ìˆœìœ„ -> 7, 7ìˆœìœ„ -> 1\n",
    "        return (max_rank + 1) - rank_value \n",
    "    \n",
    "    df_interactions_list = []\n",
    "    \n",
    "    # --- 1. ì œí’ˆëª… + ë§› ê¸°ë°˜ ìƒí˜¸ì‘ìš© (ê¸°ì¡´ ë¡œì§: ë­í‚¹ ì œê±°) ---\n",
    "    for item_col, flavor_col, weight_col in INTERACTION_WEIGHT_COLS:\n",
    "        temp_df = df_user_clean[['user_id', item_col, flavor_col, weight_col]].copy()\n",
    "        \n",
    "        temp_df.rename(columns={item_col: 'product', \n",
    "                                flavor_col: 'flavor', \n",
    "                                weight_col: 'weight'}, \n",
    "                       inplace=True)\n",
    "        \n",
    "        temp_df.dropna(subset=['product', 'flavor'], inplace=True)\n",
    "        \n",
    "        # ì œí’ˆëª…/ë§› ì •ê·œí™” ë° item_id ìƒì„±\n",
    "        temp_df['item_id'] = temp_df.apply(lambda row: normalize_interaction_id(row['product'], row['flavor']), axis=1)\n",
    "        temp_df.drop(columns=['product', 'flavor'], inplace=True)\n",
    "        \n",
    "        # ğŸš¨ ìƒí˜¸ì‘ìš© ê°€ì¤‘ì¹˜ 10ë°° ì¦í­ ì ìš©\n",
    "        temp_df['weight'] = temp_df['weight'] * 10\n",
    "        \n",
    "        df_interactions_list.append(temp_df)\n",
    "    \n",
    "    \n",
    "    # --- 2. ë­í‚¹ ì‘ë‹µ ê¸°ë°˜ ìƒí˜¸ì‘ìš© (ì œê±°ë¨ - 7ë‹¨ê³„ë¡œ ì´ë™) ---\n",
    "    \n",
    "    df_interactions = pd.concat(df_interactions_list, ignore_index=True)\n",
    "    \n",
    "    df_interactions['weight'] = pd.to_numeric(df_interactions['weight'], errors='coerce')\n",
    "    \n",
    "    # Item Featureì— ì¡´ì¬í•˜ëŠ” ìœ íš¨í•œ Item IDë§Œ ë‚¨ê¸°ê³  í•„í„°ë§\n",
    "    valid_items = df_item_raw[ITEM_ID_COL].unique()\n",
    "    df_interactions = df_interactions[df_interactions['item_id'].isin(valid_items)]\n",
    "    \n",
    "    df_interactions.dropna(subset=['item_id', 'weight'], inplace=True)\n",
    "    \n",
    "    # Item IDì™€ User ID ìŒì˜ ì¤‘ë³µ ì œê±° (ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë‚¨ê¹€)\n",
    "    df_interactions.sort_values(by='weight', ascending=False, inplace=True)\n",
    "    df_interactions.drop_duplicates(subset=['user_id', 'item_id'], keep='first', inplace=True)\n",
    "    \n",
    "    print(\"âœ… Interaction Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. (ë­í‚¹ ë°ì´í„° User Featureë¡œ ì´ë™)\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 7ë‹¨ê³„: User Feature Matrix êµ¬ì¶• (â˜… ë­í‚¹ ë°ì´í„° í†µí•©)\n",
    "    df_user_features_list = []\n",
    "    \n",
    "    # --- 1. ì¼ë°˜ User Feature ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§) ---\n",
    "    df_user_features_ohe = df_user_clean[['user_id'] + OHE_USER_COLS].melt(\n",
    "        id_vars='user_id', var_name='question', value_name='feature_value'\n",
    "    ).dropna(subset=['feature_value'])\n",
    "    \n",
    "    df_user_features_ohe['feature_value'] = df_user_features_ohe['feature_value'].astype(str).str.split(r'[,/]')\n",
    "    df_user_features_ohe = df_user_features_ohe.explode('feature_value')\n",
    "    df_user_features_ohe['feature'] = df_user_features_ohe['question'].astype(str) + '_' + df_user_features_ohe['feature_value'].astype(str).str.strip()\n",
    "    df_user_features_ohe['weight'] = 1.0 # OHE í”¼ì²˜ëŠ” ê°€ì¤‘ì¹˜ 1.0 ìœ ì§€\n",
    "    df_user_features_list.append(df_user_features_ohe[['user_id', 'feature', 'weight']].drop_duplicates())\n",
    "    \n",
    "    \n",
    "    # --- 2. ë­í‚¹ ë°ì´í„° User Featureë¡œ í†µí•© (ìƒˆë¡œìš´ ë¡œì§) ---\n",
    "    for rank_col, weight_col, product_tag, feature_start_col in RANKING_COLS_MAP:\n",
    "        if rank_col in df_user_clean.columns:\n",
    "            \n",
    "            df_rank_user_feat = df_user_clean[['user_id', rank_col]].copy()\n",
    "            df_rank_user_feat.rename(columns={rank_col: 'rank_str'}, inplace=True)\n",
    "            \n",
    "            # 1. ë­í‚¹ ì‘ë‹µ ë¬¸ìì—´ì„ ê° ìˆœìœ„(1, 2, 3...)ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ explode\n",
    "            df_rank_user_feat['rank_list'] = df_rank_user_feat['rank_str'].astype(str).str.strip().apply(list)\n",
    "            df_rank_user_feat = df_rank_user_feat.explode('rank_list')\n",
    "            \n",
    "            # 2. ì‘ë‹µì˜ ìˆœì„œ(Index)ë¥¼ ê³„ì‚° (1, 2, 3...)\n",
    "            df_rank_user_feat['feature_index'] = df_rank_user_feat.groupby('user_id').cumcount() \n",
    "            \n",
    "            # 3. Item Featureì™€ ë™ì¼í•œ ë°©ë²•ìœ¼ë¡œ ì»¬ëŸ¼ í—¤ë” ì´ë¦„ ëª©ë¡ ì¶”ì¶œ\n",
    "            all_cols = df_user_clean.columns.tolist()\n",
    "            try:\n",
    "                start_idx = all_cols.index(feature_start_col)\n",
    "                feature_cols_list = all_cols[start_idx : start_idx + MAX_RANK_COUNT] \n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "            index_to_col = {i: col for i, col in enumerate(feature_cols_list)}\n",
    "            \n",
    "            # 4. Feature ì´ë¦„ ìƒì„± (ì œí’ˆêµ°_RANK_í•­ëª©í—¤ë”)\n",
    "            df_rank_user_feat['feature_header'] = df_rank_user_feat['feature_index'].map(index_to_col)\n",
    "            df_rank_user_feat['feature'] = product_tag.upper() + '_RANK_' + df_rank_user_feat['feature_header'].astype(str).str.upper()\n",
    "            \n",
    "            # 5. ê°€ì¤‘ì¹˜ ê³„ì‚° (ìˆœìœ„ ì—­ë³€í™˜ì„ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©)\n",
    "            df_rank_user_feat['weight'] = df_rank_user_feat['rank_list'].apply(rank_to_weight) \n",
    "            \n",
    "            df_rank_user_feat.dropna(subset=['feature', 'weight'], inplace=True)\n",
    "            \n",
    "            # ìµœì¢… User Feature ë°ì´í„°: user_id, feature, weight\n",
    "            df_user_features_list.append(df_rank_user_feat[['user_id', 'feature', 'weight']].drop_duplicates())\n",
    "    \n",
    "    # --- 3. ìµœì¢… User Feature ê²°í•© ---\n",
    "    df_user_features = pd.concat(df_user_features_list, ignore_index=True)\n",
    "    df_user_features = df_user_features.drop_duplicates(subset=['user_id', 'feature'], keep='first')\n",
    "    \n",
    "    \n",
    "    print(\"âœ… User Feature Matrix ì†ŒìŠ¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. (ë­í‚¹ ê°€ì¤‘ì¹˜ í†µí•©)\")\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(\"\\n--- ë””ë²„ê¹…: í”¼ì²˜ ë°ì´í„° ìƒíƒœ í™•ì¸ ---\")\n",
    "    print(f\"User Features ì´ ê°œìˆ˜ (Unique): {len(df_user_features['feature'].unique())}\")\n",
    "    # User Featureì˜ ìƒìœ„ 10ê°œ í”¼ì²˜ì™€ í•´ë‹¹ ê°€ì¤‘ì¹˜ í™•ì¸\n",
    "    print(\"User Features (ìƒìœ„ 5ê°œ):\")\n",
    "    print(df_user_features.head(5))\n",
    "    \n",
    "    print(f\"\\nItem Features ì´ ê°œìˆ˜ (Unique): {len(df_item_features['feature'].unique())}\")\n",
    "    # Item Featureì˜ ìƒìœ„ 10ê°œ í”¼ì²˜ì™€ í•´ë‹¹ Item ID í™•ì¸\n",
    "    print(\"Item Features (ìƒìœ„ 5ê°œ):\")\n",
    "    print(df_item_features.head(5))\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 8ë‹¨ê³„: LightFM Dataset êµ¬ì¶• ë° Train/Test ë¶„ë¦¬ (ì•ˆì •í™”ëœ ìˆ˜ë™ ë¶„ë¦¬)\n",
    "    # 1. Dataset ê°ì²´ ì´ˆê¸°í™” ë° fit (ì´ì „ê³¼ ë™ì¼)\n",
    "    dataset = Dataset()\n",
    "    dataset.fit(\n",
    "        users=df_user_clean.index.unique(),\n",
    "        items=df_item_raw[ITEM_ID_COL].unique(),\n",
    "        user_features=df_user_features['feature'].unique(),\n",
    "        item_features=df_item_features['feature'].unique()\n",
    "    )\n",
    "    \n",
    "    # 2. Total Interaction í–‰ë ¬ êµ¬ì¶• (ì´ ìƒí˜¸ì‘ìš© ê°œìˆ˜ í™•ì¸ìš©)\n",
    "    (interactions_all, sample_weights_all) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight'])\n",
    "        for index, row in df_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    # 3. ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ ê¸°ë°˜ ìˆ˜ë™ ë¶„ë¦¬\n",
    "    total_indices = np.arange(len(df_interactions))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(total_indices)\n",
    "    \n",
    "    test_size = int(len(df_interactions) * 0.2)\n",
    "    train_indices = total_indices[test_size:]\n",
    "    test_indices = total_indices[:test_size]\n",
    "    \n",
    "    # 4. Train/Test ë°ì´í„°í”„ë ˆì„ ë¶„ë¦¬ (ì¸ë±ìŠ¤ ìˆœì„œ ìœ ì§€)\n",
    "    df_train_interactions = df_interactions.iloc[train_indices].copy()\n",
    "    df_test_interactions = df_interactions.iloc[test_indices].copy()\n",
    "    \n",
    "    # 5. Train/Test í–‰ë ¬ ë° ê°€ì¤‘ì¹˜ í–‰ë ¬ ì¬êµ¬ì¶• (ì˜¤ë¥˜ ë°©ì§€ í•µì‹¬)\n",
    "    # ë¶„ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì„ ì‚¬ìš©í•˜ì—¬ build_interactionsë¥¼ í˜¸ì¶œí•˜ë©´ ìˆœì„œ ë¶ˆì¼ì¹˜ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ\n",
    "    (interactions_train, weights_train) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) \n",
    "        for index, row in df_train_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    (interactions_test, weights_test) = dataset.build_interactions(\n",
    "        (row['user_id'], row['item_id'], row['weight']) \n",
    "        for index, row in df_test_interactions.iterrows()\n",
    "    )\n",
    "    \n",
    "    # 6. Feature Matrix êµ¬ì¶• (ë™ì¼)\n",
    "    user_features_matrix = dataset.build_user_features(\n",
    "        (row['user_id'], {row['feature']: row['weight']}) for index, row in df_user_features.iterrows()\n",
    "    )\n",
    "    item_features_matrix = dataset.build_item_features(\n",
    "        (row[ITEM_ID_COL], [row['feature']]) for index, row in df_item_features.iterrows()\n",
    "    )\n",
    "    \n",
    "\n",
    "    print(\"\\n--- LightFM í–‰ë ¬ í¬ê¸° ---\")\n",
    "    print(f\"Interaction Matrix (Total): {interactions_all.shape}\")\n",
    "    print(f\"Interaction Matrix (Train): {interactions_train.shape} / Non-zero: {interactions_train.getnnz()}\")\n",
    "    print(f\"Interaction Matrix (Test): {interactions_test.shape} / Non-zero: {interactions_test.getnnz()}\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    ## 9ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ (Train Set ì‚¬ìš©)\n",
    "\n",
    "    model = LightFM(\n",
    "        loss='warp', \n",
    "        no_components=15,\n",
    "        learning_rate=0.03, \n",
    "        user_alpha=0,\n",
    "        item_alpha=0,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        interactions_train, \n",
    "        sample_weight=weights_train, # COO í˜•ì‹ìœ¼ë¡œ ì „ë‹¬\n",
    "        user_features=user_features_matrix, \n",
    "        item_features=item_features_matrix,\n",
    "        epochs=60, \n",
    "        num_threads=4,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\nLightFM í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ìµœì¢… ëª¨ë¸ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb76ef7-5729-4c65-a8d9-3c7d99488732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Precision@3: 0.2429\n",
      "Test Set AUC Score: 0.9691\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "# Precision@3 ì¸¡ì •\n",
    "# í•™ìŠµ ë°ì´í„°ì™€ ì‚¬ìš©ì/ì•„ì´í…œ íŠ¹ì§•ì„ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "test_precision = precision_at_k(\n",
    "    model, \n",
    "    interactions_test, \n",
    "    user_features=user_features_matrix, \n",
    "    item_features=item_features_matrix, \n",
    "    k=3\n",
    ").mean()\n",
    "\n",
    "print(f\"Test Set Precision@3: {test_precision:.4f}\")\n",
    "\n",
    "# AUC Score ì¸¡ì • (ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ìˆœìœ„ ì˜ˆì¸¡ ëŠ¥ë ¥ì„ í‰ê°€)\n",
    "test_auc = auc_score(\n",
    "    model, \n",
    "    interactions_test, \n",
    "    user_features=user_features_matrix, \n",
    "    item_features=item_features_matrix\n",
    ").mean()\n",
    "\n",
    "print(f\"Test Set AUC Score: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12156c06-cb92-4a55-8146-afe73e5af87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Precision@3: 0.2497\n",
      "Train Set AUC Score: 0.9789\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "overfitting íŒë‹¨ìš© ì½”ë“œ\n",
    "\"\"\"\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°(Train Set)ì— ëŒ€í•œ Precision@3 ì¸¡ì •\n",
    "train_precision = precision_at_k(\n",
    "    model,\n",
    "    interactions_train, # ğŸ‘ˆ interactions_test ëŒ€ì‹  interactions_train ì‚¬ìš©\n",
    "    user_features=user_features_matrix,\n",
    "    item_features=item_features_matrix,\n",
    "    k=3\n",
    ").mean()\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°(Train Set)ì— ëŒ€í•œ AUC Score ì¸¡ì •\n",
    "train_auc = auc_score(\n",
    "    model,\n",
    "    interactions_train, # ğŸ‘ˆ interactions_test ëŒ€ì‹  interactions_train ì‚¬ìš©\n",
    "    user_features=user_features_matrix,\n",
    "    item_features=item_features_matrix\n",
    ").mean()\n",
    "\n",
    "print(f\"Train Set Precision@3: {train_precision:.4f}\")\n",
    "print(f\"Train Set AUC Score: {train_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c1a20-8951-4f0c-92b8-7fececb3c1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (LightFM Ready)",
   "language": "python",
   "name": "lightfm_python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
