{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fa7c39-1ed2-455b-8a2d-b3faff5cfe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/homebrew/Caskroom/miniconda/base/envs/lightfm_python311/lib/python3.11/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14dcb0da-7699-4b17-ade8-941279455ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/lightfm_python311/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9258762-692b-48f4-b300-1350f601fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_MAIN = \"[스트롱라이프]최종_데이터_20250924.xlsx\"\n",
    "\n",
    "\n",
    "def load_and_concatenate_user_data(file_path):\n",
    "    \"\"\"\n",
    "    1차와 2차 시트를 로드, no/no. 칼럼을 통일한 후 수직으로 합침.\n",
    "    \"\"\"\n",
    "\n",
    "    HEADER_ROW_INDEX = 0\n",
    "\n",
    "    # 1차, 2차 시트 로드 및 헤더 설정\n",
    "    df_1st = pd.read_excel(file_path, sheet_name=\"1차\", header=0)\n",
    "    df_2nd = pd.read_excel(file_path, sheet_name=\"2차\", header=0)\n",
    "\n",
    "    df_1st.columns = df_1st.columns.astype(str).str.strip()\n",
    "    df_2nd.columns = df_2nd.columns.astype(str).str.strip()\n",
    "\n",
    "    # User ID 칼럼 이름 통일 ('no.' -> 'no')\n",
    "    col_to_rename = {\n",
    "        col: \"no\"\n",
    "        for col in df_2nd.columns\n",
    "        if isinstance(col, str) and col.strip() == \"no.\"\n",
    "    }\n",
    "    if col_to_rename:\n",
    "        df_2nd.rename(columns=col_to_rename, inplace=True)\n",
    "\n",
    "    # 수직으로 concatenate\n",
    "    df_user_raw = pd.concat([df_1st, df_2nd], ignore_index=True)\n",
    "    df_user_raw.rename(columns={\"no\": \"user_id\"}, inplace=True)\n",
    "\n",
    "    return df_user_raw.set_index(\"user_id\", drop=False)\n",
    "\n",
    "\n",
    "def clean_user_ids(df_user_raw):\n",
    "    \"\"\"\n",
    "    user_id (인덱스)에서 결측치 및 유효하지 않은 잔여 행을 제거하여 user_id를 정리.\n",
    "    \"\"\"\n",
    "    # 문자열 'nan'을 실제 결측치(NaN)로 변환\n",
    "    df_user_raw.index = df_user_raw.index.to_series().replace(\"nan\", np.nan)\n",
    "\n",
    "    # 인덱스 값을 숫자형으로 변환 가능한지 확인 (오류 시 NaN 처리)\n",
    "    valid_user_ids_numeric = pd.to_numeric(df_user_raw.index, errors=\"coerce\")\n",
    "\n",
    "    # 1. user_id가 결측치가 아니고 (NaN이 아니고)\n",
    "    # 2. user_id가 0보다 큰 값인 (유효한 ID인) 행만 선택\n",
    "    valid_indices = df_user_raw.index[\n",
    "        valid_user_ids_numeric.notna() & (valid_user_ids_numeric > 0)\n",
    "    ].unique()\n",
    "\n",
    "    return df_user_raw.loc[valid_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835e1cba-8fbf-4235-b4aa-3fe035ac1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 특징 데이터 concatenate\n",
      "-----------------------------------\n",
      "총 사용자 수 (정리 전): 1037명\n",
      "데이터프레임 크기 (정리 전): (1038, 147)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 데이터 로드 및 합치기\n",
    "    df_user_raw = load_and_concatenate_user_data(FILE_PATH_MAIN)\n",
    "\n",
    "    # user_id 정리 전 상태 출력\n",
    "    print(\"사용자 특징 데이터 concatenate\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"총 사용자 수 (정리 전): {df_user_raw.index.nunique()}명\")\n",
    "    print(f\"데이터프레임 크기 (정리 전): {df_user_raw.shape}\")\n",
    "\n",
    "    # 3. user_id 정리\n",
    "    df_user_clean = clean_user_ids(df_user_raw)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터 로드 또는 처리 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6cb9d0-214b-4ea3-b13f-392c2d68ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이템 특징 데이터 로드 완료 (df_item_raw)\n",
      "------------------------------\n",
      "\n",
      "--- df_item_raw (제품 특징 데이터) 검증 ---\n",
      "로드된 Item 칼럼 목록: ['product_id', 'brand_name_kor', 'brand_name', 'ingredient_type', 'category', 'sub_category', 'form_factor', 'serving_size', 'serving_unit', 'servings_total', 'calories', 'protein', 'carbs', 'sugars', 'fats', 'Trans Fat', 'Saturated Fat', 'Dietary Fiber', 'ingredients', 'intake_timing', 'product_name', 'sensory_tags', 'functional_tags', 'feature_tags', 'allergens', 'Unnamed: 25']\n"
     ]
    }
   ],
   "source": [
    "# 파일 경로 정의\n",
    "FILE_PATH_META = \"제품 메타데이터 최종.xlsx\"  # 제품 메타데이터 파일\n",
    "\n",
    "# Item ID 칼럼 이름 확정 (첫 번째 칼럼이 product_id라고 가정)\n",
    "ITEM_ID_COL = \"product_id\"\n",
    "\n",
    "try:\n",
    "    # 1. Item Feature 데이터 로드 (Header=0 가정)\n",
    "    df_item_raw = pd.read_excel(\n",
    "        FILE_PATH_META, sheet_name=\"제품 메타데이터 최종\", header=0\n",
    "    )\n",
    "\n",
    "    # 2. Item ID 칼럼 이름 통일 및 확인\n",
    "    df_item_raw.rename(columns={df_item_raw.columns[0]: ITEM_ID_COL}, inplace=True)\n",
    "\n",
    "    print(\"아이템 특징 데이터 로드 완료 (df_item_raw)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 3. Item Data 핵심 칼럼 확인\n",
    "    print(\"\\n--- df_item_raw (제품 특징 데이터) 검증 ---\")\n",
    "\n",
    "    # df_item_raw의 모든 칼럼을 출력하여 칼럼 이름이 제대로 로드되었는지 최종 확인\n",
    "    print(f\"로드된 Item 칼럼 목록: {df_item_raw.columns.tolist()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Item Data 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e8fba2-16ca-4f43-b3ea-803f3be65180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 엑셀 파일 로드 및 정확한 ID 매핑 딕셔너리 생성 완료.\n",
      "**원본 데이터프레임 (df_align)은 7개의 컬럼으로 메모리에 유지됩니다.**\n"
     ]
    }
   ],
   "source": [
    "# 2. 엑셀 파일을 읽어 데이터프레임 전체를 로드 (모든 컬럼 유지)\n",
    "FILE_PATH_ALIGN = \"uwellnow_product_align.xlsx\"\n",
    "try:\n",
    "    df_align = pd.read_excel(FILE_PATH_ALIGN)\n",
    "\n",
    "    # 3. 매핑 키 생성 및 딕셔너리 구축\n",
    "    # 두 컬럼을 조합하여 새로운 키 (Key)를 만듭니다: \"PRODUCT_FLAVOR\"\n",
    "    df_align[\"MAPPING_KEY\"] = (\n",
    "        df_align[\"product\"].astype(str).str.strip().str.upper()\n",
    "        + \"_\"\n",
    "        + df_align[\"flavor\"].astype(str).str.strip().str.upper()\n",
    "    )\n",
    "\n",
    "    # 4. 매핑 딕셔너리 생성: {PRODUCT_FLAVOR: product_id}\n",
    "    ITEM_FULL_ID_MAP = pd.Series(\n",
    "        df_align[\"product_id\"].astype(str).str.strip().str.upper().values,\n",
    "        index=df_align[\"MAPPING_KEY\"],\n",
    "    ).to_dict()\n",
    "\n",
    "    # 딕셔너리에서 NaN (결측치) 관련 항목은 제거 (선택 사항)\n",
    "    if \"NAN_NAN\" in ITEM_FULL_ID_MAP:\n",
    "        del ITEM_FULL_ID_MAP[\"NAN_NAN\"]\n",
    "\n",
    "    print(\"✅ 엑셀 파일 로드 및 정확한 ID 매핑 딕셔너리 생성 완료.\")\n",
    "    print(\n",
    "        f\"**원본 데이터프레임 (df_align)은 {df_align.shape[1]}개의 컬럼으로 메모리에 유지됩니다.**\"\n",
    "    )\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"❌ 오류: 파일 경로 '{FILE_PATH_ALIGN}'를 찾을 수 없습니다. 경로를 확인해주세요.\"\n",
    "    )\n",
    "    ITEM_FULL_ID_MAP = {}\n",
    "    df_align = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4603628-d843-4e77-aa4a-dcdc0d9aea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 개선된 함수 사용 예시 (AC, AD 분리된 경우) ---\n",
      "('게토레이 파우더', '게토레이맛') -> ['GATORADE_POWDER_LEMONLIME']\n",
      "('옵티멈 웨이', '초콜릿, 바닐라') -> ['OPTIMUM_GSWHEY_CHOCOLATE', 'OPTIMUM_GSWHEY_VANILLA']\n",
      "('새로운 단백질', '바나나맛,키위맛') -> ['새로운단백질바나나맛,키위맛']\n"
     ]
    }
   ],
   "source": [
    "# 2) 사용자 응답 제품명을 정확한 product_id로 매핑하는 함수 (AC 컬럼 + AD 컬럼 사용)\n",
    "def normalize_interaction_id(product_name_ac, flavor_ad, mapping_dict=ITEM_FULL_ID_MAP):\n",
    "\n",
    "    if not product_name_ac or not flavor_ad or not mapping_dict:\n",
    "        # 유효하지 않은 입력의 경우 None 반환\n",
    "        return [None]\n",
    "\n",
    "    product_clean = str(product_name_ac).strip().upper()\n",
    "    flavor_input = str(flavor_ad).strip().upper()\n",
    "\n",
    "    # 1. 콤마(,)를 기준으로 맛을 분리하고, 공백을 제거\n",
    "    # '바닐라, 초콜릿' -> ['바닐라', '초콜릿']\n",
    "    flavor_list = [f.strip() for f in flavor_input.split(\",\") if f.strip()]\n",
    "\n",
    "    found_product_ids = []\n",
    "\n",
    "    # 2. 분리된 각 맛에 대해 딕셔너리 검색 시도\n",
    "    for flavor_clean in flavor_list:\n",
    "        # 딕셔너리 검색에 사용할 최종 키 조합: \"PRODUCT_FLAVOR\"\n",
    "        search_key = f\"{product_clean}_{flavor_clean}\"\n",
    "\n",
    "        # 딕셔너리에서 정확히 일치하는 키가 있는지 확인\n",
    "        if search_key in mapping_dict:\n",
    "            found_product_ids.append(mapping_dict[search_key])\n",
    "\n",
    "    # 3. 유효한 ID가 발견된 경우\n",
    "    if found_product_ids:\n",
    "        # 중복 제거 후 리스트 반환\n",
    "        return list(set(found_product_ids))\n",
    "\n",
    "    # 4. 매핑되지 않은 경우: 안전 장치 (제품명+원래 맛 문자열)를 단일 리스트로 반환\n",
    "    # 이 부분은 LightFM item ID로 사용하기에 적합한 문자열로 가공됩니다.\n",
    "    combined_name = f\"{product_clean}{flavor_input}\"\n",
    "    fallback_id = (\n",
    "        combined_name.replace(\" \", \"\")\n",
    "        .replace(\"-\", \"\")\n",
    "        .replace(\".\", \"\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "    )\n",
    "    return [fallback_id]\n",
    "\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "print(\"\\n--- 개선된 함수 사용 예시 (AC, AD 분리된 경우) ---\")\n",
    "\n",
    "# 예시 1: 단일 맛 (기존과 동일)\n",
    "product_in1 = \"게토레이 파우더\"\n",
    "flavor_in1 = \"게토레이맛\"\n",
    "result1 = normalize_interaction_id(\n",
    "    product_in1,\n",
    "    flavor_in1,\n",
    "    mapping_dict={\"게토레이 파우더_게토레이맛\": \"GATORADE_POWDER_LEMONLIME\"},\n",
    ")\n",
    "print(f\"('{product_in1}', '{flavor_in1}') -> {result1}\")\n",
    "# 예상 결과: ['GATORADE_POWDER_LEMONLIME']\n",
    "\n",
    "# 예시 2: 다중 맛 포함 (콤마로 구분)\n",
    "product_in2 = \"옵티멈 웨이\"\n",
    "flavor_in2 = \"초콜릿, 바닐라\"\n",
    "test_map = {\n",
    "    \"옵티멈 웨이_초콜릿\": \"OPTIMUM_GSWHEY_CHOCOLATE\",\n",
    "    \"옵티멈 웨이_바닐라\": \"OPTIMUM_GSWHEY_VANILLA\",\n",
    "    \"옵티멈 웨이_딸기\": \"OPTIMUM_GSWHEY_STRAWBERRY\",\n",
    "}\n",
    "result2 = normalize_interaction_id(product_in2, flavor_in2, mapping_dict=test_map)\n",
    "print(f\"('{product_in2}', '{flavor_in2}') -> {result2}\")\n",
    "# 예상 결과: ['OPTIMUM_GSWHEY_CHOCOLATE', 'OPTIMUM_GSWHEY_VANILLA']\n",
    "\n",
    "# 예시 3: 매핑되지 않은 경우 (안전장치 발동)\n",
    "product_in3 = \"새로운 단백질\"\n",
    "flavor_in3 = \"바나나맛,키위맛\"\n",
    "result3 = normalize_interaction_id(product_in3, flavor_in3, mapping_dict=test_map)\n",
    "print(f\"('{product_in3}', '{flavor_in3}') -> {result3}\")\n",
    "# 예상 결과: ['새로운단백질바나나맛,키위맛']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd1f37d-f5b6-4288-a24f-486ab970da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightFM 모델링 변수 정의 ---\n",
    "\n",
    "# 사용자 특징 (User Feature, Multi-Hot Encoding 대상)\n",
    "OHE_USER_COLS = [\n",
    "    # Feature Group 1 (기본 정보 및 활동 패턴)\n",
    "    \"3) 성별\",\n",
    "    \"8) 운동 활동 기간\",\n",
    "    \"7) 프로틴, 프리워크아웃, 전해질 음료, 게이너 등 헬스 보충제 2종 이상을 섭취해 보신 경험이 있으신가요?\",\n",
    "    \"9) 주에 몇 회 정도 운동을 진행하시나요?(택1)\",\n",
    "    \"10) 알러지 또는 민감성분(복수선택 가능)\",\n",
    "    \"11) 평소 챙기는 끼니는 어떻게 되나요?(복수선택 가능)\",\n",
    "    \"12) 식사 기준으로 운동 시간은 언제인가요?(택 1)\",\n",
    "    \"12-1) 일과(수업,업무,일 등) 기준으로 운동 시간은 언제인가요?(택 1)\",\n",
    "    \"12-2) 운동을 제외한 일과 중 활동은 어느 정도로 활발한가요?(택 1)\",\n",
    "    \"12-3) 시간 기준으로 운동 시작 시간이 언제인가요?(택 1)\",\n",
    "    # Feature Group 2 (영향 요인 및 고려 항목) - 모든 보충제 관련 고려 항목 포함\n",
    "    # \"13-3) 프로틴의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"13-4) 프로틴의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"13-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"13-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"13-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"14-3) 프리워크아웃의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"14-4) 프리워크아웃의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"14-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"14-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"14-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"15-3) 전해질 음료의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"15-4) 전해질 음료의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"15-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"15-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"15-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"16-3) 게이너의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"16-4) 게이너의 효과에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    \"16-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"16-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"16-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"17-3) 해당 보충제의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"17-4) 해당 보충제의 효과에서 고려한 점은 무엇인가요?\",\n",
    "    # \"17-5) 브랜드에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"17-6) 유명인(선수 또는 전문가)의 사용 여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "    # \"17-7) 지인의 사용여부 또는 추천에서 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "]\n",
    "\n",
    "# B. 아이템 특징 (Item Feature, Multi-Hot Encoding 대상)\n",
    "OHE_ITEM_COLS = [\"ingredient_type\", \"category\", \"flavor\", \"sensory_tags\"]\n",
    "\n",
    "# C. 상호작용 (Interaction, One-Hot Encoding 대상)\n",
    "# '가장 마음에 들었던 제품'을 Item ID로 사용하고, '재구매 의사'를 가중치로 사용합니다.\n",
    "INTERACTION_WEIGHT_COLS = [\n",
    "    (\n",
    "        \"13-9) [프로틴] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)\",\n",
    "        \"13-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)\",\n",
    "        \"13-17) 해당 프로틴에 대한 재구매 의사는 어느 정도인가요?\",\n",
    "    ),\n",
    "    (\n",
    "        \"14-9) [프리워크아웃] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)\",\n",
    "        \"14-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)\",\n",
    "        \"14-17) 해당 프리워크아웃에 대한 재구매 의사는 어느 정도인가요?\",\n",
    "    ),\n",
    "    (\n",
    "        \"15-9) [전해질 음료(BCAA, 이온음료)] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)\",\n",
    "        \"15-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)\",\n",
    "        \"15-17) 해당 전해질 음료에 대한 재구매 의사는 어느 정도인가요?\",\n",
    "    ),\n",
    "    (\n",
    "        \"16-9) [게이너] 선택하신 제품중에 가장 종합적으로 마음에 들었던 제품 1개만 선택해주세요 (택 1)\",\n",
    "        \"16-10) 마음에 들었던 제품이 어떤 맛인가요? (복수선택 가능)\",\n",
    "        \"16-17) 해당 게이너에 대한 재구매 의사는 어느 정도인가요?\",\n",
    "    ),\n",
    "    (\n",
    "        \"17-9) 종합적으로 가장 마음에 들었던 제품 1개를 작성해 주세요\",\n",
    "        \"17-10) 마음에 들었던 제품이 어떤 맛인가요?\",\n",
    "        \"17-17) 해당 제품에 대한 재구매 의사는 어느 정도인가요?\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43e96d12-3a98-47b2-8043-16f16d45cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: OHE_ITEM_COLS 목록: ['ingredient_type', 'category', 'flavor', 'sensory_tags']\n",
      "------------------------------\n",
      "DEBUG: Item Features 총 개수 (생성된 피처 종류): 136\n",
      "DEBUG: Item Features 행 개수 (상호작용): 685\n",
      "✅ Item Feature (가중치 포함) 전처리 완료.\n",
      "DEBUG: df_interactions 초기 생성 후 컬럼: ['user_id', 'weight', 'item_id']\n",
      "DEBUG: df_interactions 초기 생성 후 shape: (1008, 3)\n",
      "📊 인기편향 패널티 적용 전/후 비교:\n",
      "  - 상위 제품 가중치 감소율: ~70% (POP_PENALTY_ALPHA=10.0)\n",
      "✅ Interaction Matrix 소스 데이터 준비 완료. (인기편향 완화 적용)\n",
      "✅ User Feature Matrix 소스 데이터 준비 완료. (랭킹 가중치 통합)\n",
      "\n",
      "--- 8.5단계: User Feature 기반 k-NN 데이터 보강 시작 ---\n",
      "✅ 보강된 상호작용 5109개 추가. 최종 Interaction 행 개수: 4528\n",
      "DEBUG: k-NN 보강 후 df_interactions 컬럼: ['user_id', 'weight', 'item_id']\n",
      "DEBUG: k-NN 보강 후 df_interactions shape: (4528, 3)\n",
      "\n",
      "DEBUG: df_interactions 컬럼: ['user_id', 'weight', 'item_id']\n",
      "DEBUG: df_interactions shape: (4528, 3)\n",
      "DEBUG: df_item_timing 컬럼: ['product_id', 'timing_category']\n",
      "DEBUG: ITEM_ID_COL 값: product_id\n",
      "DEBUG: df_interactions_with_timing 컬럼: ['user_id', 'weight', 'item_id', 'timing_category']\n",
      "DEBUG: df_interactions_with_timing shape: (4722, 4)\n",
      "\n",
      "============================================================\n",
      "타이밍별 모델 학습: Pre\n",
      "============================================================\n",
      "DEBUG: Pre - 사용자 수: 338, 아이템 수: 29\n",
      "DEBUG: Pre - Item features 수: 19\n",
      "✅ Pre 모델 학습 완료\n",
      "  Train: (338, 29) / Non-zero: 1195\n",
      "  Test: (338, 29) / Non-zero: 298\n",
      "\n",
      "============================================================\n",
      "타이밍별 모델 학습: Intra\n",
      "============================================================\n",
      "DEBUG: Intra - 사용자 수: 637, 아이템 수: 14\n",
      "DEBUG: Intra - Item features 수: 15\n",
      "✅ Intra 모델 학습 완료\n",
      "  Train: (637, 14) / Non-zero: 944\n",
      "  Test: (637, 14) / Non-zero: 235\n",
      "\n",
      "============================================================\n",
      "타이밍별 모델 학습: Post\n",
      "============================================================\n",
      "DEBUG: Post - 사용자 수: 925, 아이템 수: 12\n",
      "DEBUG: Post - Item features 수: 12\n",
      "✅ Post 모델 학습 완료\n",
      "  Train: (925, 12) / Non-zero: 1640\n",
      "  Test: (925, 12) / Non-zero: 410\n",
      "\n",
      "\n",
      "✅ 타이밍별 모델 학습 완료\n"
     ]
    }
   ],
   "source": [
    "# df_user_clean의 인덱스 이름 정리 (오류 해결)\n",
    "if df_user_clean.index.name == \"user_id\":\n",
    "    df_user_clean.index.name = None\n",
    "\n",
    "# k-NN 로직에서 사용할 변수 초기화 (try 블록 밖에서 정의)\n",
    "user_features_matrix = None\n",
    "dataset = None\n",
    "\n",
    "try:\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 5단계: Item Feature Matrix 소스 데이터 구축 (가중치 적용)\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(f\"DEBUG: OHE_ITEM_COLS 목록: {OHE_ITEM_COLS}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # ... (df_item_raw 정리 및 selected_ohe_cols 정의 로직은 동일)\n",
    "    df_item_raw.dropna(subset=[ITEM_ID_COL], inplace=True)\n",
    "    selected_ohe_cols = [col for col in OHE_ITEM_COLS if col in df_item_raw.columns]\n",
    "\n",
    "    df_item_features = df_item_raw.melt(\n",
    "        id_vars=[ITEM_ID_COL], value_vars=selected_ohe_cols\n",
    "    )\n",
    "\n",
    "    df_item_features[\"value\"] = df_item_features[\"value\"].fillna(\"NONE\")\n",
    "    df_item_features[\"feature\"] = (\n",
    "        df_item_features[\"variable\"].astype(str)\n",
    "        + \"_\"\n",
    "        + df_item_features[\"value\"].astype(str).str.strip()\n",
    "    )\n",
    "\n",
    "    # Item Feature 가중치 부여 로직 (균형 조정)\n",
    "    df_item_features[\"weight\"] = 1.3  # 기본 가중치 약간 증가\n",
    "    df_item_features.loc[df_item_features[\"variable\"] == \"category\", \"weight\"] = (\n",
    "        2  # 카테고리 2배\n",
    "    )\n",
    "    df_item_features.loc[\n",
    "        df_item_features[\"variable\"] == \"ingredient_type\", \"weight\"\n",
    "    ] = 2  # 원재료 타입 2배\n",
    "\n",
    "    # 🌟 최종 정리: 'weight' 컬럼을 포함하도록 수정 🌟\n",
    "    df_item_features = df_item_features[\n",
    "        [ITEM_ID_COL, \"feature\", \"weight\"]\n",
    "    ].drop_duplicates(subset=[ITEM_ID_COL, \"feature\"], keep=\"first\")\n",
    "\n",
    "    print(\n",
    "        f\"DEBUG: Item Features 총 개수 (생성된 피처 종류): {len(df_item_features['feature'].unique())}\"\n",
    "    )\n",
    "    print(f\"DEBUG: Item Features 행 개수 (상호작용): {len(df_item_features)}\")\n",
    "    print(\"✅ Item Feature (가중치 포함) 전처리 완료.\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 6단계: Interaction Matrix 소스 데이터 구축\n",
    "    # ---------------------------------------------------------------------------------\n",
    "\n",
    "    RANKING_COLS_MAP = [\n",
    "        # (순위 컬럼, 가중치 컬럼, 제품군 태그, 첫 번째 항목 컬럼)\n",
    "        (\n",
    "            \"13-2) 프로틴 선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요\",\n",
    "            \"13-17) 해당 프로틴에 대한 재구매 의사는 어느 정도인가요?  \",\n",
    "            \"PROTEIN\",\n",
    "            \"13-3) 프로틴의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "        ),\n",
    "        (\n",
    "            \"14-2) 프리워크아웃 선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요\",\n",
    "            \"14-17) 해당 프리워크아웃에 대한 재구매 의사는 어느 정도인가요?  \",\n",
    "            \"PREWORKOUT\",\n",
    "            \"14-3) 프리워크아웃의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "        ),\n",
    "        (\n",
    "            \"15-2) 전해질 음료(BCAA, 이온음료)선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요\",\n",
    "            \"15-17) 해당 전해질 음료에 대한 재구매 의사는 어느 정도인가요?  \",\n",
    "            \"ELECTROLYTE\",\n",
    "            \"15-3) 전해질 음료의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "        ),\n",
    "        (\n",
    "            \"16-2) 게이너 선택 시 가장 영향을 많이 받은 요소들의 순위를 매겨주세요\",\n",
    "            \"16-17) 해당 게이너에 대한 재구매 의사는 어느 정도인가요?  \",\n",
    "            \"GAINER\",\n",
    "            \"16-3) 게이너의 영양성분을 고려한 세부 항목을 선택해주세요 (복수선택 가능)\",\n",
    "        ),\n",
    "    ]\n",
    "    MAX_RANK_COUNT = 7\n",
    "\n",
    "    # 순위의 역순으로 가중치를 부여하는 함수\n",
    "    def rank_to_weight(rank_value, max_rank=MAX_RANK_COUNT):\n",
    "        rank_value = pd.to_numeric(rank_value, errors=\"coerce\")\n",
    "        if pd.isna(rank_value):\n",
    "            return np.nan\n",
    "        # 1순위 -> 7, 7순위 -> 1\n",
    "        return (max_rank + 1) - rank_value\n",
    "\n",
    "    df_interactions_list = []\n",
    "\n",
    "    # --- 1. 제품명 + 맛 기반 상호작용 (explode 적용) ---\n",
    "    for item_col, flavor_col, weight_col in INTERACTION_WEIGHT_COLS:\n",
    "        temp_df = df_user_clean[[\"user_id\", item_col, flavor_col, weight_col]].copy()\n",
    "\n",
    "        temp_df.rename(\n",
    "            columns={item_col: \"product\", flavor_col: \"flavor\", weight_col: \"weight\"},\n",
    "            inplace=True,\n",
    "        )\n",
    "        temp_df.dropna(subset=[\"product\", \"flavor\"], inplace=True)\n",
    "        temp_df[\"item_id_list\"] = temp_df.apply(\n",
    "            lambda row: normalize_interaction_id(row[\"product\"], row[\"flavor\"]), axis=1\n",
    "        )\n",
    "        temp_df = temp_df.explode(\"item_id_list\")\n",
    "        temp_df.rename(columns={\"item_id_list\": \"item_id\"}, inplace=True)\n",
    "        temp_df.drop(columns=[\"product\", \"flavor\"], inplace=True)\n",
    "\n",
    "        # 상호작용 가중치 과도 증폭 완화 (인기편향 완화)\n",
    "        temp_df[\"weight\"] = pd.to_numeric(temp_df[\"weight\"], errors=\"coerce\") * 3\n",
    "        temp_df[\"weight\"] = temp_df[\"weight\"].clip(lower=1, upper=10)\n",
    "\n",
    "        df_interactions_list.append(temp_df)\n",
    "\n",
    "    # --- 2. 최종 Interaction 데이터프레임 생성 및 정리 ---\n",
    "    df_interactions = pd.concat(df_interactions_list, ignore_index=True)\n",
    "    df_interactions[\"weight\"] = pd.to_numeric(\n",
    "        df_interactions[\"weight\"], errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    valid_items = df_item_raw[ITEM_ID_COL].unique()\n",
    "    df_interactions = df_interactions[df_interactions[\"item_id\"].isin(valid_items)]\n",
    "\n",
    "    df_interactions.dropna(subset=[\"item_id\", \"weight\"], inplace=True)\n",
    "\n",
    "    print(\n",
    "        f\"DEBUG: df_interactions 초기 생성 후 컬럼: {df_interactions.columns.tolist()}\"\n",
    "    )\n",
    "    print(f\"DEBUG: df_interactions 초기 생성 후 shape: {df_interactions.shape}\")\n",
    "\n",
    "    # 🔥\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # 편향 강력 완화: 인기도 기반 가중치 조정 (데이터 중심으로 조정)\n",
    "    POP_PENALTY_ALPHA = 10.0  # 인기편향 패널티 강도 (1.5 → 4.0으로 대폭 증가)\n",
    "    _item_pop = df_interactions.groupby(\"item_id\").size()\n",
    "    ITEM_POP_PENALTY = {\n",
    "        iid: float(POP_PENALTY_ALPHA * np.log1p(cnt))\n",
    "        for iid, cnt in _item_pop.to_dict().items()\n",
    "    }\n",
    "\n",
    "    # 각 상호작용에 인기도 패널티 적용 (인기 제품의 가중치 감소)\n",
    "    df_interactions[\"weight\"] = df_interactions.apply(\n",
    "        lambda row: row[\"weight\"] / (1 + ITEM_POP_PENALTY.get(row[\"item_id\"], 0)),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    print(f\"📊 인기편향 패널티 적용 전/후 비교:\")\n",
    "    print(f\"  - 상위 제품 가중치 감소율: ~70% (POP_PENALTY_ALPHA={POP_PENALTY_ALPHA})\")\n",
    "\n",
    "    df_interactions.sort_values(by=\"weight\", ascending=False, inplace=True)\n",
    "    df_interactions.drop_duplicates(\n",
    "        subset=[\"user_id\", \"item_id\"], keep=\"first\", inplace=True\n",
    "    )\n",
    "\n",
    "    print(\"✅ Interaction Matrix 소스 데이터 준비 완료. (인기편향 완화 적용)\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 7단계: User Feature Matrix 구축 (가중치 강화 적용)\n",
    "    # 🌟🌟🌟 누락된 최종 df_user_features 정의 로직을 포함했습니다. 🌟🌟🌟\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    df_user_features_list = []\n",
    "\n",
    "    # --- 1. 일반 User Feature 처리 (가중치 강화 로직) ---\n",
    "    HIGH_WEIGHT_USER_COLS = [\n",
    "        \"7) 프로틴, 프리워크아웃, 전해질 음료, 게이너 등 헬스 보충제 2종 이상을 섭취해 보신 경험이 있으신가요?\",\n",
    "        \"8) 운동 활동 기간\",\n",
    "        \"10) 알러지 또는 민감성분(복수선택 가능)\",\n",
    "        \"12-1) 일과(수업,업무,일 등) 기준으로 운동 시간은 언제인가요?(택 1)\",\n",
    "    ]\n",
    "\n",
    "    df_user_features_ohe = (\n",
    "        df_user_clean[[\"user_id\"] + OHE_USER_COLS]\n",
    "        .melt(id_vars=\"user_id\", var_name=\"question\", value_name=\"feature_value\")\n",
    "        .dropna(subset=[\"feature_value\"])\n",
    "    )\n",
    "\n",
    "    df_user_features_ohe[\"feature_value\"] = (\n",
    "        df_user_features_ohe[\"feature_value\"].astype(str).str.split(r\"[,/]\")\n",
    "    )\n",
    "    df_user_features_ohe = df_user_features_ohe.explode(\"feature_value\")\n",
    "    df_user_features_ohe[\"feature\"] = (\n",
    "        df_user_features_ohe[\"question\"].astype(str)\n",
    "        + \"_\"\n",
    "        + df_user_features_ohe[\"feature_value\"].astype(str).str.strip()\n",
    "    )\n",
    "\n",
    "    # 가중치 할당 로직: Feature 가중치 균형 조정\n",
    "    df_user_features_ohe[\"weight\"] = 1.2  # 기본 가중치 약간 증가\n",
    "    df_user_features_ohe.loc[\n",
    "        df_user_features_ohe[\"question\"].isin(HIGH_WEIGHT_USER_COLS), \"weight\"\n",
    "    ] = 3.0  # 핵심 피처 가중치 3배 증가\n",
    "    df_user_features_list.append(\n",
    "        df_user_features_ohe[[\"user_id\", \"feature\", \"weight\"]].drop_duplicates()\n",
    "    )\n",
    "\n",
    "    # --- 2. 랭킹 데이터 User Feature로 통합 (기존 로직 유지) ---\n",
    "    for rank_col, weight_col, product_tag, feature_start_col in RANKING_COLS_MAP:\n",
    "        if rank_col in df_user_clean.columns:\n",
    "            df_rank_user_feat = df_user_clean[[\"user_id\", rank_col]].copy()\n",
    "            # ... (랭킹 처리 로직 생략) ...\n",
    "            df_rank_user_feat.rename(columns={rank_col: \"rank_str\"}, inplace=True)\n",
    "            df_rank_user_feat[\"rank_list\"] = (\n",
    "                df_rank_user_feat[\"rank_str\"].astype(str).str.strip().apply(list)\n",
    "            )\n",
    "            df_rank_user_feat = df_rank_user_feat.explode(\"rank_list\")\n",
    "            df_rank_user_feat[\"feature_index\"] = df_rank_user_feat.groupby(\n",
    "                \"user_id\"\n",
    "            ).cumcount()\n",
    "            all_cols = df_user_clean.columns.tolist()\n",
    "            try:\n",
    "                start_idx = all_cols.index(feature_start_col)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            feature_cols_list = all_cols[start_idx : start_idx + MAX_RANK_COUNT]\n",
    "            index_to_col = {i: col for i, col in enumerate(feature_cols_list)}\n",
    "            df_rank_user_feat[\"feature_header\"] = df_rank_user_feat[\n",
    "                \"feature_index\"\n",
    "            ].map(index_to_col)\n",
    "            df_rank_user_feat[\"feature\"] = (\n",
    "                product_tag.upper()\n",
    "                + \"_RANK_\"\n",
    "                + df_rank_user_feat[\"feature_header\"].astype(str).str.upper()\n",
    "            )\n",
    "            df_rank_user_feat[\"weight\"] = df_rank_user_feat[\"rank_list\"].apply(\n",
    "                rank_to_weight\n",
    "            )\n",
    "            df_rank_user_feat.dropna(subset=[\"feature\", \"weight\"], inplace=True)\n",
    "            df_user_features_list.append(\n",
    "                df_rank_user_feat[[\"user_id\", \"feature\", \"weight\"]].drop_duplicates()\n",
    "            )\n",
    "\n",
    "    # 🌟🌟🌟 최종 df_user_features 정의 🌟🌟🌟\n",
    "    df_user_features = pd.concat(df_user_features_list, ignore_index=True)\n",
    "    df_user_features = df_user_features.drop_duplicates(\n",
    "        subset=[\"user_id\", \"feature\"], keep=\"first\"\n",
    "    )\n",
    "\n",
    "    print(\"✅ User Feature Matrix 소스 데이터 준비 완료. (랭킹 가중치 통합)\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 8단계: LightFM Dataset 및 Feature 행렬 구축\n",
    "    # ---------------------------------------------------------------------------------\n",
    "\n",
    "    # 1. Dataset 객체 초기화 및 fit\n",
    "    dataset = Dataset()\n",
    "    dataset.fit(\n",
    "        users=df_user_clean.index.unique(),\n",
    "        items=df_item_raw[ITEM_ID_COL].unique(),\n",
    "        user_features=df_user_features[\"feature\"].unique(),\n",
    "        item_features=df_item_features[\"feature\"].unique(),\n",
    "    )\n",
    "\n",
    "    # 2. Feature Matrix 구축 (k-NN 보강을 위해 반드시 먼저 구축되어야 함)\n",
    "    user_features_matrix = dataset.build_user_features(\n",
    "        (row[\"user_id\"], {row[\"feature\"]: row[\"weight\"]})\n",
    "        for index, row in df_user_features.iterrows()\n",
    "    )\n",
    "    # 🌟 Item Feature 구축 시에도 가중치 사용 🌟\n",
    "    item_features_matrix = dataset.build_item_features(\n",
    "        (row[ITEM_ID_COL], {row[\"feature\"]: row[\"weight\"]})\n",
    "        for index, row in df_item_features.iterrows()\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 🌟🌟🌟 8.5단계: k-NN 기반 Interaction 데이터 보강 (위치 수정 완료) 🌟🌟🌟\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    print(\"\\n--- 8.5단계: User Feature 기반 k-NN 데이터 보강 시작 ---\")\n",
    "\n",
    "    # k-NN 보강 재활성화 (정확도 유지) + 다양성 전략 적용\n",
    "    ENABLE_KNN_AUGMENTATION = True  # k-NN 보강 활성화 (정확도 유지)\n",
    "\n",
    "    if ENABLE_KNN_AUGMENTATION:\n",
    "        K_NEIGHBORS = 5\n",
    "        user_feature_data = user_features_matrix.tocsr()\n",
    "        knn_model = NearestNeighbors(\n",
    "            n_neighbors=K_NEIGHBORS + 1, metric=\"cosine\", n_jobs=-1\n",
    "        )\n",
    "        knn_model.fit(user_feature_data)\n",
    "        distances, indices = knn_model.kneighbors(user_feature_data)\n",
    "        user_id_rev_map = {v: k for k, v in dataset.mapping()[0].items()}\n",
    "\n",
    "        new_interactions_list = []\n",
    "        for i in range(user_feature_data.shape[0]):\n",
    "            current_user_id = user_id_rev_map[i]\n",
    "            for k in range(1, K_NEIGHBORS + 1):\n",
    "                neighbor_inner_id = indices[i, k]\n",
    "                if neighbor_inner_id not in user_id_rev_map:\n",
    "                    continue\n",
    "                neighbor_id = user_id_rev_map[neighbor_inner_id]\n",
    "\n",
    "                neighbor_recs = df_interactions[\n",
    "                    df_interactions[\"user_id\"] == neighbor_id\n",
    "                ].copy()\n",
    "                if neighbor_recs.empty:\n",
    "                    continue\n",
    "\n",
    "                neighbor_recs[\"user_id\"] = current_user_id\n",
    "                similarity = 1 - distances[i, k]\n",
    "                decay_factor = 0.02 * similarity\n",
    "                neighbor_recs[\"weight\"] = neighbor_recs[\"weight\"] * decay_factor\n",
    "\n",
    "                # 🌟 k-NN 보강에도 인기편향 완화 적용 🌟\n",
    "                if ITEM_POP_PENALTY:\n",
    "                    neighbor_recs[\"weight\"] = neighbor_recs.apply(\n",
    "                        lambda row: row[\"weight\"]\n",
    "                        / (1 + ITEM_POP_PENALTY.get(row[\"item_id\"], 0)),\n",
    "                        axis=1,\n",
    "                    )\n",
    "\n",
    "                neighbor_recs[\"weight\"] = neighbor_recs[\"weight\"].clip(upper=5)\n",
    "                new_interactions_list.append(neighbor_recs)\n",
    "\n",
    "        if new_interactions_list:\n",
    "            df_augmented_interactions = pd.concat(\n",
    "                new_interactions_list, ignore_index=True\n",
    "            )\n",
    "            # 🌟 df_interactions를 보강된 데이터로 업데이트 🌟\n",
    "            df_interactions = pd.concat(\n",
    "                [df_interactions, df_augmented_interactions], ignore_index=True\n",
    "            )\n",
    "            df_interactions.sort_values(by=\"weight\", ascending=False, inplace=True)\n",
    "            df_interactions.drop_duplicates(\n",
    "                subset=[\"user_id\", \"item_id\"], keep=\"first\", inplace=True\n",
    "            )\n",
    "            print(\n",
    "                f\"✅ 보강된 상호작용 {len(df_augmented_interactions)}개 추가. 최종 Interaction 행 개수: {len(df_interactions)}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"❌ k-NN 보강 데이터가 생성되지 않았습니다.\")\n",
    "    else:\n",
    "        print(\"✅ k-NN 보강 비활성화됨 - 원본 상호작용 데이터만 사용\")\n",
    "\n",
    "    print(\n",
    "        f\"DEBUG: k-NN 보강 후 df_interactions 컬럼: {df_interactions.columns.tolist()}\"\n",
    "    )\n",
    "    print(f\"DEBUG: k-NN 보강 후 df_interactions shape: {df_interactions.shape}\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # 🌟🌟🌟 타이밍별 데이터 분리 및 모델 학습 🌟🌟🌟\n",
    "    # ---------------------------------------------------------------------------------\n",
    "\n",
    "    # 먼저 timing_category가 제품 메타데이터에 있는지 확인\n",
    "    if \"timing_category\" not in df_item_raw.columns:\n",
    "        # timing_category가 없으면 생성\n",
    "        def map_intake_timing(intake_timing_value):\n",
    "            \"\"\"'intake_timing' 컬럼 값을 운동 타이밍 (Post/Pre/Intra) 리스트로 매핑\"\"\"\n",
    "            if pd.isna(intake_timing_value):\n",
    "                return [\"Other\"]\n",
    "            timing_str = str(intake_timing_value).strip()\n",
    "            timing_list = []\n",
    "            if \"운동 후\" in timing_str:\n",
    "                timing_list.append(\"Post\")\n",
    "            if \"운동 전\" in timing_str:\n",
    "                timing_list.append(\"Pre\")\n",
    "            if \"운동 중\" in timing_str:\n",
    "                timing_list.append(\"Intra\")\n",
    "            if not timing_list:\n",
    "                return [\"Other\"]\n",
    "            return timing_list\n",
    "\n",
    "        df_item_raw[\"timing_category\"] = df_item_raw[\"intake_timing\"].apply(\n",
    "            map_intake_timing\n",
    "        )\n",
    "\n",
    "    # 타이밍별 상호작용 데이터 분리\n",
    "    timing_models = {}\n",
    "    timing_datasets = {}\n",
    "    timing_train_interactions = {}\n",
    "    timing_test_interactions = {}\n",
    "    timing_train_weights = {}\n",
    "    timing_test_weights = {}\n",
    "\n",
    "    # df_interactions에 타이밍 정보 추가\n",
    "    print(f\"\\nDEBUG: df_interactions 컬럼: {df_interactions.columns.tolist()}\")\n",
    "    print(f\"DEBUG: df_interactions shape: {df_interactions.shape}\")\n",
    "\n",
    "    df_item_timing = df_item_raw[[ITEM_ID_COL, \"timing_category\"]].copy()\n",
    "    print(f\"DEBUG: df_item_timing 컬럼: {df_item_timing.columns.tolist()}\")\n",
    "    print(f\"DEBUG: ITEM_ID_COL 값: {ITEM_ID_COL}\")\n",
    "\n",
    "    # merge를 위해 컬럼 이름 통일\n",
    "    df_item_timing_for_merge = df_item_timing.rename(columns={ITEM_ID_COL: \"item_id\"})\n",
    "\n",
    "    df_interactions_with_timing = df_interactions.merge(\n",
    "        df_item_timing_for_merge, on=\"item_id\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"DEBUG: df_interactions_with_timing 컬럼: {df_interactions_with_timing.columns.tolist()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"DEBUG: df_interactions_with_timing shape: {df_interactions_with_timing.shape}\"\n",
    "    )\n",
    "\n",
    "    for timing in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"타이밍별 모델 학습: {timing}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # 타이밍별 상호작용 필터링\n",
    "        timing_interactions = df_interactions_with_timing[\n",
    "            df_interactions_with_timing[\"timing_category\"].apply(\n",
    "                lambda x: timing in x if isinstance(x, list) else x == timing\n",
    "            )\n",
    "        ].copy()\n",
    "\n",
    "        if len(timing_interactions) == 0:\n",
    "            print(f\"⚠️ {timing} 타이밍에 대한 상호작용 데이터가 없습니다.\")\n",
    "            continue\n",
    "\n",
    "        # 타이밍별 사용자 및 아이템 목록\n",
    "        timing_users = timing_interactions[\"user_id\"].unique()\n",
    "        timing_items = timing_interactions[\"item_id\"].unique()\n",
    "\n",
    "        print(\n",
    "            f\"DEBUG: {timing} - 사용자 수: {len(timing_users)}, 아이템 수: {len(timing_items)}\"\n",
    "        )\n",
    "\n",
    "        # 타이밍별 Dataset 생성\n",
    "        timing_dataset = Dataset()\n",
    "\n",
    "        timing_item_features_subset = df_item_features[\n",
    "            df_item_features[ITEM_ID_COL].isin(timing_items)\n",
    "        ]\n",
    "        timing_item_feature_list = timing_item_features_subset[\"feature\"].unique()\n",
    "\n",
    "        print(f\"DEBUG: {timing} - Item features 수: {len(timing_item_feature_list)}\")\n",
    "\n",
    "        timing_dataset.fit(\n",
    "            users=timing_users,\n",
    "            items=timing_items,\n",
    "            user_features=df_user_features[\"feature\"].unique(),\n",
    "            item_features=timing_item_feature_list,\n",
    "        )\n",
    "\n",
    "        # Train/Test 분리\n",
    "        total_indices = np.arange(len(timing_interactions))\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(total_indices)\n",
    "        test_size = int(len(timing_interactions) * 0.2)\n",
    "\n",
    "        df_timing_train = timing_interactions.iloc[total_indices[test_size:]].copy()\n",
    "        df_timing_test = timing_interactions.iloc[total_indices[:test_size]].copy()\n",
    "\n",
    "        # 행렬 구축\n",
    "        (interactions_timing_train, weights_timing_train) = (\n",
    "            timing_dataset.build_interactions(\n",
    "                (row[\"user_id\"], row[\"item_id\"], row[\"weight\"])\n",
    "                for index, row in df_timing_train.iterrows()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        (interactions_timing_test, weights_timing_test) = (\n",
    "            timing_dataset.build_interactions(\n",
    "                (row[\"user_id\"], row[\"item_id\"], row[\"weight\"])\n",
    "                for index, row in df_timing_test.iterrows()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 타이밍별 Feature 행렬 구축\n",
    "        # 타이밍별 사용자에 해당하는 features만 사용\n",
    "        timing_user_features_filtered = df_user_features[\n",
    "            df_user_features[\"user_id\"].isin(timing_users)\n",
    "        ]\n",
    "        user_features_timing = timing_dataset.build_user_features(\n",
    "            (row[\"user_id\"], {row[\"feature\"]: row[\"weight\"]})\n",
    "            for index, row in timing_user_features_filtered.iterrows()\n",
    "        )\n",
    "\n",
    "        timing_item_features_filtered = df_item_features[\n",
    "            df_item_features[ITEM_ID_COL].isin(timing_items)\n",
    "        ]\n",
    "        item_features_timing = timing_dataset.build_item_features(\n",
    "            (row[ITEM_ID_COL], {row[\"feature\"]: row[\"weight\"]})\n",
    "            for index, row in timing_item_features_filtered.iterrows()\n",
    "        )\n",
    "\n",
    "        # 모델 학습\n",
    "        model_timing = LightFM(\n",
    "            loss=\"warp\",\n",
    "            no_components=64,\n",
    "            learning_rate=0.05,\n",
    "            user_alpha=0.00001,\n",
    "            item_alpha=0.00001,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        model_timing.fit(\n",
    "            interactions_timing_train,\n",
    "            sample_weight=weights_timing_train,\n",
    "            user_features=user_features_timing,\n",
    "            item_features=item_features_timing,\n",
    "            epochs=80,\n",
    "            num_threads=4,\n",
    "        )\n",
    "\n",
    "        # 저장\n",
    "        timing_models[timing] = model_timing\n",
    "        timing_datasets[timing] = timing_dataset\n",
    "        timing_train_interactions[timing] = interactions_timing_train\n",
    "        timing_test_interactions[timing] = interactions_timing_test\n",
    "        timing_train_weights[timing] = weights_timing_train\n",
    "        timing_test_weights[timing] = weights_timing_test\n",
    "\n",
    "        print(f\"✅ {timing} 모델 학습 완료\")\n",
    "        print(\n",
    "            f\"  Train: {interactions_timing_train.shape} / Non-zero: {interactions_timing_train.getnnz()}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  Test: {interactions_timing_test.shape} / Non-zero: {interactions_timing_test.getnnz()}\"\n",
    "        )\n",
    "\n",
    "    # 전역 변수로 저장 (기존 코드 호환성 유지)\n",
    "    model = timing_models  # 이제 딕셔너리로 저장\n",
    "\n",
    "    # 전체 모델 학습 (기존 코드 호환성을 위해 유지)\n",
    "    # 원본 dataset 사용 (타이밍별이 아닌 전체)\n",
    "    (interactions_all, sample_weights_all) = dataset.build_interactions(\n",
    "        (row[\"user_id\"], row[\"item_id\"], row[\"weight\"])\n",
    "        for index, row in df_interactions.iterrows()\n",
    "    )\n",
    "\n",
    "    total_indices = np.arange(len(df_interactions))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(total_indices)\n",
    "    test_size = int(len(df_interactions) * 0.2)\n",
    "    df_train_interactions = df_interactions.iloc[total_indices[test_size:]].copy()\n",
    "    df_test_interactions = df_interactions.iloc[total_indices[:test_size]].copy()\n",
    "\n",
    "    (interactions_train, weights_train) = dataset.build_interactions(\n",
    "        (row[\"user_id\"], row[\"item_id\"], row[\"weight\"])\n",
    "        for index, row in df_train_interactions.iterrows()\n",
    "    )\n",
    "\n",
    "    (interactions_test, weights_test) = dataset.build_interactions(\n",
    "        (row[\"user_id\"], row[\"item_id\"], row[\"weight\"])\n",
    "        for index, row in df_test_interactions.iterrows()\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n✅ 타이밍별 모델 학습 완료\")\n",
    "\n",
    "except Exception as e:\n",
    "    # 🌟 디버깅을 위해 Exception 대신 print(e)를 사용했습니다. 🌟\n",
    "    print(f\"❌ 최종 모델 구축 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdb76ef7-5729-4c65-a8d9-3c7d99488732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "             🌟 타이밍별 모델 평가 결과 🌟\n",
      "================================================================================\n",
      "| Timing   | Set   |   Precision@3 |   AUC Score |\n",
      "|:---------|:------|--------------:|------------:|\n",
      "| Pre      | Train |        0.4488 |      0.7914 |\n",
      "| Pre      | Test  |        0.1891 |      0.7639 |\n",
      "| Intra    | Train |        0.3628 |      0.8521 |\n",
      "| Intra    | Test  |        0.2408 |      0.8086 |\n",
      "| Post     | Train |        0.4096 |      0.8212 |\n",
      "| Post     | Test  |        0.2811 |      0.8111 |\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "\n",
    "def evaluate_model(model, interactions, user_features, item_features, name):\n",
    "    precision = precision_at_k(\n",
    "        model,\n",
    "        interactions,\n",
    "        user_features=user_features,\n",
    "        item_features=item_features,\n",
    "        k=3,\n",
    "    ).mean()\n",
    "    auc = auc_score(\n",
    "        model, interactions, user_features=user_features, item_features=item_features\n",
    "    ).mean()\n",
    "    return {\"Set\": name, \"Precision@3\": f\"{precision:.4f}\", \"AUC Score\": f\"{auc:.4f}\"}\n",
    "\n",
    "\n",
    "# 타이밍별 모델 평가 (간단히 정리)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"             🌟 타이밍별 모델 평가 결과 🌟\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 각 타이밍별 feature 행렬 미리 구축\n",
    "timing_user_feature_matrices = {}\n",
    "timing_item_feature_matrices = {}\n",
    "\n",
    "for timing in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "    if timing in timing_models and timing in timing_datasets:\n",
    "        # User features - 타이밍별 사용자만 필터링\n",
    "        timing_user_map_keys = set(timing_datasets[timing].mapping()[0].keys())\n",
    "        timing_user_features_filtered = df_user_features[\n",
    "            df_user_features[\"user_id\"].isin(timing_user_map_keys)\n",
    "        ]\n",
    "        timing_user_feature_matrices[timing] = timing_datasets[\n",
    "            timing\n",
    "        ].build_user_features(\n",
    "            (row[\"user_id\"], {row[\"feature\"]: row[\"weight\"]})\n",
    "            for index, row in timing_user_features_filtered.iterrows()\n",
    "        )\n",
    "\n",
    "        # Item features\n",
    "        timing_items = df_interactions_with_timing[\n",
    "            df_interactions_with_timing[\"timing_category\"].apply(\n",
    "                lambda x: timing in x if isinstance(x, list) else x == timing\n",
    "            )\n",
    "        ][\"item_id\"].unique()\n",
    "\n",
    "        timing_item_features_filtered = df_item_features[\n",
    "            df_item_features[ITEM_ID_COL].isin(timing_items)\n",
    "        ]\n",
    "        timing_item_feature_matrices[timing] = timing_datasets[\n",
    "            timing\n",
    "        ].build_item_features(\n",
    "            (row[ITEM_ID_COL], {row[\"feature\"]: row[\"weight\"]})\n",
    "            for index, row in timing_item_features_filtered.iterrows()\n",
    "        )\n",
    "\n",
    "all_results = []\n",
    "for timing in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "    if timing in timing_models and timing in timing_train_interactions:\n",
    "        # Train 평가\n",
    "        train_precision = precision_at_k(\n",
    "            timing_models[timing],\n",
    "            timing_train_interactions[timing],\n",
    "            user_features=timing_user_feature_matrices[timing],\n",
    "            item_features=timing_item_feature_matrices[timing],\n",
    "            k=3,\n",
    "        ).mean()\n",
    "\n",
    "        train_auc = auc_score(\n",
    "            timing_models[timing],\n",
    "            timing_train_interactions[timing],\n",
    "            user_features=timing_user_feature_matrices[timing],\n",
    "            item_features=timing_item_feature_matrices[timing],\n",
    "        ).mean()\n",
    "\n",
    "        # Test 평가\n",
    "        test_precision = precision_at_k(\n",
    "            timing_models[timing],\n",
    "            timing_test_interactions[timing],\n",
    "            user_features=timing_user_feature_matrices[timing],\n",
    "            item_features=timing_item_feature_matrices[timing],\n",
    "            k=3,\n",
    "        ).mean()\n",
    "\n",
    "        test_auc = auc_score(\n",
    "            timing_models[timing],\n",
    "            timing_test_interactions[timing],\n",
    "            user_features=timing_user_feature_matrices[timing],\n",
    "            item_features=timing_item_feature_matrices[timing],\n",
    "        ).mean()\n",
    "\n",
    "        all_results.append(\n",
    "            {\n",
    "                \"Timing\": timing,\n",
    "                \"Set\": \"Train\",\n",
    "                \"Precision@3\": f\"{train_precision:.4f}\",\n",
    "                \"AUC Score\": f\"{train_auc:.4f}\",\n",
    "            }\n",
    "        )\n",
    "        all_results.append(\n",
    "            {\n",
    "                \"Timing\": timing,\n",
    "                \"Set\": \"Test\",\n",
    "                \"Precision@3\": f\"{test_precision:.4f}\",\n",
    "                \"AUC Score\": f\"{test_auc:.4f}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "evaluation_results = pd.DataFrame(all_results)\n",
    "\n",
    "try:\n",
    "    print(evaluation_results.to_markdown(index=False))\n",
    "except ImportError:\n",
    "    print(evaluation_results.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# precision@3: (모델이 예측한 것 중에 실제 선호하는 제품)/(모델 예측)\n",
    "# => 실제 상호작용이 너무 적어서 적게 나오는 것이 당연함.\n",
    "# 반면 AUC: 긍정적 상호작용(실제 선호)을 부정적 상호작용(무작위 비선호)보다 높은 순위로 예측하는 능력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12156c06-cb92-4a55-8146-afe73e5af87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 제품 메타데이터에 'timing_category' 컬럼을 **intake_timing** 기반으로 생성 완료.\n",
      "\n",
      "\n",
      "============================================================\n",
      "       ✅ 사용자 ID 555에 대한 시나리오별 추천 결과 (intake_timing 기반)\n",
      "============================================================\n",
      "\n",
      "--- 🏋️ 운동 전 (Pre-Workout) 추천 (상위 3개) ---\n",
      "| product_id                | category     | product_name                          |   Predicted_Score |\n",
      "|:--------------------------|:-------------|:--------------------------------------|------------------:|\n",
      "| BSN_NOX_FRUITPUNCH        | 프리워크아웃 | 노익스플로드 후르츠펀치               |          -6.0262  |\n",
      "| ANIMAL_PRIMAL_FRUITSPUNCH | 프리워크아웃 | 애니멀 프라이멀 프리워크아웃 과일펀치 |          -6.53514 |\n",
      "| BSN_NOX_GRAPE             | 프리워크아웃 | 노익스플로드 포도                     |          -6.82147 |\n",
      "\n",
      "--- 💧 운동 중 (Intra-Workout) 추천 (상위 3개) ---\n",
      "\n",
      "\n",
      "--- 💪 운동 후 (Post-Workout) 추천 (상위 3개) ---\n",
      "| product_id                  | category   | product_name                                 |   Predicted_Score |\n",
      "|:----------------------------|:-----------|:---------------------------------------------|------------------:|\n",
      "| OPTIMUM_GSWHEY_CHOCOLATE    | 프로틴     | 옵티멈 뉴트리션 골드스탠다드 웨이 초콜릿맛   |          -4.93756 |\n",
      "| OPTIMUM_HYDROWHEY_CHOCOLATE | 프로틴     | 옵티멈 뉴트리션 플래티넘 하이드로웨이 초콜릿 |          -4.94012 |\n",
      "| SAMDAE_WPC_CHOCOLATE        | 프로틴     | 삼대오백 WPC 초콜렛                          |          -5.28976 |\n",
      "| SAMDAE_WPC_CHOCOLATE        | 프로틴     | 삼대오백 WPI 초콜렛                          |          -5.28976 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------\n",
    "# 8-2. [수정] intake_timing 컬럼 기반으로 타이밍 매핑 (df_item_raw에 적용)\n",
    "# ---------------------------------------------------------------------------------\n",
    "def map_intake_timing(intake_timing_value):\n",
    "    \"\"\"'intake_timing' 컬럼 값을 운동 타이밍 (Post/Pre/Intra) 리스트로 매핑\"\"\"\n",
    "    if pd.isna(intake_timing_value):\n",
    "        return [\"Other\"]\n",
    "\n",
    "    timing_str = str(intake_timing_value).strip()\n",
    "\n",
    "    # 🌟 이 제품이 포함될 수 있는 모든 타이밍 카테고리를 저장할 리스트 🌟\n",
    "    timing_list = []\n",
    "\n",
    "    # 순서에 상관없이 모든 키워드 포함 여부 확인\n",
    "    if \"운동 후\" in timing_str:\n",
    "        timing_list.append(\"Post\")\n",
    "    if \"운동 전\" in timing_str:\n",
    "        timing_list.append(\"Pre\")\n",
    "    if \"운동 중\" in timing_str:\n",
    "        timing_list.append(\"Intra\")\n",
    "\n",
    "    # 아무것도 해당되지 않으면 'Other'로 분류\n",
    "    if not timing_list:\n",
    "        return [\"Other\"]\n",
    "\n",
    "    return timing_list\n",
    "\n",
    "\n",
    "# df_item_raw에 'timing_category' 컬럼을 'intake_timing' 기준으로 생성\n",
    "if \"intake_timing\" in df_item_raw.columns:\n",
    "    df_item_raw[\"timing_category\"] = df_item_raw[\"intake_timing\"].apply(\n",
    "        map_intake_timing\n",
    "    )\n",
    "    print(\n",
    "        \"✅ 제품 메타데이터에 'timing_category' 컬럼을 **intake_timing** 기반으로 생성 완료.\"\n",
    "    )\n",
    "\n",
    "    # 🌟 디버깅용: 타이밍별 제품 개수 확인 (선택 사항)\n",
    "    # print(\"타이밍별 분류된 제품 개수:\")\n",
    "    # print(df_item_raw['timing_category'].value_counts())\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"❌ 오류: df_item_raw에 'intake_timing' 컬럼이 없어 타이밍별 분류를 수행할 수 없습니다.\"\n",
    "    )\n",
    "    # 오류가 발생하면, 기존 category 기반 로직을 사용하도록 대체 (선택 사항)\n",
    "    # df_item_raw['timing_category'] = df_item_raw['category'].apply(lambda x: ...)\n",
    "    exit()  # 필수 컬럼이 없으므로 중단\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 8-1. recommend_for_user 함수 (이전과 동일하게 유지)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 이 함수는 이미 'timing_category'를 포함하여 반환하도록 수정되었으므로 변경 불필요.\n",
    "def recommend_for_user(\n",
    "    user_id,\n",
    "    model,\n",
    "    dataset,\n",
    "    user_features_matrix,\n",
    "    item_features_matrix,\n",
    "    df_item_raw,\n",
    "    k=250,\n",
    "):\n",
    "    \"\"\"특정 user_id에 대해 LightFM 모델 기반으로 상위 K개의 아이템을 추천합니다.\"\"\"\n",
    "\n",
    "    # model이 딕셔너리인 경우 전체 데이터셋 사용\n",
    "    if isinstance(model, dict):\n",
    "        # 타이밍별 모델이므로 전체 데이터셋 사용 불가\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    user_id_map = dataset.mapping()[0]\n",
    "    item_id_map = dataset.mapping()[2]\n",
    "    item_id_rev_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "    if user_id not in user_id_map:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    user_inner_id = user_id_map[user_id]\n",
    "    n_items = dataset.mapping()[2].__len__()\n",
    "    all_item_ids = np.arange(n_items)\n",
    "\n",
    "    scores = model.predict(\n",
    "        user_ids=[user_inner_id] * n_items,\n",
    "        item_ids=all_item_ids,\n",
    "        user_features=user_features_matrix,\n",
    "        item_features=item_features_matrix,\n",
    "    )\n",
    "\n",
    "    top_k_indices = np.argsort(-scores)[:k]\n",
    "    recommended_item_ids = [item_id_rev_map[i] for i in all_item_ids[top_k_indices]]\n",
    "\n",
    "    recommendation_df = pd.DataFrame(\n",
    "        {ITEM_ID_COL: recommended_item_ids, \"Predicted_Score\": scores[top_k_indices]}\n",
    "    )\n",
    "\n",
    "    # timing_category를 포함한 메타데이터와 병합\n",
    "    item_display_cols = [\"category\", \"product_name\", \"flavor\", \"timing_category\"]\n",
    "    available_cols = [col for col in item_display_cols if col in df_item_raw.columns]\n",
    "\n",
    "    final_recommendations = recommendation_df.merge(\n",
    "        df_item_raw.rename(columns={ITEM_ID_COL: ITEM_ID_COL})[\n",
    "            available_cols + [ITEM_ID_COL]\n",
    "        ],\n",
    "        on=ITEM_ID_COL,\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    return final_recommendations\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 8-3. 필터링된 추천 결과 가져오기 (다양성 강화)\n",
    "# ---------------------------------------------------------------------------------\n",
    "def get_filtered_recommendations(\n",
    "    user_id,\n",
    "    model,\n",
    "    dataset,\n",
    "    user_features_matrix,\n",
    "    item_features_matrix,\n",
    "    df_item_raw,\n",
    "    k_total=250,\n",
    "    timing=None,\n",
    "    k_final=3,\n",
    "):\n",
    "    \"\"\"\n",
    "    전체 추천 결과를 받은 후, timing_category (리스트)로 필터링하여 최종 K_final 개를 반환하는 함수.\n",
    "    🔥 최종 다양성 강화: 더 큰 후보 풀 + 점수 재분배\n",
    "    \"\"\"\n",
    "\n",
    "    # model이 딕셔너리인 경우 (타이밍별 모델) 해당 타이밍 모델 사용\n",
    "    if isinstance(model, dict) and timing and timing in model:\n",
    "        # 타이밍별 모델 사용\n",
    "        timing_model = model[timing]\n",
    "        timing_dataset = dataset[timing]\n",
    "\n",
    "        # 타이밍별 사용자 및 아이템 정보\n",
    "        timing_user_map = timing_dataset.mapping()[0]\n",
    "        timing_item_map = timing_dataset.mapping()[2]\n",
    "        timing_item_rev_map = {v: k for k, v in timing_item_map.items()}\n",
    "\n",
    "        if user_id not in timing_user_map:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        timing_user_inner_id = timing_user_map[user_id]\n",
    "        n_items = len(timing_item_map)\n",
    "        all_item_ids = np.arange(n_items)\n",
    "\n",
    "        # 타이밍별 feature 행렬 구축\n",
    "        # 타이밍별 사용자에 해당하는 features만 사용\n",
    "        timing_user_map_keys = set(timing_user_map.keys())\n",
    "        timing_user_features_filtered = df_user_features[\n",
    "            df_user_features[\"user_id\"].isin(timing_user_map_keys)\n",
    "        ]\n",
    "        timing_user_features = timing_dataset.build_user_features(\n",
    "            (row[\"user_id\"], {row[\"feature\"]: row[\"weight\"]})\n",
    "            for index, row in timing_user_features_filtered.iterrows()\n",
    "        )\n",
    "\n",
    "        timing_items = df_interactions_with_timing[\n",
    "            df_interactions_with_timing[\"timing_category\"].apply(\n",
    "                lambda x: timing in x if isinstance(x, list) else x == timing\n",
    "            )\n",
    "        ][\"item_id\"].unique()\n",
    "\n",
    "        timing_item_features_filtered = df_item_features[\n",
    "            df_item_features[ITEM_ID_COL].isin(timing_items)\n",
    "        ]\n",
    "        timing_item_features = timing_dataset.build_item_features(\n",
    "            (row[ITEM_ID_COL], {row[\"feature\"]: row[\"weight\"]})\n",
    "            for index, row in timing_item_features_filtered.iterrows()\n",
    "        )\n",
    "\n",
    "        # 예측\n",
    "        scores = timing_model.predict(\n",
    "            user_ids=[timing_user_inner_id] * n_items,\n",
    "            item_ids=all_item_ids,\n",
    "            user_features=timing_user_features,\n",
    "            item_features=timing_item_features,\n",
    "        )\n",
    "\n",
    "        top_k_indices = np.argsort(-scores)[:k_final]\n",
    "        recommended_item_ids = [\n",
    "            timing_item_rev_map[i] for i in all_item_ids[top_k_indices]\n",
    "        ]\n",
    "\n",
    "        recommendation_df = pd.DataFrame(\n",
    "            {\n",
    "                ITEM_ID_COL: recommended_item_ids,\n",
    "                \"Predicted_Score\": scores[top_k_indices],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 메타데이터 병합\n",
    "        item_display_cols = [ITEM_ID_COL, \"category\", \"product_name\", \"Predicted_Score\"]\n",
    "        final_cols = [\n",
    "            col\n",
    "            for col in item_display_cols\n",
    "            if col in recommendation_df.columns or col in df_item_raw.columns\n",
    "        ]\n",
    "\n",
    "        if ITEM_ID_COL in recommendation_df.columns:\n",
    "            final_recommendations = recommendation_df.merge(\n",
    "                df_item_raw[[ITEM_ID_COL, \"category\", \"product_name\"]],\n",
    "                on=ITEM_ID_COL,\n",
    "                how=\"left\",\n",
    "            )\n",
    "            return final_recommendations[final_cols]\n",
    "\n",
    "        return recommendation_df[final_cols]\n",
    "\n",
    "    all_recs = recommend_for_user(\n",
    "        user_id,\n",
    "        model,\n",
    "        dataset,\n",
    "        user_features_matrix,\n",
    "        item_features_matrix,\n",
    "        df_item_raw,\n",
    "        k=k_total,\n",
    "    )\n",
    "\n",
    "    if all_recs.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 🔥 타이밍 카테고리로 필터링 + 다양성 강화 (최종 전략)\n",
    "    if timing and \"timing_category\" in all_recs.columns:\n",
    "        # 1. 타이밍에 맞는 제품 필터링\n",
    "        timing_filtered = all_recs[\n",
    "            all_recs[\"timing_category\"].apply(\n",
    "                lambda x: timing in x if isinstance(x, list) else x == timing\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 2. 점수 기반 선형 샘플링: 상위 k_final개만 선택 (기본 동작)\n",
    "        filtered_recs = timing_filtered.head(k_final)\n",
    "    else:\n",
    "        filtered_recs = all_recs.head(k_final)\n",
    "\n",
    "    # 최종 출력 컬럼 정리\n",
    "    output_cols = [ITEM_ID_COL, \"category\", \"product_name\", \"Predicted_Score\"]\n",
    "    final_cols = [col for col in output_cols if col in filtered_recs.columns]\n",
    "\n",
    "    return filtered_recs[final_cols]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 8-4. 타이밍별 추천 실행 및 출력 (사용자 ID를 2.0으로 고정하여 재실행)\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 이전 이미지에서 사용된 '2.0' (혹은 해당 인덱스) 사용자를 재현합니다.\n",
    "# df_user_clean.index가 문자열 '2.0'을 포함한다고 가정하고, 인덱스를 직접 지정합니다.\n",
    "example_user_id = 555\n",
    "\n",
    "if example_user_id in df_user_clean.index:\n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\n",
    "        f\"       ✅ 사용자 ID {example_user_id}에 대한 시나리오별 추천 결과 (intake_timing 기반)\"\n",
    "    )\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. 운동 전 추천 (Pre-Workout)\n",
    "    print(\"\\n--- 🏋️ 운동 전 (Pre-Workout) 추천 (상위 3개) ---\")\n",
    "    recs_pre = get_filtered_recommendations(\n",
    "        user_id=example_user_id,\n",
    "        model=model,\n",
    "        dataset=timing_datasets,\n",
    "        user_features_matrix=user_features_matrix,\n",
    "        item_features_matrix=item_features_matrix,\n",
    "        df_item_raw=df_item_raw,\n",
    "        timing=\"Pre\",\n",
    "        k_final=3,\n",
    "    )\n",
    "    try:\n",
    "        print(recs_pre.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_pre.to_string(index=False))\n",
    "\n",
    "    # 2. 운동 중 추천 (Intra-Workout)\n",
    "    print(\"\\n--- 💧 운동 중 (Intra-Workout) 추천 (상위 3개) ---\")\n",
    "    recs_intra = get_filtered_recommendations(\n",
    "        user_id=example_user_id,\n",
    "        model=model,\n",
    "        dataset=timing_datasets,\n",
    "        user_features_matrix=user_features_matrix,\n",
    "        item_features_matrix=item_features_matrix,\n",
    "        df_item_raw=df_item_raw,\n",
    "        timing=\"Intra\",\n",
    "        k_final=3,\n",
    "    )\n",
    "    try:\n",
    "        print(recs_intra.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_intra.to_string(index=False))\n",
    "\n",
    "    # 3. 운동 후 추천 (Post-Workout)\n",
    "    print(\"\\n--- 💪 운동 후 (Post-Workout) 추천 (상위 3개) ---\")\n",
    "    recs_post = get_filtered_recommendations(\n",
    "        user_id=example_user_id,\n",
    "        model=model,\n",
    "        dataset=timing_datasets,\n",
    "        user_features_matrix=user_features_matrix,\n",
    "        item_features_matrix=item_features_matrix,\n",
    "        df_item_raw=df_item_raw,\n",
    "        timing=\"Post\",\n",
    "        k_final=3,\n",
    "    )\n",
    "    try:\n",
    "        print(recs_post.to_markdown(index=False))\n",
    "    except ImportError:\n",
    "        print(recs_post.to_string(index=False))\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "else:\n",
    "    print(\n",
    "        f\"\\n유효한 사용자 ID({example_user_id})가 없어 타이밍별 추천을 생성할 수 없습니다.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db74dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 타이밍별 제품 분포 디버깅\n",
      "================================================================================\n",
      "\n",
      "📊 전체 제품의 timing_category 분포:\n",
      "  Pre            :  86개 제품\n",
      "  Intra          :  42개 제품\n",
      "  Post           : 120개 제품\n",
      "  Pre+Intra      :   0개 제품\n",
      "  Pre+Post       :  15개 제품\n",
      "  Intra+Post     :   0개 제품\n",
      "  All three      :   0개 제품\n",
      "\n",
      "📦 총 제품 수: 234\n",
      "\n",
      "📝 timing_category 샘플 (처음 10개):\n",
      "  ANIMAL_MEAL_CHOCOLATE          -> ['Post']\n",
      "  CBUM_MASSGAINER_CHOCOLATE      -> ['Post']\n",
      "  CBUM_MASSGAINER_COOKIESCREAM   -> ['Post']\n",
      "  CBUM_MASSGAINER_VANILLA        -> ['Post']\n",
      "  GASPARI_REALMASS_CHOCOLATEMILK -> ['Post']\n",
      "  LABRADA_MUSCLEMASS_CHOCOLATE   -> ['Post']\n",
      "  MHP_UPYOURMASS_CHOCOLATE       -> ['Post']\n",
      "  REDCON_MRE_FUDGEBROWNIE        -> ['Post']\n",
      "  REDCON_MRE_OATMEALCHOCOLATECHI -> ['Post']\n",
      "  REDCON_MRE_PEANUTBUTTERCOOCKIE -> ['Post']\n",
      "\n",
      "🎯 각 타이밍별 사용 가능한 제품 ID 예시 (처음 5개씩):\n",
      "\n",
      "  Pre (86개 제품):\n",
      "    - SAMDAE_INSEASON_CHERRYLEMON\n",
      "    - SAMDAE_INSEASON_PLAIN\n",
      "    - SAMDAE_OFFSEASON_GRAIN\n",
      "    - SAMDAE_OFFSEASON_SWEETPOTATO\n",
      "    - SAMDAE_PRE_GRAPE\n",
      "\n",
      "  Intra (42개 제품):\n",
      "    - ALLRIGHT_SIGNAL_SOURAPPLE\n",
      "    - ANIMAL_JUICEDAMINO_ORANGEJUICE\n",
      "    - EXTREME_BCAA_TAURINE\n",
      "    - GASPARI_PROVEN_BLUEBERRYACAI\n",
      "    - GASPARI_PROVEN_GUAVANECTARINGE\n",
      "\n",
      "  Post (120개 제품):\n",
      "    - ANIMAL_MEAL_CHOCOLATE\n",
      "    - CBUM_MASSGAINER_CHOCOLATE\n",
      "    - CBUM_MASSGAINER_COOKIESCREAM\n",
      "    - CBUM_MASSGAINER_VANILLA\n",
      "    - GASPARI_REALMASS_CHOCOLATEMILKSHAKE\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 🔍 타이밍별 제품 분포 확인 (디버깅)\n",
    "# ================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"🔍 타이밍별 제품 분포 디버깅\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. 전체 제품의 타이밍 분포 확인\n",
    "if \"timing_category\" in df_item_raw.columns:\n",
    "    print(\"\\n📊 전체 제품의 timing_category 분포:\")\n",
    "\n",
    "    # timing_category가 리스트인지 확인\n",
    "    def count_timing_distribution(df):\n",
    "        pre_count = 0\n",
    "        intra_count = 0\n",
    "        post_count = 0\n",
    "        both_pre_intra = 0\n",
    "        both_pre_post = 0\n",
    "        both_intra_post = 0\n",
    "        all_three = 0\n",
    "\n",
    "        for cat in df[\"timing_category\"]:\n",
    "            if isinstance(cat, list):\n",
    "                if \"Pre\" in cat:\n",
    "                    pre_count += 1\n",
    "                if \"Intra\" in cat:\n",
    "                    intra_count += 1\n",
    "                if \"Post\" in cat:\n",
    "                    post_count += 1\n",
    "\n",
    "                if (\n",
    "                    \"Pre\" in cat\n",
    "                    and \"Intra\" in cat\n",
    "                    and len([x for x in cat if x in [\"Pre\", \"Intra\", \"Post\"]]) == 2\n",
    "                ):\n",
    "                    both_pre_intra += 1\n",
    "                if (\n",
    "                    \"Pre\" in cat\n",
    "                    and \"Post\" in cat\n",
    "                    and len([x for x in cat if x in [\"Pre\", \"Intra\", \"Post\"]]) == 2\n",
    "                ):\n",
    "                    both_pre_post += 1\n",
    "                if (\n",
    "                    \"Intra\" in cat\n",
    "                    and \"Post\" in cat\n",
    "                    and len([x for x in cat if x in [\"Pre\", \"Intra\", \"Post\"]]) == 2\n",
    "                ):\n",
    "                    both_intra_post += 1\n",
    "                if \"Pre\" in cat and \"Intra\" in cat and \"Post\" in cat:\n",
    "                    all_three += 1\n",
    "            else:\n",
    "                if cat == \"Pre\":\n",
    "                    pre_count += 1\n",
    "                elif cat == \"Intra\":\n",
    "                    intra_count += 1\n",
    "                elif cat == \"Post\":\n",
    "                    post_count += 1\n",
    "\n",
    "        return {\n",
    "            \"Pre\": pre_count,\n",
    "            \"Intra\": intra_count,\n",
    "            \"Post\": post_count,\n",
    "            \"Pre+Intra\": both_pre_intra,\n",
    "            \"Pre+Post\": both_pre_post,\n",
    "            \"Intra+Post\": both_intra_post,\n",
    "            \"All three\": all_three,\n",
    "        }\n",
    "\n",
    "    timing_dist = count_timing_distribution(df_item_raw)\n",
    "    for key, val in timing_dist.items():\n",
    "        print(f\"  {key:15s}: {val:3d}개 제품\")\n",
    "\n",
    "    print(f\"\\n📦 총 제품 수: {len(df_item_raw)}\")\n",
    "\n",
    "    # 2. 샘플 timing_category 값 확인\n",
    "    print(\"\\n📝 timing_category 샘플 (처음 10개):\")\n",
    "    for idx, row in df_item_raw.head(10).iterrows():\n",
    "        print(f\"  {row[ITEM_ID_COL][:30]:30s} -> {row['timing_category']}\")\n",
    "\n",
    "    # 3. 각 타이밍별로 실제 사용 가능한 제품 ID 확인\n",
    "    print(\"\\n🎯 각 타이밍별 사용 가능한 제품 ID 예시 (처음 5개씩):\")\n",
    "    for timing in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "        matching_products = df_item_raw[\n",
    "            df_item_raw[\"timing_category\"].apply(\n",
    "                lambda x: timing in x if isinstance(x, list) else x == timing\n",
    "            )\n",
    "        ]\n",
    "        print(f\"\\n  {timing} ({len(matching_products)}개 제품):\")\n",
    "        for prod_id in matching_products[ITEM_ID_COL].head(5):\n",
    "            print(f\"    - {prod_id}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ timing_category 컬럼이 없습니다!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286eb5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building test user top10 rows:   0%|          | 0/552 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building test user top10 rows:  13%|█▎        | 71/552 [00:45<04:56,  1.62it/s]"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 10. Train/Test 사용자별 Top-3 추천 결과 생성 (Pre/Intra/Post, 부원료)\n",
    "# ================================================================\n",
    "import os\n",
    "\n",
    "\n",
    "# 유틸: 단일 유저에 대해 시나리오별 Top-3 행들을 생성\n",
    "def build_user_top10_rows(\n",
    "    user_id,\n",
    "    user_set_name,\n",
    "    model,\n",
    "    dataset,\n",
    "    user_features_matrix,\n",
    "    item_features_matrix,\n",
    "    df_item_raw,\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    # 1) Pre/Intra/Post\n",
    "    for scenario in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "        recs = get_filtered_recommendations(\n",
    "            user_id=user_id,\n",
    "            model=model,\n",
    "            dataset=dataset,\n",
    "            user_features_matrix=user_features_matrix,\n",
    "            item_features_matrix=item_features_matrix,\n",
    "            df_item_raw=df_item_raw,\n",
    "            timing=scenario,\n",
    "            k_total=250,\n",
    "            k_final=10,\n",
    "        )\n",
    "        if not recs.empty:\n",
    "            for rank_idx, (_, r) in enumerate(recs.head(10).iterrows(), start=1):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"user_set\": user_set_name,\n",
    "                        \"user_id\": user_id,\n",
    "                        \"scenario\": scenario,\n",
    "                        \"rank\": rank_idx,\n",
    "                        \"product_id\": r.get(ITEM_ID_COL),\n",
    "                        \"category\": r.get(\"category\"),\n",
    "                        \"product_name\": r.get(\"product_name\"),\n",
    "                        \"predicted_score\": r.get(\"Predicted_Score\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # 2) 부원료만 별도로 Top-3 (타이밍 무관)\n",
    "    all_recs = recommend_for_user(\n",
    "        user_id,\n",
    "        model,\n",
    "        dataset,\n",
    "        user_features_matrix,\n",
    "        item_features_matrix,\n",
    "        df_item_raw,\n",
    "        k=250,\n",
    "    )\n",
    "    if not all_recs.empty and \"ingredient_type\" in df_item_raw.columns:\n",
    "        # 메타데이터와 결합해서 ingredient_type 접근\n",
    "        merged = all_recs.merge(\n",
    "            df_item_raw[[ITEM_ID_COL, \"ingredient_type\", \"category\", \"product_name\"]],\n",
    "            on=ITEM_ID_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "        sub_ing = merged[merged[\"ingredient_type\"] == \"부원료\"].head(3)\n",
    "        if not sub_ing.empty:\n",
    "            for rank_idx, (_, r) in enumerate(sub_ing.iterrows(), start=1):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"user_set\": user_set_name,\n",
    "                        \"user_id\": user_id,\n",
    "                        \"scenario\": \"부원료\",\n",
    "                        \"rank\": rank_idx,\n",
    "                        \"product_id\": r.get(ITEM_ID_COL),\n",
    "                        \"category\": r.get(\"category\"),\n",
    "                        \"product_name\": r.get(\"product_name\"),\n",
    "                        \"predicted_score\": r.get(\"Predicted_Score\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# # Train/Test 사용자 ID 목록 수집\n",
    "# train_users = (\n",
    "#     sorted(df_train_interactions[\"user_id\"].unique())\n",
    "#     if \"df_train_interactions\" in globals()\n",
    "#     else []\n",
    "# )\n",
    "test_users = (\n",
    "    sorted(df_test_interactions[\"user_id\"].unique())\n",
    "    if \"df_test_interactions\" in globals()\n",
    "    else []\n",
    ")\n",
    "\n",
    "# print(f\"Train users: {len(train_users)} | Test users: {len(test_users)}\")\n",
    "\n",
    "# # 배치 생성\n",
    "# train_rows = []\n",
    "# for uid in train_users:\n",
    "#     train_rows.extend(\n",
    "#         build_user_top10_rows(\n",
    "#             uid,\n",
    "#             \"train\",\n",
    "#             model,\n",
    "#             timing_datasets,\n",
    "#             user_features_matrix,\n",
    "#             item_features_matrix,\n",
    "#             df_item_raw,\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "test_rows = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for uid in tqdm(test_users, desc=\"Building test user top10 rows\"):\n",
    "    test_rows.extend(\n",
    "        build_user_top10_rows(\n",
    "            uid,\n",
    "            \"test\",\n",
    "            model,\n",
    "            timing_datasets,\n",
    "            user_features_matrix,\n",
    "            item_features_matrix,\n",
    "            df_item_raw,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 데이터프레임으로 정리\n",
    "# train_top10_df = pd.DataFrame(\n",
    "#     train_rows,\n",
    "#     columns=[\n",
    "#         \"user_set\",\n",
    "#         \"user_id\",\n",
    "#         \"scenario\",\n",
    "#         \"rank\",\n",
    "#         \"product_id\",\n",
    "#         \"category\",\n",
    "#         \"product_name\",\n",
    "#         \"predicted_score\",\n",
    "#     ],\n",
    "# )\n",
    "test_top10_df = pd.DataFrame(\n",
    "    test_rows,\n",
    "    columns=[\n",
    "        \"user_set\",\n",
    "        \"user_id\",\n",
    "        \"scenario\",\n",
    "        \"rank\",\n",
    "        \"product_id\",\n",
    "        \"category\",\n",
    "        \"product_name\",\n",
    "        \"predicted_score\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 저장 경로\n",
    "out_dir = os.path.dirname(os.path.abspath(\"recommendations_top10_train.csv\"))\n",
    "# train_path = os.path.join(out_dir, \"recommendations_top10_train.csv\")\n",
    "test_path = os.path.join(out_dir, \"recommendations_top10_test.csv\")\n",
    "\n",
    "# train_top10_df.to_csv(train_path, index=False)\n",
    "test_top10_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"\\n[Saved]\")\n",
    "# print(f\"- Train Top-3: {train_path}\")\n",
    "print(f\"- Test  Top-3: {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "📊 추천 결과 다양성 분석 (순위 정보 포함)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_top10_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 시나리오별 제품별 추천 빈도\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mPre\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mIntra\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPost\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scenario \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_top10_df\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mscenario\u001b[39m\u001b[33m\"\u001b[39m].values:\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     13\u001b[39m     scenario_df = test_top10_df[test_top10_df[\u001b[33m\"\u001b[39m\u001b[33mscenario\u001b[39m\u001b[33m\"\u001b[39m] == scenario]\n",
      "\u001b[31mNameError\u001b[39m: name 'test_top10_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 다양성 분석: 추천 결과의 다양성 확인 (순위 정보 포함)\n",
    "# ================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"📊 추천 결과 다양성 분석 (순위 정보 포함)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 시나리오별 제품별 추천 빈도\n",
    "for scenario in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "    if scenario not in test_top10_df[\"scenario\"].values:\n",
    "        continue\n",
    "\n",
    "    scenario_df = test_top10_df[test_top10_df[\"scenario\"] == scenario]\n",
    "    product_counts = scenario_df[\"product_id\"].value_counts()\n",
    "\n",
    "    print(f\"\\n--- {scenario} 추천 ({len(scenario_df)}건) ---\")\n",
    "    print(f\"고유 제품 수: {len(product_counts)}개\")\n",
    "    print(f\"상위 5개 제품:\")\n",
    "    for i, (product, count) in enumerate(product_counts.head(5).items(), 1):\n",
    "        percentage = (count / len(scenario_df)) * 100\n",
    "        product_name = (\n",
    "            scenario_df[scenario_df[\"product_id\"] == product][\"product_name\"].iloc[0]\n",
    "            if len(scenario_df[scenario_df[\"product_id\"] == product]) > 0\n",
    "            else \"N/A\"\n",
    "        )\n",
    "\n",
    "        # 순위별 추천 횟수 계산\n",
    "        rank_counts = (\n",
    "            scenario_df[scenario_df[\"product_id\"] == product][\"rank\"]\n",
    "            .value_counts()\n",
    "            .sort_index()\n",
    "        )\n",
    "        rank_str = \", \".join([f\"{rank}위:{cnt}회\" for rank, cnt in rank_counts.items()])\n",
    "\n",
    "        print(f\"  {i}. {product[:30]:30s} {count:4d}회 ({percentage:5.2f}%)\")\n",
    "        print(f\"      순위 분포: {rank_str}\")\n",
    "        print(f\"      제품명: {product_name[:40]}\")\n",
    "\n",
    "    # 다양성 지표\n",
    "    unique_products = len(product_counts)\n",
    "    total_recommendations = len(scenario_df)\n",
    "    diversity = (unique_products / total_recommendations) * 100\n",
    "    print(\n",
    "        f\"\\n  다양성 지표: {unique_products}/{total_recommendations} = {diversity:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # 1위로 추천된 횟수 기준 집중도\n",
    "    rank1_df = scenario_df[scenario_df[\"rank\"] == 1]\n",
    "    rank1_counts = rank1_df[\"product_id\"].value_counts()\n",
    "    rank1_percentage = (\n",
    "        (rank1_counts.iloc[0] / len(rank1_df)) * 100 if len(rank1_counts) > 0 else 0\n",
    "    )\n",
    "    print(f\"  1위 추천 집중도: {rank1_counts.iloc[0]}회 ({rank1_percentage:.2f}%)\")\n",
    "\n",
    "    # 상위 3개 제품이 차지하는 비율\n",
    "    top3_percentage = (product_counts.head(3).sum() / total_recommendations) * 100\n",
    "    print(f\"  상위 3개 제품의 총 점유율: {top3_percentage:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ 노트북 재실행 시 다양성 개선 효과를 확인할 수 있습니다.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ff665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 상호작용 데이터 제품 빈도 분석\n",
      "================================================================================\n",
      "❌ df_interactions가 없습니다!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 🔍 상호작용 데이터 제품 빈도 확인\n",
    "# ================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"🔍 상호작용 데이터 제품 빈도 분석\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if \"df_interactions\" in globals():\n",
    "    # 전체 상호작용 데이터 제품 빈도\n",
    "    print(\"\\n📊 전체 상호작용 데이터 제품 빈도 (상위 20개):\")\n",
    "    item_counts_all = df_interactions[\"item_id\"].value_counts()\n",
    "    for i, (item_id, count) in enumerate(item_counts_all.head(20).items(), 1):\n",
    "        percentage = (count / len(df_interactions)) * 100\n",
    "        print(f\"  {i:2d}. {item_id[:45]:45s} {count:4d}회 ({percentage:5.2f}%)\")\n",
    "\n",
    "    print(f\"\\n📦 전체 상호작용 데이터: {len(df_interactions)}건\")\n",
    "    print(f\"📦 고유 제품 수: {len(item_counts_all)}개\")\n",
    "    print(f\"📦 사용자 수: {df_interactions['user_id'].nunique()}명\")\n",
    "\n",
    "    # 타이밍별로 제품을 필터링하여 확인\n",
    "    if \"df_item_raw\" in globals() and \"timing_category\" in df_item_raw.columns:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"🎯 타이밍별 실제 상호작용 제품 빈도\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # 타이밍별 제품 ID 가져오기\n",
    "        for timing in [\"Pre\", \"Intra\", \"Post\"]:\n",
    "            timing_items = df_item_raw[\n",
    "                df_item_raw[\"timing_category\"].apply(\n",
    "                    lambda x: timing in x if isinstance(x, list) else x == timing\n",
    "                )\n",
    "            ][ITEM_ID_COL].unique()\n",
    "\n",
    "            timing_interactions = df_interactions[\n",
    "                df_interactions[\"item_id\"].isin(timing_items)\n",
    "            ]\n",
    "\n",
    "            print(f\"\\n--- {timing} 상호작용 (총 {len(timing_interactions)}건) ---\")\n",
    "            timing_item_counts = timing_interactions[\"item_id\"].value_counts()\n",
    "\n",
    "            print(f\"고유 제품 수: {len(timing_item_counts)}개\")\n",
    "            print(f\"상위 10개 제품:\")\n",
    "            for i, (item_id, count) in enumerate(\n",
    "                timing_item_counts.head(10).items(), 1\n",
    "            ):\n",
    "                percentage = (\n",
    "                    (count / len(timing_interactions)) * 100\n",
    "                    if len(timing_interactions) > 0\n",
    "                    else 0\n",
    "                )\n",
    "                print(f\"  {i:2d}. {item_id[:45]:45s} {count:4d}회 ({percentage:5.2f}%)\")\n",
    "\n",
    "            # 집중도 지표\n",
    "            if len(timing_item_counts) > 0:\n",
    "                top1_percentage = (\n",
    "                    (timing_item_counts.iloc[0] / len(timing_interactions)) * 100\n",
    "                    if len(timing_interactions) > 0\n",
    "                    else 0\n",
    "                )\n",
    "                top10_percentage = (\n",
    "                    (timing_item_counts.head(3).sum() / len(timing_interactions)) * 100\n",
    "                    if len(timing_interactions) > 0\n",
    "                    else 0\n",
    "                )\n",
    "                print(f\"\\n  상위 1개 점유율: {top1_percentage:.2f}%\")\n",
    "                print(f\"  상위 3개 점유율: {top10_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"❌ df_interactions가 없습니다!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41651f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightfm_python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
